# update_911_daily.py

from __future__ import annotations
import os, re
from pathlib import Path
import pandas as pd
import numpy as np

# ------------ ENV & yollar ------------
P_911      = Path(os.getenv("FR_911_PATH", "fr_911.csv"))
COL_DT_911 = os.getenv("FR_911_DATE_COL", "incident_datetime")
COL_G_911  = os.getenv("FR_911_GEOID_COL", "GEOID")
COL_CAT    = os.getenv("FR_911_CAT_COL", "category")

GRID_IN    = Path(os.getenv("FR_GRID_DAILY_IN",  "fr_crime_grid_daily.csv"))
GRID_OUT   = Path(os.getenv("FR_GRID_DAILY_OUT", "fr_crime_grid_daily.csv"))
EV_IN      = Path(os.getenv("FR_EVENTS_DAILY_IN","fr_crime_events_daily.csv"))
EV_OUT     = Path(os.getenv("FR_EVENTS_DAILY_OUT","fr_crime_events_daily.csv"))

CAT_TOPK   = int(os.getenv("FR_CAT_TOPK", "8"))
WINS_Q     = float(os.getenv("FR_911_WINSOR_Q", "0.999"))

def log(x): print(x, flush=True)

def _read_csv(p: Path) -> pd.DataFrame:
    if not p.exists():
        log(f"‚ùå Bulunamadƒ±: {p}")
        return pd.DataFrame()
    df = pd.read_csv(p, low_memory=False)
    log(f"üìñ Okundu: {p} ({len(df):,}√ó{df.shape[1]})")
    return df

def _save_csv(df: pd.DataFrame, p: Path):
    # downcast + kaydet
    for c in df.select_dtypes(include=["float64"]).columns:
        df[c] = pd.to_numeric(df[c], downcast="float")
    for c in df.select_dtypes(include=["int64","Int64"]).columns:
        df[c] = pd.to_numeric(df[c], downcast="integer")
    tmp = p.with_suffix(p.suffix + ".tmp")
    df.to_csv(tmp, index=False)
    tmp.replace(p)
    log(f"üíæ Yazƒ±ldƒ±: {p} ({len(df):,}√ó{df.shape[1]})")

def _norm_geoid(s: pd.Series) -> pd.Series:
    return (
        s.astype(str)
         .str.extract(r"(\d+)")[0]
         .fillna("")
         .apply(lambda x: x.zfill(11) if x else "")
    )

def autodetect_dt_col(df: pd.DataFrame, pref: str) -> str | None:
    if pref in df.columns: return pref
    for c in ["datetime","occurred_at","timestamp","date_time","created_at","time"]:
        if c in df.columns: return c
    if "date" in df.columns and "time" in df.columns:
        return "date+time"
    if "date" in df.columns:
        return "date"
    return None

def _slug(s: str) -> str:
    # kategori colon adƒ± g√ºvenli kƒ±sa slug
    s = str(s).strip().lower()
    s = re.sub(r"[^a-z0-9]+", "_", s).strip("_")
    return s[:24] if s else "cat"

# ========== 911 ‚Üí G√ºnl√ºk ==========
def make_911_daily(df911: pd.DataFrame, col_g: str, col_dt_hint: str) -> pd.DataFrame:
    # [8] dedup (varsa)
    for cid in ["call_id", "incident_id", "id"]:
        if cid in df911.columns:
            before = len(df911)
            df911 = df911.drop_duplicates(subset=[cid]).copy()
            if len(df911) != before: log(f"üßπ Dedup: {before-len(df911)} satƒ±r √ßƒ±karƒ±ldƒ± ({cid})")
            break

    # GEOID normalize
    if col_g not in df911.columns:
        cand = [c for c in df911.columns if "geoid" in c.lower()]
        if not cand:
            log("‚ö†Ô∏è 911 verisinde GEOID yok ‚Üí atlanƒ±yor.")
            return pd.DataFrame()
        col_g = cand[0]
    df911["GEOID"] = _norm_geoid(df911[col_g])

    # datetime parse ‚Üí date
    use_dt = autodetect_dt_col(df911, col_dt_hint)
    if use_dt is None:
        log("‚ö†Ô∏è 911 zaman s√ºtunu bulunamadƒ± ‚Üí atlanƒ±yor.")
        return pd.DataFrame()
    if use_dt == "date+time":
        dt = pd.to_datetime(df911["date"].astype(str).str.strip() + " " +
                            df911["time"].astype(str).str.strip(),
                            errors="coerce", utc=True)
    else:
        dt = pd.to_datetime(df911[use_dt], errors="coerce", utc=True)
    df911["date"] = dt.dt.date

    # g√ºnl√ºk sayƒ±m (ham)
    daily_raw = (
        df911.dropna(subset=["GEOID","date"])
             .groupby(["GEOID","date"], as_index=False)
             .size()
             .rename(columns={"size":"n911_d"})
    )

    # [8] winsorize (opsiyonel)
    if WINS_Q and 0 < WINS_Q < 1 and not daily_raw.empty:
        q = daily_raw["n911_d"].quantile(WINS_Q)
        daily_raw["n911_d"] = daily_raw["n911_d"].clip(upper=max(q, 1))
        log(f"üîß Winsorize: q={WINS_Q} √ºst={q:.1f}")

    # [1] tam takvim reindex (eksik g√ºnleri 0)
    if not daily_raw.empty:
        all_days = pd.date_range(daily_raw["date"].min(), daily_raw["date"].max(), freq="D").date
        geoids = daily_raw["GEOID"].unique()
        idx = pd.MultiIndex.from_product([geoids, all_days], names=["GEOID","date"])
        daily = (daily_raw.set_index(["GEOID","date"])
                           .reindex(idx, fill_value=0)
                           .reset_index())
    else:
        daily = daily_raw

    # leakage engelle: shift(1) + rolling(3/7/30)
    daily = daily.sort_values(["GEOID","date"])
    daily["n911_prev_1d"]  = daily.groupby("GEOID")["n911_d"].shift(1)
    daily["n911_roll_3d"]  = daily.groupby("GEOID")["n911_d"].shift(1).rolling(3,  min_periods=1).sum()
    daily["n911_roll_7d"]  = daily.groupby("GEOID")["n911_d"].shift(1).rolling(7,  min_periods=1).sum()
    daily["n911_roll_30d"] = daily.groupby("GEOID")["n911_d"].shift(1).rolling(30, min_periods=1).sum()

    # [2] EMA/decay (shift(1) √ºst√ºnden)
    for alpha in (0.3, 0.5):
        daily[f"n911_ema_a{int(alpha*10)}"] = (
            daily.groupby("GEOID")["n911_d"]
                 .apply(lambda s: s.shift(1).ewm(alpha=alpha, adjust=False).mean())
        ).astype("float32")

    # NaN‚Üí0, tipler
    fill_int = ["n911_d","n911_prev_1d","n911_roll_3d","n911_roll_7d","n911_roll_30d"]
    daily[fill_int] = daily[fill_int].fillna(0).astype("int32")

    # [3] trend 7v30 (float)
    daily["n911_trend_7v30"] = (daily["n911_roll_7d"] - daily["n911_roll_30d"]).astype("float32")

    return daily

# ========== 911 ‚Üí Kategori bazlƒ± ==========
def make_911_category_rollings(df911: pd.DataFrame) -> pd.DataFrame:
    # kategori kolonu autodetect
    cat_col = None
    for c in [COL_CAT, "type", "call_type", "category_name", "event_type"]:
        if c in df911.columns:
            cat_col = c; break
    if cat_col is None:
        log("‚ÑπÔ∏è 911 kategori s√ºtunu bulunamadƒ± ‚Äî kategori rolling atlandƒ±.")
        return pd.DataFrame()

    # tarih hazƒ±r deƒüilse √ºret
    if "date" not in df911.columns:
        use_dt = autodetect_dt_col(df911, COL_DT_911)
        if use_dt is None:
            log("‚ÑπÔ∏è Kategori i√ßin tarih t√ºretilemedi.")
            return pd.DataFrame()
        if use_dt == "date+time":
            dt = pd.to_datetime(df911["date"].astype(str)+" "+df911["time"].astype(str), errors="coerce", utc=True)
        else:
            dt = pd.to_datetime(df911[use_dt], errors="coerce", utc=True)
        df911["date"] = dt.dt.date

    df911["GEOID"] = _norm_geoid(df911.get(COL_G_911, df911["GEOID"]))
    cat = (df911.dropna(subset=["GEOID","date"])
                 .groupby(["GEOID","date",cat_col], as_index=False)
                 .size().rename(columns={"size":"n911_cat"}))

    if cat.empty:
        return pd.DataFrame()

    # en sƒ±k K kategori
    topk = (cat.groupby(cat_col)["n911_cat"].sum().nlargest(CAT_TOPK).index.tolist())
    cat = cat[cat[cat_col].isin(topk)].copy()
    cat["_cat_slug"] = cat[cat_col].apply(_slug)

    # tam takvim per GEOID√ócat
    out_list = []
    for geo in cat["GEOID"].unique():
        df_g = cat[cat["GEOID"]==geo].copy()
        days = pd.date_range(df_g["date"].min(), df_g["date"].max(), freq="D").date
        for cg in df_g["_cat_slug"].unique():
            df_gc = df_g[df_g["_cat_slug"]==cg].set_index("date")["n911_cat"]
            df_gc = df_gc.reindex(days, fill_value=0).reset_index().rename(columns={"index":"date","n911_cat":"cnt"})
            df_gc["GEOID"] = geo
            df_gc["_cat_slug"] = cg
            out_list.append(df_gc)
    if not out_list:
        return pd.DataFrame()

    cat_full = pd.concat(out_list, ignore_index=True)
    cat_full = cat_full.sort_values(["GEOID","_cat_slug","date"])

    # sƒ±zƒ±ntƒ±sƒ±z rolling
    def _roll_grp(g):
        g["cnt_prev_1d"]  = g["cnt"].shift(1)
        g["cnt_roll_7d"]  = g["cnt"].shift(1).rolling(7,  min_periods=1).sum()
        g["cnt_roll_30d"] = g["cnt"].shift(1).rolling(30, min_periods=1).sum()
        return g
    cat_full = cat_full.groupby(["GEOID","_cat_slug"], group_keys=False).apply(_roll_grp)

    # pivotla kolona (top-K ile sƒ±nƒ±rlƒ±)
    piv = cat_full.pivot_table(index=["GEOID","date"],
                               columns="_cat_slug",
                               values=["cnt_prev_1d","cnt_roll_7d","cnt_roll_30d"],
                               fill_value=0, aggfunc="first")
    # kolon isimlerini d√ºzle≈ütir
    piv.columns = [f"n911_{lvl2}_{lvl1}" for (lvl1,lvl2) in piv.columns.to_flat_index()]
    piv = piv.reset_index()
    return piv

# ========== GRID / EVENTS enrich ==========
def enrich_grid(grid: pd.DataFrame, g911: pd.DataFrame, gcat: pd.DataFrame) -> pd.DataFrame:
    out = grid.copy()
    # tarih tipi normalize
    if not np.issubdtype(pd.Series(out["date"]).dtype, np.datetime64):
        out["date"] = pd.to_datetime(out["date"], errors="coerce").dt.date

    out = out.merge(g911, on=["GEOID","date"], how="left")
    if not gcat.empty:
        out = out.merge(gcat, on=["GEOID","date"], how="left")

    # doldur
    base_int = ["n911_d","n911_prev_1d","n911_roll_3d","n911_roll_7d","n911_roll_30d"]
    for c in base_int:
        if c in out.columns: out[c] = out[c].fillna(0).astype("int32")
    for c in ["n911_ema_a3","n911_ema_a5","n911_trend_7v30"]:
        if c in out.columns: out[c] = out[c].fillna(0).astype("float32")
    # kategori kolonlarƒ± (float)
    if not gcat.empty:
        for c in gcat.columns:
            if c not in ("GEOID","date"):
                out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0)

    return out

def enrich_events(events: pd.DataFrame, g911: pd.DataFrame, gcat: pd.DataFrame) -> pd.DataFrame:
    out = events.copy()
    # GEOID + date
    if "GEOID" in out.columns:
        out["GEOID"] = _norm_geoid(out["GEOID"])
    if "date" not in out.columns:
        if "incident_datetime" in out.columns:
            out["date"] = pd.to_datetime(out["incident_datetime"], errors="coerce", utc=True).dt.date
        else:
            raise ValueError("OUT_EVENTS i√ßinde 'date' yok ve 'incident_datetime' yok.")

    # sadece ge√ßmi≈ü pencereler: prev/roll/ema/trend g√ºvenli
    feats = g911[["GEOID","date","n911_prev_1d","n911_roll_3d","n911_roll_7d",
                  "n911_roll_30d","n911_ema_a3","n911_ema_a5","n911_trend_7v30"]].drop_duplicates()
    out = out.merge(feats, on=["GEOID","date"], how="left")

    # kategori (opsiyonel)
    if not gcat.empty:
        out = out.merge(gcat, on=["GEOID","date"], how="left")

    # fill
    for c in ["n911_prev_1d","n911_roll_3d","n911_roll_7d","n911_roll_30d"]:
        if c in out.columns: out[c] = out[c].fillna(0).astype("int32")
    for c in ["n911_ema_a3","n911_ema_a5","n911_trend_7v30"]:
        if c in out.columns: out[c] = out[c].fillna(0).astype("float32")
    if not gcat.empty:
        for c in gcat.columns:
            if c not in ("GEOID","date"):
                out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0)

    return out

# ========== MAIN ==========
def main():
    log("üöÄ update_911_daily.py (revize: 1,2,3,7,8)")
    df911 = _read_csv(P_911)
    if df911.empty:
        log("‚ÑπÔ∏è 911 verisi yok, i≈ülem atlandƒ±.")
        return 0

    g911 = make_911_daily(df911, COL_G_911, COL_DT_911)    # base + reindex + EMA + trend
    if g911.empty:
        log("‚ÑπÔ∏è 911 g√ºnl√ºk t√ºretilemedi, i≈ülem atlandƒ±.")
        return 0

    gcat = make_911_category_rollings(df911)               # kategori-bazlƒ± (opsiyonel)
    if not gcat.empty:
        log(f"üìä Kategori rolling kolonlarƒ±: {len(gcat.columns)-2}")

    # ---- GRID ----
    grid = _read_csv(GRID_IN)
    if not grid.empty:
        grid2 = enrich_grid(grid, g911, gcat)
        _save_csv(grid2, GRID_OUT)
    else:
        log("‚ÑπÔ∏è GRID bulunamadƒ±, GRID zenginle≈ütirme atlandƒ±.")

    # ---- EVENTS ----
    ev = _read_csv(EV_IN)
    if not ev.empty:
        ev2 = enrich_events(ev, g911, gcat)
        _save_csv(ev2, EV_OUT)
    else:
        log("‚ÑπÔ∏è EVENTS bulunamadƒ±, EVENTS zenginle≈ütirme atlandƒ±.")

    log("‚úÖ Tamam.")

if __name__ == "__main__":
    main()
