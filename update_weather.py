# update_weather.py ‚Äî weather'ƒ± g√ºncelle + *_crime_07 ile birle≈ütir ‚Üí *_crime_08.csv
# Robust, header-safe, √ßok-kent destekli (prefix: sf, fr, ...)

from datetime import datetime, timedelta, date
import os
import sys
from typing import Optional, List
import pandas as pd
import numpy as np

# Opsiyonel: PyGithub ve Meteostat
try:
    from github import Github  # only if upload wanted
except Exception:
    Github = None

try:
    from meteostat import Daily, Point
except Exception as e:
    print("‚ö†Ô∏è meteostat kurulu deƒüilse yalnƒ±zca mevcut weather CSV'si ile devam ederiz:", e)
    Daily = None
    Point = None

# =====================================================================================
# AYARLAR
# =====================================================================================
DATA_DIR      = os.getenv("CRIME_DATA_DIR", "crime_prediction_data").rstrip("/")

# Weather dosyasƒ± (g√ºncellenecek / olu≈üturulacak)
WEATHER_CSV   = os.getenv("WEATHER_CSV", os.path.join(DATA_DIR, "sf_weather_5years.csv"))

# √áok-kent: virg√ºlle ayƒ±r (√∂rn: "sf,fr")
CITY_PREFIXES = [s.strip() for s in os.getenv("CITY_PREFIXES", "sf").split(",") if s.strip()]

# GitHub'a yalnƒ±zca istenirse y√ºkle (hem token hem repo bilgileri lazƒ±mdƒ±r)
UPLOAD_WEATHER_TO_GH = os.getenv("UPLOAD_WEATHER_TO_GH", "0") in ("1", "true", "True")
UPLOAD_08_TO_GH      = os.getenv("UPLOAD_08_TO_GH", "0") in ("1", "true", "True")
GITHUB_TOKEN         = os.getenv("GITHUB_TOKEN") or os.getenv("GH_TOKEN")
REPO_NAME            = os.getenv("REPO_NAME", "cem5113/crime_prediction_data")
WEATHER_TARGET_PATH  = os.getenv("WEATHER_TARGET_PATH", f"{DATA_DIR}/sf_weather_5years.csv")

# Meteostat ayarlarƒ±
LAT, LON = float(os.getenv("WX_LAT", "37.7749")), float(os.getenv("WX_LON", "-122.4194"))  # San Francisco
HOT_DAY_THRESHOLD_C = float(os.getenv("HOT_DAY_THRESHOLD_C", "25.0"))

# =====================================================================================
# TARƒ∞H PENCERESƒ∞
# =====================================================================================
def five_year_window(today: date):
    try:
        start = today.replace(year=today.year - 5)
    except ValueError:
        start = today - timedelta(days=365*5 + 2)
    return (start + timedelta(days=1), today)

today = date.today()
win_start, win_end = five_year_window(today)
print(f"üìÖ 5Y Pencere: {win_start} ‚Üí {win_end}")

# =====================================================================================
# YARDIMCILAR
# =====================================================================================
def to_date(s: pd.Series) -> pd.Series:
    return pd.to_datetime(s, errors="coerce").dt.date

def normalize_weather_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Weather kolonlarƒ±nƒ± standardize eder (header-safe)."""
    d = df.copy()
    lmap = {c.lower(): c for c in d.columns}
    def has(c): return c in lmap
    def col(c): return lmap[c]

    # date/datetime/time ‚Üí date
    if has("date"):
        d[col("date")] = to_date(d[col("date")])
    elif has("time"):
        d["date"] = to_date(d[col("time")])
    elif has("datetime"):
        d["date"] = to_date(d[col("datetime")])

    # yeniden adla
    ren = {}
    if has("temp_min") and not has("tmin"): ren[col("temp_min")] = "tmin"
    if has("temp_max") and not has("tmax"): ren[col("temp_max")] = "tmax"
    if has("precipitation_mm") and not has("prcp"): ren[col("precipitation_mm")] = "prcp"
    if has("prcp_mm") and not has("prcp"): ren[col("prcp_mm")] = "prcp"
    if has("taverage") and not has("tavg"): ren[col("taverage")] = "tavg"
    d.rename(columns=ren, inplace=True)

    # tipler
    for c in ["tavg", "tmin", "tmax", "prcp", "snow", "wspd", "pres"]:
        if c in d.columns:
            d[c] = pd.to_numeric(d[c], errors="coerce")

    # Yok ise kolon olu≈ütur
    for c in ["tavg", "tmin", "tmax", "prcp"]:
        if c not in d.columns:
            d[c] = np.nan

    # temp_range, is_rainy, is_hot_day
    d["temp_range"] = (d["tmax"] - d["tmin"]).astype(float)
    d["is_rainy"] = (pd.to_numeric(d.get("prcp", np.nan), errors="coerce").fillna(0) > 0).astype("Int64")
    d["is_hot_day"] = (pd.to_numeric(d.get("tmax", np.nan), errors="coerce") > HOT_DAY_THRESHOLD_C).astype("Int64")

    # tarih zorunlu
    if "date" not in d.columns:
        d["date"] = pd.NaT

    d["date"] = to_date(d["date"])
    d.dropna(subset=["date"], inplace=True)
    d = d.drop_duplicates(subset=["date"]).sort_values("date")

    # pencere kƒ±rp
    d = d[(d["date"] >= win_start) & (d["date"] <= win_end)].copy()

    # sadece gerekli kolonlar
    final_cols = ["date", "tavg", "tmin", "tmax", "prcp", "temp_range", "is_rainy", "is_hot_day"]
    for c in final_cols:
        if c not in d.columns:
            d[c] = np.nan
    return d[final_cols]

def fetch_weather(lat: float, lon: float, start_d: date, end_d: date) -> pd.DataFrame:
    """Meteostat Daily ile veri √ßek; header-safe normalize et."""
    if Daily is None or Point is None:
        print("‚ÑπÔ∏è meteostat yok ‚Üí bo≈ü DataFrame d√∂n√ºyorum.")
        return pd.DataFrame(columns=["date","tavg","tmin","tmax","prcp","temp_range","is_rainy","is_hot_day"])
    start_dt = datetime(start_d.year, start_d.month, start_d.day)
    end_dt   = datetime(end_d.year, end_d.month, end_d.day)
    df = Daily(Point(lat, lon), start_dt, end_dt).fetch().reset_index()
    df.rename(columns={"time": "date"}, inplace=True)
    df = normalize_weather_columns(df)
    return df

def read_existing_weather(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        return pd.DataFrame(columns=["date","tavg","tmin","tmax","prcp","temp_range","is_rainy","is_hot_day"])
    try:
        ex = pd.read_csv(path, low_memory=False)
        ex = normalize_weather_columns(ex)
        return ex
    except Exception as e:
        print("‚ö†Ô∏è Mevcut weather dosyasƒ± okunamadƒ±, ba≈ütan √ßekilecek:", e)
        return pd.DataFrame(columns=["date","tavg","tmin","tmax","prcp","temp_range","is_rainy","is_hot_day"])

def upsert_github_csv(df: pd.DataFrame, target_path: str):
    if not (UPLOAD_WEATHER_TO_GH or UPLOAD_08_TO_GH):
        return
    if Github is None or not GITHUB_TOKEN:
        print("‚ÑπÔ∏è GitHub upload atlandƒ± (token veya PyGithub yok).")
        return
    try:
        g = Github(GITHUB_TOKEN)
        repo = g.get_repo(REPO_NAME)
        csv_str = df.to_csv(index=False)
        try:
            contents = repo.get_contents(target_path)
            repo.update_file(contents.path, f"update {os.path.basename(target_path)}", csv_str, contents.sha, branch="main")
            print(f"‚úÖ GitHub g√ºncellendi: {target_path}")
        except Exception:
            repo.create_file(target_path, f"add {os.path.basename(target_path)}", csv_str, branch="main")
            print(f"üÜï GitHub olu≈üturuldu: {target_path}")
    except Exception as e:
        print("‚ö†Ô∏è GitHub y√ºkleme hatasƒ±:", e)

def normalize_crime07(df: pd.DataFrame) -> pd.DataFrame:
    """*_crime_07 i√ßin tarih kolonunu g√ºvenle normalize et; GEOID vb. dokunma."""
    d = df.copy()
    cols = {c.lower(): c for c in d.columns}
    date_col = None
    for cand in ("date", "datetime", "time"):
        if cand in cols:
            date_col = cols[cand]
            break
    if date_col is None:
        # hi√ßbir tarih kolonu yoksa bƒ±rakalƒ±m (merge edemeyiz)
        d["date"] = pd.NaT
    else:
        d["date"] = to_date(d[date_col])
    d.dropna(subset=["date"], inplace=True)
    d["date"] = d["date"].astype("object")  # date dtype
    return d

def merge_07_weather_to_08(crime07_path: str, weather_df: pd.DataFrame, out_path: str) -> Optional[pd.DataFrame]:
    if not os.path.exists(crime07_path):
        print(f"‚ùå {crime07_path} bulunamadƒ±; {out_path} √ºretilemedi.")
        return None
    try:
        c7 = pd.read_csv(crime07_path, low_memory=False)
    except Exception as e:
        print(f"‚ùå {crime07_path} okunamadƒ±:", e)
        return None

    c7 = normalize_crime07(c7)

    # Weather kolonlarƒ±na wx_ prefix ekleyelim (√ßakƒ±≈ümayƒ± √∂nler)
    w = weather_df.copy()
    wx_cols = [c for c in w.columns if c != "date"]
    w = w.rename(columns={c: f"wx_{c}" for c in wx_cols})

    # LEFT MERGE (su√ß verisi master)
    merged = c7.merge(w, on="date", how="left", validate="m:1")

    # Kaydet
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    merged.to_csv(out_path, index=False)
    print(f"üíæ {out_path} yazƒ±ldƒ±. Satƒ±r: {len(merged)}")
    return merged

# =====================================================================================
# (YENƒ∞) WEATHER DF CACHE: Aynƒ± script i√ßinde tekrar kullanmak i√ßin
# =====================================================================================
_WEATHER_LATEST: pd.DataFrame | None = None

def get_weather_df() -> pd.DataFrame:
    """Script i√ßinde daha sonra tekrar kullanmak i√ßin g√ºncel weather DF'ini getirir."""
    global _WEATHER_LATEST
    if _WEATHER_LATEST is not None:
        return _WEATHER_LATEST
    if os.path.exists(WEATHER_CSV):
        try:
            df = pd.read_csv(WEATHER_CSV, low_memory=False)
            return normalize_weather_columns(df)
        except Exception:
            pass
    # Yedek: bo≈ü ≈üema
    return pd.DataFrame(
        columns=["date","tavg","tmin","tmax","prcp","temp_range","is_rainy","is_hot_day"]
    )

# =====================================================================================
# WEATHER G√úNCELLE
# =====================================================================================
existing = read_existing_weather(WEATHER_CSV)
last_date = existing["date"].max() if not existing.empty else None
fetch_start = (last_date + timedelta(days=1)) if pd.notna(last_date) else win_start
fetch_end   = win_end

if fetch_start <= fetch_end:
    print(f"üì• Meteostat Daily: {fetch_start} ‚Üí {fetch_end}")
    neww = fetch_weather(LAT, LON, fetch_start, fetch_end)
    print(f"‚úÖ Yeni g√ºn sayƒ±sƒ±: {len(neww)}")
    allw = pd.concat([existing, neww], ignore_index=True) if not existing.empty else neww.copy()
else:
    print("‚ÑπÔ∏è Weather g√ºncel; indirilecek yeni g√ºn yok.")
    allw = existing.copy()

# normalize + pencere kƒ±rp + tekille≈ütir
allw = normalize_weather_columns(allw)
allw = allw.drop_duplicates(subset=["date"]).sort_values("date")
allw = allw[(allw["date"] >= win_start) & (allw["date"] <= win_end)].copy()

# Kaydet (local)
os.makedirs(os.path.dirname(WEATHER_CSV), exist_ok=True)
allw.to_csv(WEATHER_CSV, index=False)
print(f"üíæ Weather kaydedildi: {WEATHER_CSV} ‚Äî {len(allw)} satƒ±r, {allw['date'].min()} ‚Üí {allw['date'].max()}")

# (YENƒ∞) Bellek i√ßi cache: aynƒ± scriptte tekrar kullanƒ±m i√ßin
_WEATHER_LATEST = allw.copy()

# ƒ∞stenirse GitHub'a y√ºkle
if UPLOAD_WEATHER_TO_GH:
    upsert_github_csv(allw, WEATHER_TARGET_PATH)

# =====================================================================================
# CRIME_07 ‚Üí CRIME_08 Bƒ∞RLE≈ûTƒ∞RME (√ßok-kent)
# =====================================================================================
produced_any = False
for pref in CITY_PREFIXES:
    pref = pref.strip()
    if not pref:
        continue
    in07  = os.path.join(DATA_DIR, f"{pref}_crime_07.csv")
    out08 = os.path.join(DATA_DIR, f"{pref}_crime_08.csv")
    print(f"üîó Birle≈ütiriliyor: {os.path.basename(in07)} + weather ‚Üí {os.path.basename(out08)}")
    m = merge_07_weather_to_08(in07, get_weather_df(), out08)
    if m is not None:
        produced_any = True
        if UPLOAD_08_TO_GH:
            target08 = f"{DATA_DIR}/{os.path.basename(out08)}"
            upsert_github_csv(m, target08)

if not produced_any:
    print("‚ÑπÔ∏è Hi√ßbir 07 dosyasƒ± bulunamadƒ±; 08 √ºretilemedi.")
else:
    print("üéâ Weather birle≈ütirme tamam. 08 dosyalarƒ± hazƒ±r.")
