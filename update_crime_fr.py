# update_crime_fr.py  (event-based fr_crime.csv)
from __future__ import annotations
import os
from pathlib import Path
from datetime import datetime
import pandas as pd
import numpy as np
import shutil

# =========================
# Ayarlar (ENV ile Ã¶zelleÅŸtirilebilir)
# =========================
EVENTS_PATH = Path(os.getenv("FR_EVENTS_PATH", "sf_crime.csv"))     # olay bazlÄ± kaynak (suÃ§_id iÃ§ermeli)
LABEL_PATH  = Path(os.getenv("FR_LABEL_PATH", "sf_crime_L.csv"))    # grid etiket kaynaÄŸÄ±
OUT_PATH    = Path(os.getenv("FR_OUT_PATH",   "fr_crime.csv"))      # hedef: olay bazlÄ± Ã§Ä±ktÄ±
MIRROR_DIR  = Path(os.getenv("FR_MIRROR_DIR", "crime_prediction_data"))

# Otomatik label bulma aÃ§Ä±k/kapalÄ± (1/0) â€“ kapatmak isterseniz FR_AUTOFIND_LABEL=0
AUTOFIND_LABEL = os.getenv("FR_AUTOFIND_LABEL", "1") == "1"

# Potansiyel eÅŸleÅŸme anahtarlarÄ± (Ã¶ncelik sÄ±rasÄ±yla)
FULL_KEYS = ["GEOID", "season", "day_of_week", "event_hour"]
GEOID_ONLY = ["GEOID"]

# Ã‡ekilecek etiket kolonu adÄ±
YCOL = os.getenv("FR_YCOL", "Y_label")


# =========================
# YardÄ±mcÄ±lar
# =========================
def _abs(p: Path) -> Path:
    """Absolute & expanded path."""
    return p.expanduser().resolve()

def safe_read_csv(p: Path) -> pd.DataFrame:
    p = _abs(p)
    if not p.exists():
        print(f"â„¹ï¸ BulunamadÄ±: {p}")
        return pd.DataFrame()
    try:
        df = pd.read_csv(p, low_memory=False)
        print(f"ğŸ“– Okundu: {p}  ({len(df):,} satÄ±r, {df.shape[1]} sÃ¼tun)")
        return df
    except Exception as e:
        print(f"âš ï¸ OkunamadÄ±: {p} â†’ {e}")
        return pd.DataFrame()

def safe_save_csv(df: pd.DataFrame, p: Path) -> None:
    p = _abs(p)
    p.parent.mkdir(parents=True, exist_ok=True)
    tmp = p.with_suffix(".tmp.csv")
    df.to_csv(tmp, index=False)
    tmp.replace(p)
    print(f"ğŸ’¾ Kaydedildi: {p}  ({len(df):,} satÄ±r, {df.shape[1]} sÃ¼tun)")

def normalize_event_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "GEOID" in df:
        df["GEOID"] = (
            df["GEOID"].astype(str).str.extract(r"(\d+)")[0].str.zfill(11)
        )
    for c in ("day_of_week", "event_hour"):
        if c in df:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)
    return df

def normalize_label_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "GEOID" in df:
        df["GEOID"] = (
            df["GEOID"].astype(str).str.extract(r"(\d+)")[0].str.zfill(11)
        )
    for c in ("day_of_week", "event_hour", YCOL):
        if c in df:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)
    return df

def dedupe_labels(df: pd.DataFrame, keys: list[str]) -> pd.DataFrame:
    """AynÄ± anahtar iÃ§in birden fazla Y varsa 1'i tercih et; yoksa 0."""
    if not all(k in df.columns for k in keys + [YCOL]):
        # Y_label yoksa sadece anahtara gÃ¶re tekilleÅŸtir
        return df.drop_duplicates(subset=[c for c in keys if c in df.columns])
    return df.groupby(keys, as_index=False)[YCOL].max()  # 1 > 0

def try_merge(events: pd.DataFrame, labels: pd.DataFrame, keys: list[str]) -> tuple[pd.DataFrame, list[str]]:
    keys = [k for k in keys if k in events.columns and k in labels.columns]
    if not keys:
        raise ValueError("EÅŸleÅŸme iÃ§in ortak anahtar bulunamadÄ±.")
    L = dedupe_labels(labels, keys)
    merged = events.merge(L[keys + [YCOL]], on=keys, how="left")
    return merged, keys

def resolve_label_path(initial: Path) -> Path | None:
    """LABEL_PATH yoksa makul adaylarÄ± dener (isteÄŸe baÄŸlÄ±)."""
    p = _abs(initial)
    if p.exists():
        return p
    candidates = [
        Path("crime_prediction_data/sf_crime_L.csv"),
        Path("sf_crime_L.csv"),
        Path("crime_prediction_data/sf_crime_grid_full_labeled.csv"),
        Path("sf_crime_grid_full_labeled.csv"),
        Path("crime_prediction_data/sf_crime_52.csv"),
        Path("sf_crime_52.csv"),
        Path("crime_prediction_data/sf_crime_y.csv"),
        Path("sf_crime_y.csv"),
    ]
    for c in candidates:
        if _abs(c).exists():
            print(f"ğŸ” Etiket kaynaÄŸÄ± otomatik bulundu: {_abs(c)}")
            return _abs(c)
    return None


# =========================
# AkÄ±ÅŸ
# =========================
def main() -> int:
    print("ğŸ“‚ CWD:", Path.cwd())
    print("ğŸ”§ ENV â†’ FR_EVENTS_PATH:", _abs(EVENTS_PATH))
    print("ğŸ”§ ENV â†’ FR_LABEL_PATH :", _abs(LABEL_PATH))
    print("ğŸ”§ ENV â†’ FR_OUT_PATH   :", _abs(OUT_PATH))
    print("ğŸ”§ ENV â†’ FR_MIRROR_DIR :", _abs(MIRROR_DIR))
    print("ğŸ”§ ENV â†’ FR_YCOL       :", YCOL)
    print("ğŸ”§ ENV â†’ FR_AUTOFIND_LABEL:", AUTOFIND_LABEL)

    # 1) Olay verisini oku
    events = safe_read_csv(EVENTS_PATH)
    if events.empty:
        print(f"âŒ Olay verisi boÅŸ veya yok: {_abs(EVENTS_PATH)}")
        return 0
    if "id" not in events.columns:
        print("âš ï¸ UyarÄ±: 'id' kolonu bulunamadÄ±. Yine de olay bazlÄ± devam edilecek.")
    events = normalize_event_df(events)
    base_len = len(events)
    print(f"ğŸ§® Olay satÄ±r sayÄ±sÄ±: {base_len:,}")

    # 2) Etiket gridini oku (gerekirse otomatik bul)
    lbl_path = LABEL_PATH
    labels = safe_read_csv(lbl_path)
    if labels.empty and AUTOFIND_LABEL:
        auto = resolve_label_path(lbl_path)
        if auto is not None and auto != _abs(lbl_path):
            lbl_path = auto
            labels = safe_read_csv(lbl_path)

    if labels.empty:
        print(f"âŒ Etiket kaynaÄŸÄ± boÅŸ veya yok: {_abs(lbl_path)}")
        return 0

    labels = normalize_label_df(labels)

    # 3) Ã–nce tam anahtar, olmazsa yalnÄ±zca GEOID ile eÅŸle
    used_keys: list[str] | None = None
    try:
        out, used_keys = try_merge(events, labels, FULL_KEYS)
        print(f"ğŸ”— EÅŸleÅŸme anahtarlarÄ±: {used_keys} (tam anahtar)")
    except Exception:
        out, used_keys = try_merge(events, labels, GEOID_ONLY)
        print(f"ğŸ”— EÅŸleÅŸme anahtarlarÄ±: {used_keys} (yalnÄ±zca GEOID)")

    # 4) EÅŸleÅŸemeyen satÄ±rlar
    missing = int(out[YCOL].isna().sum()) if YCOL in out.columns else 0
    if missing > 0:
        rate = round(missing / base_len * 100, 2) if base_len else 0.0
        print(f"â„¹ï¸ EÅŸleÅŸemeyen olay satÄ±rÄ±: {missing:,} (%{rate}) â†’ {YCOL} NaN. NaN'larÄ± 0'a Ã§eviriyorum.")
        out[YCOL] = out[YCOL].fillna(0).astype(int)

    # 5) Ä°z bilgisi
    out["fr_snapshot_at"] = datetime.utcnow().isoformat(timespec="seconds") + "Z"
    out["fr_label_keys"]  = "+".join(used_keys or [])

    # 6) Kaydet & mirror
    safe_save_csv(out, OUT_PATH)
    try:
        _abs(MIRROR_DIR).mkdir(parents=True, exist_ok=True)
        shutil.copy2(_abs(OUT_PATH), _abs(MIRROR_DIR) / _abs(OUT_PATH).name)
        print(f"ğŸ“¦ Mirror kopya: {_abs(MIRROR_DIR) / _abs(OUT_PATH).name}")
    except Exception as e:
        print(f"â„¹ï¸ Mirror kopya atlandÄ±/baÅŸarÄ±sÄ±z: {e}")

    # 7) HÄ±zlÄ± Ã¶zet
    if YCOL in out.columns:
        vc = out[YCOL].value_counts(normalize=True, dropna=False).mul(100).round(2)
        print("\nğŸ“Š Y_label oranlarÄ± (%):")
        try:
            # print(vc.to_string()) bazen geniÅŸ veri setinde uyarÄ± verebiliyor
            for k, v in vc.items():
                print(f"  {k}: {v}%")
        except Exception:
            print(vc)

    # 8) Temel kalite kontrolleri
    if "id" in out.columns:
        dup = int(out["id"].duplicated().sum())
        if dup:
            print(f"âš ï¸ UyarÄ±: {dup} adet tekrar eden id var.")
        else:
            print("âœ… id benzersiz gÃ¶rÃ¼nÃ¼yor.")

    return 0


if __name__ == "__main__":
    try:
        code = main()
        raise SystemExit(code if isinstance(code, int) else 0)
    except Exception as e:
        print(f"âš ï¸ FR derleme sÄ±rasÄ±nda yakalanmamÄ±ÅŸ hata: {e}")
        raise SystemExit(0)
