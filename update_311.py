# update_population.py â€” GEOID (11 hane, tract) zenginleÅŸtirme â†’ sf_crime_03.csv
from __future__ import annotations
import os, re, zipfile, csv
from pathlib import Path
import pandas as pd

pd.options.mode.copy_on_write = True

# ============================== Utils ==============================
def log(msg: str): print(msg, flush=True)

def safe_unzip(zip_path: Path, dest_dir: Path):
    if not zip_path.exists():
        log(f"â„¹ï¸ Artifact ZIP yok: {zip_path}")
        return
    dest_dir.mkdir(parents=True, exist_ok=True)
    log(f"ğŸ“¦ ZIP aÃ§Ä±lÄ±yor: {zip_path} â†’ {dest_dir}")
    with zipfile.ZipFile(zip_path, "r") as zf:
        for m in zf.infolist():
            out = dest_dir / m.filename
            out.parent.mkdir(parents=True, exist_ok=True)
            if m.is_dir():
                out.mkdir(parents=True, exist_ok=True); continue
            with zf.open(m, "r") as src, open(out, "wb") as dst:
                dst.write(src.read())
    log("âœ… ZIP Ã§Ä±karma tamam.")

# --- GEOID temizleyici: scientific notation & float gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ dÃ¼zelt ---
def _clean_geoid_scalar(x: str) -> str:
    if x is None:
        return ""
    s = str(x).strip()
    # Bilimsel gÃ¶sterim / float (Ã¶r: 6.0755980501E10, 60755980501.0)
    try:
        if re.fullmatch(r"[0-9]+(\.[0-9]+)?([eE][+\-]?[0-9]+)?", s):
            as_int = int(float(s))
            return str(as_int)
    except Exception:
        pass
    # Genel durum: rakam dÄ±ÅŸÄ±nÄ± at
    return re.sub(r"\D+", "", s)

def _digits_only(s: pd.Series) -> pd.Series:
    return s.astype(str).map(_clean_geoid_scalar).fillna("")

def _mode_len(series: pd.Series) -> int:
    if series.empty: return 11
    L = series.astype(str).str.len()
    m = L.mode(dropna=True)
    return int(m.iloc[0]) if not m.empty else int(L.dropna().median())

def _key(series: pd.Series, L: int) -> pd.Series:
    # YalnÄ±zca rakamlarÄ± al; kÄ±sa ise zfill, uzun ise kÄ±rp
    s = _digits_only(series)
    return s.str.zfill(L).str[:L]

def _find_geoid_col(df: pd.DataFrame) -> str | None:
    cands = ["GEOID","geoid","geo_id","GEOID10","geoid10","GeoID",
             "tract","TRACT","tract_geoid","TRACT_GEOID",
             "geography_id","GEOID2"]
    low = {c.lower(): c for c in df.columns}
    for n in cands:
        if n.lower() in low: return low[n.lower()]
    for c in df.columns:
        if "geoid" in c.lower(): return c
    return None

def _find_population_col(df: pd.DataFrame, forced: str | None = None) -> str | None:
    if forced and forced in df.columns:
        return forced
    cands = ["population","pop","total_population","B01003_001E","estimate","total","value"]
    low = {c.lower(): c for c in df.columns}
    for n in cands:
        if n.lower() in low: return low[n.lower()]
    for c in df.columns:
        if re.fullmatch(r"(pop.*|.*population.*|value)", c, flags=re.I): return c
    return None

def _num(s: pd.Series) -> pd.Series:
    return pd.to_numeric(
        s.astype(str).str.replace(",", "", regex=False).str.replace(" ", "", regex=False),
        errors="coerce"
    )

# ============================== Opsiyonel: Crosswalk ==============================
def _detect_crosswalk_cols(df: pd.DataFrame):
    """
    Crosswalk CSV iÃ§in muhtemel kolon setleri:
      - 'geoid_from','geoid_to'
      - 'tract2010','tract2020'
      - 'geoid10','geoid20'
    DÃ¶nÃ¼ÅŸ: (src_col, dst_col) veya (None,None)
    """
    candidates = [
        ("geoid_from","geoid_to"), ("tract2010","tract2020"),
        ("geoid10","geoid20"), ("GEOID10","GEOID20"), ("from","to")
    ]
    cols = set(df.columns)
    for a,b in candidates:
        if a in cols and b in cols:
            return a,b
    # zayÄ±f sezgi: iÃ§inde 2010/2020 geÃ§en ilk iki kolon
    c2010 = [c for c in df.columns if "2010" in c]
    c2020 = [c for c in df.columns if "2020" in c]
    if c2010 and c2020:
        return c2010[0], c2020[0]
    return None, None

def _apply_crosswalk_if_provided(pp: pd.DataFrame, key_col: str, join_len: int) -> pd.DataFrame:
    """
    Env: CROSSWALK_CSV varsa pp['_key'] deÄŸerlerini dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    Crosswalk haritasÄ± tractâ†’tract dÃ¼zeyinde olmalÄ± (11 hane).
    """
    path = os.getenv("CROSSWALK_CSV", "").strip()
    if not path:
        return pp
    p = Path(path)
    if not p.exists():
        log(f"â„¹ï¸ CROSSWALK_CSV bulunamadÄ±: {p}")
        return pp
    try:
        cw = pd.read_csv(p, dtype=str, low_memory=False)
    except Exception as e:
        log(f"âš ï¸ Crosswalk okunamadÄ±: {e}")
        return pp
    src_col, dst_col = _detect_crosswalk_cols(cw)
    if not src_col or not dst_col:
        log("âš ï¸ Crosswalk kolonlarÄ± tespit edilemedi (Ã¶rn. geoid10/geoid20).")
        return pp

    cw["_src"] = _key(cw[src_col], join_len)
    cw["_dst"] = _key(cw[dst_col], join_len)
    cw_map = dict(zip(cw["_src"], cw["_dst"]))
    before_unique = pp["_key"].nunique()
    pp = pp.copy()
    pp["_key"] = pp["_key"].map(lambda x: cw_map.get(x, x))
    after_unique = pp["_key"].nunique()
    log(f"[info] Crosswalk uygulandÄ±: uniq_keys {before_unique:,} â†’ {after_unique:,}")
    return pp

# ============================== Config ==============================
BASE_DIR      = Path(os.getenv("CRIME_DATA_DIR", "crime_prediction_data")); BASE_DIR.mkdir(parents=True, exist_ok=True)
ARTIFACT_ZIP  = Path(os.getenv("ARTIFACT_ZIP", "artifact/sf-crime-pipeline-output.zip"))
ARTIFACT_DIR  = Path(os.getenv("ARTIFACT_DIR", "artifact_unzipped"))
CRIME_OUTPUT  = str(BASE_DIR / "sf_crime_03.csv")

# BirleÅŸim anahtar uzunluÄŸu (tract iÃ§in 11)
JOIN_LEN      = int(os.getenv("JOIN_LEN", "11"))

# SF'ye filtre iÃ§in prefiks; boÅŸ ise filtre uygulanmaz
SF_PREFIX     = os.getenv("SF_PREFIX_FILTER", "06075").strip()

# Ä°steÄŸe baÄŸlÄ±: nÃ¼fus kolonunu zorla
FORCE_POP_COL = os.getenv("POPULATION_COL", "").strip() or None

# ZIP varsa aÃ§
safe_unzip(ARTIFACT_ZIP, ARTIFACT_DIR)

# Aday dosyalar (Ã¶ncelik: artifact_unzipped)
CRIME_CANDS = [
    ARTIFACT_DIR / "fr_crime_02.csv",
    ARTIFACT_DIR / "fr_crime.csv",
    BASE_DIR / "sf_crime_02.csv",
    BASE_DIR / "sf_crime.csv",
    Path("sf_crime_02.csv"),
    Path("sf_crime.csv"),
]
POP_CANDS = [
    Path(os.getenv("POPULATION_PATH")) if os.getenv("POPULATION_PATH") else None,
    ARTIFACT_DIR / "sf_population.csv",
    BASE_DIR / "sf_population.csv",
    Path("sf_population.csv"),
]

def pick(paths):
    for p in paths:
        if p and Path(p).exists(): return str(p)
    return None

crime_path = pick(CRIME_CANDS)
pop_path   = pick(POP_CANDS)
if not crime_path: raise FileNotFoundError("âŒ CRIME CSV bulunamadÄ± (fr_crime_02.csv / sf_crime_02.csv / fr_crime.csv / sf_crime.csv).")
if not pop_path:   raise FileNotFoundError("âŒ POPULATION CSV bulunamadÄ± (sf_population.csv).")
log(f"ğŸ“¥ crime: {crime_path}")
log(f"ğŸ“¥ population: {pop_path}")

# ============================== Read (STRING!) ==============================
crime = pd.read_csv(crime_path, low_memory=False, dtype=str)
pop   = pd.read_csv(pop_path,   low_memory=False, dtype=str)

crime_geoid_col = _find_geoid_col(crime)
if not crime_geoid_col: raise RuntimeError("SuÃ§ veri setinde GEOID kolonu yok.")
pop_geoid_col = _find_geoid_col(pop)
if not pop_geoid_col:  raise RuntimeError("NÃ¼fus CSVâ€™de GEOID kolonu yok.")
pop_val_col   = _find_population_col(pop, FORCE_POP_COL)
if not pop_val_col:    raise RuntimeError("NÃ¼fus CSVâ€™de nÃ¼fus deÄŸer kolonu yok (population/B01003_001E/estimate/...).")

crime_len = _mode_len(_digits_only(crime[crime_geoid_col]))
pop_len   = _mode_len(_digits_only(pop[pop_geoid_col]))
log(f"[info] crime GEO lenâ‰ˆ{crime_len} | pop GEO lenâ‰ˆ{pop_len} | join_len={JOIN_LEN} (tract)")
log(f"[info] pop_val_col={pop_val_col!r}")

# ============================== Prepare POP ==============================
pp0 = pop[[pop_geoid_col, pop_val_col]].copy()
pp0["_key"] = _key(pp0[pop_geoid_col], JOIN_LEN)
pp0["population"] = _num(pp0[pop_val_col]).fillna(0)

# TeÅŸhis: Prefiks daÄŸÄ±lÄ±mÄ± (ilk 5 hane)
try:
    pref_counts = (pp0["_key"].str[:5].value_counts().head(12))
    log("[diag] POP _key ilk5 prefiks (top-12):")
    for k, v in pref_counts.items():
        log(f"   â€¢ {k}: {v}")
except Exception as _e:
    log(f"[diag] Prefiks sayÄ±mÄ± atlandÄ±: {_e}")

pp = pp0

# Opsiyonel: SF prefiksi ile filtre (gÃ¼rÃ¼ltÃ¼yÃ¼ azaltÄ±r)
if SF_PREFIX:
    before = len(pp)
    pp = pp[pp["_key"].str.startswith(SF_PREFIX)]
    log(f"[info] POP SF filtresi: prefix={SF_PREFIX} | {before:,} â†’ {len(pp):,}")
    # Otomatik geri dÃ¶nÃ¼ÅŸ: eÄŸer filtre hepsini sildiyse, filtreyi kaldÄ±r (pp0'a dÃ¶n)
    if len(pp) == 0 and before > 0:
        log("âš ï¸ SF_PREFIX filtresi tÃ¼m nÃ¼fusu eledi. Otomatik olarak filtresiz moda dÃ¶nÃ¼yorum.")
        pp = pp0.copy()

# Crosswalk (opsiyonel): varsa uygula (2010â†”2020 dÃ¶nÃ¼ÅŸÃ¼mÃ¼)
pp = _apply_crosswalk_if_provided(pp, key_col="_key", join_len=JOIN_LEN)

# Pop seviyesi tract Ã¼stÃ¼ ise 11'e aggregate (sum)
pop_len_checked = _mode_len(_digits_only(pop[pop_geoid_col]))
if pop_len_checked > JOIN_LEN:
    pp = pp.groupby("_key", as_index=False)["population"].sum()
else:
    pp = pp[["_key","population"]].drop_duplicates("_key", keep="last")

# ============================== Prepare CRIME ==============================
cc = crime.copy()
cc["_key"] = _key(cc[crime_geoid_col], JOIN_LEN)

# --- TeÅŸhis: Anahtar kÃ¼meleri ve kesiÅŸim ---
left_keys  = set(cc["_key"].unique())
right_keys = set(pp["_key"].unique())
inter      = left_keys & right_keys
log(f"[debug] left_keys={len(left_keys):,} | right_keys={len(right_keys):,} | intersection={len(inter):,}")

if len(inter) == 0:
    samp_left  = list(sorted(left_keys))[:5]
    samp_right = list(sorted(right_keys))[:5]
    log(f"[debug] Ã¶rnek left keys:  {samp_left}")
    log(f"[debug] Ã¶rnek right keys: {samp_right}")
    log("âš ï¸ HiÃ§ eÅŸleÅŸme yok: Muhtemelen GEOID scientific-notation / vintaj (2010â†”2020) farkÄ± veya SF dÄ±ÅŸÄ± pop kaynaÄŸÄ±.")

# ============================== Merge & GEOID TemizliÄŸi ==============================
out = cc.merge(pp, how="left", on="_key")

# TÃ¼m GEOID tÃ¼revlerini at ve en baÅŸa 11 hanelik string GEOID koy
geoid_like_cols = [c for c in out.columns if c.lower().startswith("geoid")]
out.drop(columns=[c for c in geoid_like_cols if c != "_key"], errors="ignore", inplace=True)

# Tek resmi GEOID sÃ¼tunu:
out.insert(0, "GEOID", out["_key"].astype("string"))
out.drop(columns=["_key"], inplace=True)

# Tip gÃ¼venliÄŸi: GEOID -> string (11 hane)
out["GEOID"] = out["GEOID"].astype("string")

# Ek gÃ¼vence: tÃ¼m GEOID'ler 11 hane mi?
bad = out["GEOID"].fillna("").str.fullmatch(r"\d{11}") == False
if bad.any():
    n_bad = int(bad.sum())
    log(f"âš ï¸ UyarÄ±: {n_bad} satÄ±rda GEOID 11 hane deÄŸil (Ã¶rn: {out.loc[bad, 'GEOID'].head(3).tolist()})")

# ============================== Save ==============================
Path(CRIME_OUTPUT).parent.mkdir(parents=True, exist_ok=True)
# CSV yazarken sayÄ±larÄ± tÄ±rnak iÃ§ine alma; ama GEOID zaten string olduÄŸu iÃ§in .0 olmaz.
out.to_csv(CRIME_OUTPUT, index=False, na_rep="")

# ============================== Summary Logs ==============================
log(f"âœ… Kaydedildi â†’ {CRIME_OUTPUT}")
try:
    null_rate = out["population"].isna().mean()
    match_rate = 1.0 - null_rate
    log(f"ğŸ“Š satÄ±r: crime={len(crime):,} | pop={len(pp):,} | out={len(out):,}")
    log(f"ğŸ”— match_rate={match_rate:.2%} | population NaN oranÄ±={null_rate:.2%}")
    with pd.option_context("display.max_columns", 60, "display.width", 1600):
        log(out[["GEOID","population"]].head(10).to_string(index=False))
except Exception as e:
    log(f"â„¹ï¸ Ã–nizleme atlandÄ±: {e}")
