#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# update_bus_daily.py â€” daily_crime_03.csv + (sf_bus_stops_with_geoid.csv, blocks GeoJSON)
#                      â†’ daily_crime_04.csv (bus_stop_count, distance_to_bus, *_range)

from __future__ import annotations
import os
from pathlib import Path

import numpy as np
import pandas as pd
import geopandas as gpd
from scipy.spatial import cKDTree

pd.options.mode.copy_on_write = True

# ========= helpers =========
def log(msg: str): print(msg, flush=True)
def ensure_parent(path: str): Path(path).parent.mkdir(parents=True, exist_ok=True)

DEFAULT_GEOID_LEN = int(os.getenv("GEOID_LEN", "11"))
def normalize_geoid(s: pd.Series, L: int = DEFAULT_GEOID_LEN) -> pd.Series:
    x = s.astype(str).str.extract(r"(\d+)", expand=False)
    return x.str[:L].str.zfill(L)

def freedman_diaconis_bin_count(data: np.ndarray, max_bins: int = 10) -> int:
    data = np.asarray(data)
    if len(data) < 2 or np.all(data == data[0]):
        return 1
    q75, q25 = np.percentile(data, [75, 25])
    iqr = q75 - q25
    if iqr == 0:
        return min(max_bins, max(2, int(np.sqrt(len(data)))))
    bw = 2 * iqr / (len(data) ** (1 / 3))
    if bw <= 0:
        return min(max_bins, max(2, int(np.sqrt(len(data)))))
    return max(2, min(max_bins, int(np.ceil((data.max() - data.min()) / bw))))

def safe_save_csv(df: pd.DataFrame, path: str):
    ensure_parent(path)
    tmp = path + ".tmp"
    df.to_csv(tmp, index=False)
    os.replace(tmp, path)
    log(f"ðŸ’¾ Kaydedildi: {path} (satÄ±r={len(df):,}, sÃ¼tun={df.shape[1]})")

# ========= config (indirimsiz) =========
BASE_DIR = Path(os.getenv("CRIME_DATA_DIR", "crime_prediction_data")); BASE_DIR.mkdir(parents=True, exist_ok=True)

# IO
DAILY_IN   = Path(os.getenv("DAILY_IN",  str(BASE_DIR / "daily_crime_03.csv")))
DAILY_OUT  = Path(os.getenv("DAILY_OUT", str(BASE_DIR / "daily_crime_04.csv")))

# Canonical BUS cache (GEOID eÅŸlenmiÅŸ duraklar)
BUS_CANON  = Path(os.getenv("BUS_CANON_RAW", str(BASE_DIR / "sf_bus_stops_with_geoid.csv")))

# Blocks GeoJSON (centroid â†’ en yakÄ±n durak mesafesi iÃ§in)
BLOCKS_CANDIDATES = [
    Path(os.getenv("SF_BLOCKS_GEOJSON", str(BASE_DIR / "sf_census_blocks_with_population.geojson"))),
    Path("sf_census_blocks_with_population.geojson"),
]

# ========= 1) crime oku =========
if not DAILY_IN.exists():
    raise FileNotFoundError(f"âŒ Girdi yok: {DAILY_IN}")
crime = pd.read_csv(DAILY_IN, low_memory=False)
if "GEOID" not in crime.columns:
    raise KeyError("âŒ daily_crime_03.csv iÃ§inde 'GEOID' yok.")
crime["GEOID"] = normalize_geoid(crime["GEOID"], DEFAULT_GEOID_LEN)
crime_geoids = pd.Series(crime["GEOID"].unique(), name="GEOID")
log(f"ðŸ“¥ daily_crime_03.csv okundu â€” satÄ±r={len(crime):,}, uniq GEOID={crime_geoids.size:,}")

# ========= 2) bus cache oku (indirimsiz) =========
if not BUS_CANON.exists():
    raise FileNotFoundError(f"âŒ BUS cache yok: {BUS_CANON}\n"
                            f"Bu dosya aylÄ±k iÅŸte Ã¼retilmeli: sf_bus_stops_with_geoid.csv")
bus = pd.read_csv(BUS_CANON, low_memory=False)
# beklenen: en azÄ±ndan stop_lat/stop_lon ya da lat/lon ve GEOID (tercihen)
lat_col = next((c for c in ["stop_lat","latitude","lat","y"] if c in bus.columns), None)
lon_col = next((c for c in ["stop_lon","longitude","long","x"] if c in bus.columns), None)
if lat_col is None or lon_col is None:
    raise KeyError("âŒ BUS cache iÃ§inde lat/lon benzeri kolonlar yok (stop_lat/stop_lon vb.).")

bus["stop_lat"] = pd.to_numeric(bus[lat_col], errors="coerce")
bus["stop_lon"] = pd.to_numeric(bus[lon_col], errors="coerce")
bus = bus.dropna(subset=["stop_lat","stop_lon"]).copy()

if "GEOID" in bus.columns:
    bus["GEOID"] = normalize_geoid(bus["GEOID"], DEFAULT_GEOID_LEN)

log(f"ðŸšŒ BUS cache okundu â€” satÄ±r={len(bus):,}, GEOID kolonlu={ 'GEOID' in bus.columns }")

# ========= 3) Blocks GeoJSON bul =========
blocks_path = next((p for p in BLOCKS_CANDIDATES if p and p.exists()), None)
if blocks_path is None:
    raise FileNotFoundError("âŒ Blocks GeoJSON bulunamadÄ± (sf_census_blocks_with_population.geojson).")

gdf_blocks = gpd.read_file(blocks_path)
gcol = "GEOID" if "GEOID" in gdf_blocks.columns else next(
    (c for c in gdf_blocks.columns if str(c).upper().startswith("GEOID")), None
)
if not gcol:
    raise KeyError("âŒ Blocks GeoJSON iÃ§inde GEOID benzeri kolon yok.")
gdf_blocks["GEOID"] = normalize_geoid(gdf_blocks[gcol], DEFAULT_GEOID_LEN)
if gdf_blocks.crs is None:
    gdf_blocks.set_crs("EPSG:4326", inplace=True)
elif str(gdf_blocks.crs).lower() not in ("epsg:4326","wgs84","wgs 84"):
    gdf_blocks = gdf_blocks.to_crs(epsg=4326)

# ========= 4) BUS â†’ GEOID sayÄ±mÄ± =========
if "GEOID" not in bus.columns or bus["GEOID"].isna().all():
    # GEOID yoksa: nokta â†’ polygon sjoin ile atayÄ±p sonra say
    gdf_bus = gpd.GeoDataFrame(
        bus,
        geometry=gpd.points_from_xy(bus["stop_lon"], bus["stop_lat"]),
        crs="EPSG:4326"
    )
    try:
        gdf_bus = gpd.sjoin(gdf_bus, gdf_blocks[["GEOID","geometry"]], how="left", predicate="within")
    except Exception:
        gdf_bus = gpd.sjoin_nearest(gdf_bus, gdf_blocks[["GEOID","geometry"]], how="left", max_distance=5)
    gdf_bus = gdf_bus.drop(columns=["index_right"], errors="ignore")
    bus_geo = pd.DataFrame(gdf_bus.drop(columns=["geometry"], errors="ignore"))
else:
    bus_geo = bus.copy()

bus_geo["GEOID"] = normalize_geoid(bus_geo["GEOID"], DEFAULT_GEOID_LEN)
bus_count = (
    bus_geo.dropna(subset=["GEOID"])
           .groupby("GEOID", as_index=False)
           .agg(bus_stop_count=("stop_lat", "size"))
)

# ========= 5) distance_to_bus (m) =========
gdf_blocks_xy = gdf_blocks[["GEOID","geometry"]].copy().to_crs(3857)
gdf_blocks_xy["cx"] = gdf_blocks_xy.geometry.centroid.x
gdf_blocks_xy["cy"] = gdf_blocks_xy.geometry.centroid.y

gdf_bus_xy = gpd.GeoDataFrame(
    bus_geo.dropna(subset=["stop_lat","stop_lon"])[["stop_lat","stop_lon"]].copy(),
    geometry=gpd.points_from_xy(bus_geo.dropna(subset=["stop_lat","stop_lon"])["stop_lon"],
                                bus_geo.dropna(subset=["stop_lat","stop_lon"])["stop_lat"]),
    crs="EPSG:4326"
).to_crs(3857)

if len(gdf_bus_xy) == 0:
    bus_dist = gdf_blocks_xy[["GEOID"]].copy()
    bus_dist["distance_to_bus"] = np.nan
else:
    bus_coords = np.vstack([gdf_bus_xy.geometry.x.values, gdf_bus_xy.geometry.y.values]).T
    tree = cKDTree(bus_coords)
    centroids = np.vstack([gdf_blocks_xy["cx"].values, gdf_blocks_xy["cy"].values]).T
    distances, _ = tree.query(centroids, k=1)
    bus_dist = gdf_blocks_xy[["GEOID"]].copy()
    bus_dist["distance_to_bus"] = distances.astype(float)

# ========= 6) feature tablosu + binler =========
bus_feat = bus_dist.merge(bus_count, on="GEOID", how="left")
bus_feat["bus_stop_count"] = bus_feat["bus_stop_count"].fillna(0).astype(int)
bus_feat["GEOID"] = normalize_geoid(bus_feat["GEOID"], DEFAULT_GEOID_LEN)

# Sadece crimeâ€™da olan GEOIDâ€™leri tut
bus_feat = bus_feat.merge(crime_geoids.to_frame(), on="GEOID", how="right")

# Binleme (opsiyonel)
d = bus_feat["distance_to_bus"].replace([np.inf,-np.inf], np.nan).dropna()
if len(d) >= 2 and d.max() > d.min():
    n_bins = freedman_diaconis_bin_count(d.to_numpy(), max_bins=10)
    _, edges = pd.qcut(d, q=n_bins, retbins=True, duplicates="drop")
    labels = [f"{int(edges[i])}â€“{int(edges[i+1])}m" for i in range(len(edges)-1)]
    bus_feat["distance_to_bus_range"] = pd.cut(bus_feat["distance_to_bus"], bins=edges,
                                               labels=labels, include_lowest=True)
else:
    bus_feat["distance_to_bus_range"] = pd.Series(["0â€“0m"] * len(bus_feat))

cnt = bus_feat["bus_stop_count"].fillna(0)
if cnt.nunique() > 1:
    n_c_bins = freedman_diaconis_bin_count(cnt.to_numpy(), max_bins=8)
    _, c_edges = pd.qcut(cnt, q=n_c_bins, retbins=True, duplicates="drop")
    c_labels = [f"{int(c_edges[i])}â€“{int(c_edges[i+1])}" for i in range(len(c_edges)-1)]
    bus_feat["bus_stop_count_range"] = pd.cut(cnt, bins=c_edges, labels=c_labels, include_lowest=True)
else:
    bus_feat["bus_stop_count_range"] = pd.Series([f"{int(cnt.min())}â€“{int(cnt.max())}"] * len(cnt))

bus_feat = bus_feat.sort_values("GEOID").drop_duplicates("GEOID", keep="first")
assert bus_feat["GEOID"].is_unique, "BUS: GEOID unique olmalÄ±"

# ========= 7) crime ile merge =========
before = crime.shape
crime = crime.merge(bus_feat, on="GEOID", how="left", validate="many_to_one")
crime["bus_stop_count"] = crime["bus_stop_count"].fillna(0).astype(int)
log(f"ðŸ”— CRIME â¨¯ BUS: {before} â†’ {crime.shape}")

# ========= 8) yaz =========
safe_save_csv(crime, str(DAILY_OUT))
try:
    log(crime.head(5).to_string(index=False))
except Exception:
    pass
