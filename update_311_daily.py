#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# update_311_daily.py â€” Input: daily_crime_01.csv  â†’ Output: daily_crime_02.csv
from __future__ import annotations
import os
from pathlib import Path
from datetime import datetime
import pandas as pd

# ====== IO & AYARLAR ======
SAVE_DIR        = Path(os.getenv("CRIME_DATA_DIR", "crime_prediction_data"))
DAILY_IN        = Path(os.getenv("DAILY_IN",  str(SAVE_DIR / "daily_crime_01.csv")))
DAILY_OUT       = Path(os.getenv("DAILY_OUT", str(SAVE_DIR / "daily_crime_02.csv")))

# 311 giriÅŸ adaylarÄ±
FR_311_DAILY_IN = Path(os.getenv("FR_311_DAILY_IN", ""))  # varsa doÄŸrudan gÃ¼nlÃ¼k (GEOIDÃ—date)
AGG_311_NAME    = os.getenv("AGG_311_NAME", "sf_311_last_5_years.csv")  # 3-saatlik Ã¶zet (GEOIDÃ—dateÃ—hour_range)
AGG_311_CANDIDATES = [
    SAVE_DIR / AGG_311_NAME,
    Path("./") / AGG_311_NAME,
    SAVE_DIR / "sf_311_last_5_years_3h.csv",
]

def log(msg: str): print(msg, flush=True)
def _abs(p: Path) -> Path: return p.expanduser().resolve()

def _read_csv(path: Path) -> pd.DataFrame:
    p = _abs(path)
    if not p.exists():
        raise FileNotFoundError(f"âŒ Dosya yok: {p}")
    df = pd.read_csv(p, low_memory=False)
    log(f"ðŸ“– Okundu: {p}  ({len(df):,}Ã—{df.shape[1]})")
    return df

def _safe_write_csv(df: pd.DataFrame, path: Path) -> None:
    p = _abs(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    tmp = p.with_suffix(".tmp.csv")
    df.to_csv(tmp, index=False)
    tmp.replace(p)
    log(f"ðŸ’¾ YazÄ±ldÄ±: {p}  ({len(df):,}Ã—{df.shape[1]})")

def _to_date(s: pd.Series) -> pd.Series:
    return pd.to_datetime(s, errors="coerce").dt.date

def _norm_geoid(s: pd.Series, L: int = 11) -> pd.Series:
    x = s.astype(str).str.extract(r"(\d+)", expand=False)
    return x.str[:L].str.zfill(L)

def _find_existing(paths: list[Path]) -> Path | None:
    for p in paths:
        if p and p.exists():
            return p
    return None

def load_311_daily() -> pd.DataFrame:
    """
    1) FR_311_DAILY_IN varsa doÄŸrudan oku (GEOIDÃ—date, iÃ§erikte 311 gÃ¼nlÃ¼k sayÄ± olmalÄ±)
    2) Yoksa 3-saatlik Ã¶zet dosyasÄ±nÄ± bul â†’ GEOIDÃ—date bazÄ±nda SUM â†’ daily Ã¼ret
    """
    # 1) DoÄŸrudan gÃ¼nlÃ¼k varsa
    if FR_311_DAILY_IN and _abs(FR_311_DAILY_IN).exists():
        df = _read_csv(FR_311_DAILY_IN)
        # kolon adÄ± uyumlarÄ±
        if "311_request_count_daily" not in df.columns:
            # farklÄ± bir ad kullanÄ±lmÄ±ÅŸ olabilir â†’ mantÄ±klÄ± adaylar
            cand = [c for c in df.columns if "daily" in c and "311" in c]
            if cand:
                df = df.rename(columns={cand[0]: "311_request_count_daily"})
        # tarih kolonunu normalize et
        if "date" not in df.columns:
            for c in ("event_date", "dt", "day"):
                if c in df.columns:
                    df["date"] = df[c]
                    break
        df["date"] = _to_date(df["date"])
        if "GEOID" in df.columns:
            df["GEOID"] = _norm_geoid(df["GEOID"])
        # eksik sayaÃ§ â†’ 0
        if "311_request_count_daily" not in df.columns:
            df["311_request_count_daily"] = 0
        return df[["GEOID","date","311_request_count_daily"]].copy()

    # 2) 3-saatlik Ã¶zetten gÃ¼nlÃ¼k Ã¼ret
    src = _find_existing(AGG_311_CANDIDATES)
    if src is None:
        log("â„¹ï¸ 311 Ã¶zet bulunamadÄ±; gÃ¼nlÃ¼k 311 sÄ±fÄ±r kabul edilecek.")
        return pd.DataFrame(columns=["GEOID","date","311_request_count_daily"])

    df = _read_csv(src)
    # beklenen kolonlar: GEOID, date, hour_range, 311_request_count
    if "date" not in df.columns:
        raise SystemExit("âŒ 311 Ã¶zetinde 'date' yok.")
    if "311_request_count" not in df.columns:
        # bazÄ± pipeline'larda isimlenme farklÄ± olabilir
        cand = [c for c in df.columns if c.lower() in ("count","requests","n")]
        if not cand:
            # saatlik satÄ±r adedinden kur
            df["311_request_count"] = 1
        else:
            df = df.rename(columns={cand[0]: "311_request_count"})
    if "GEOID" in df.columns:
        df["GEOID"] = _norm_geoid(df["GEOID"])
    df["date"] = _to_date(df["date"])
    daily = (df.groupby(["GEOID","date"], dropna=False)["311_request_count"]
               .sum()
               .reset_index(name="311_request_count_daily"))
    return daily

def main() -> int:
    log("ðŸš€ update_311_daily.py")
    log(f"ðŸ”§ DAILY_IN : {_abs(DAILY_IN)}")
    log(f"ðŸ”§ DAILY_OUT: {_abs(DAILY_OUT)}")

    # 1) daily_crime_01.csv
    crime = _read_csv(DAILY_IN)
    # tarih kolon adÄ±: date / event_date â†’ date'e indir
    if "date" not in crime.columns:
        for c in ("event_date","dt","day"):
            if c in crime.columns:
                crime["date"] = crime[c]
                break
    crime["date"] = _to_date(crime["date"])
    if "GEOID" in crime.columns:
        crime["GEOID"] = _norm_geoid(crime["GEOID"])

    # 2) 311 gÃ¼nlÃ¼k
    d311 = load_311_daily()

    # 3) Merge (GEOID + date)
    keys = ["GEOID","date"]
    before = crime.shape
    out = crime.merge(d311, on=keys, how="left")
    out["311_request_count_daily"] = pd.to_numeric(out["311_request_count_daily"], errors="coerce").fillna(0).astype("int32")
    log(f"ðŸ”— Join: {before} â†’ {out.shape}")

    # 4) Ä°z bilgisi
    out["daily_311_snapshot_at"] = datetime.utcnow().isoformat(timespec="seconds") + "Z"

    # 5) Yaz
    _safe_write_csv(out, DAILY_OUT)

    # 6) KÄ±sa Ã¶nizleme
    try:
        log(out.head(8).to_string(index=False))
    except Exception:
        pass
    return 0

if __name__ == "__main__":
    raise SystemExit(main())
