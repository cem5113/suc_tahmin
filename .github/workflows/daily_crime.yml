name: Daily Crime

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
  workflow_dispatch:

permissions:
  contents: read
  actions: read

concurrency:
  group: daily-crime-${{ github.ref }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash

env:
  # K√ñK
  CRIME_DATA_DIR: ${{ github.workspace }}

  WX_LOCATION: "paris"
  WX_UNIT: "metric"
  GEOID_LEN: "11"

  # Artifact (ZIP) varsayƒ±lan ad/konum
  ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
  ARTIFACT_DIR: artifact

  # √áƒ±ktƒ± klas√∂r√º ve fallback dizinleri
  FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
  FALLBACK_DIRS: ${{ github.workspace }}/crime_prediction_data,${{ github.workspace }}

  # G√ºnl√ºk dosyalar
  FR_GRID_DAILY_IN:  crime_prediction_data/fr_crime_grid_daily.csv
  FR_GRID_DAILY_OUT: crime_prediction_data/fr_crime_grid_daily.csv
  FR_EVENTS_DAILY_IN:  crime_prediction_data/fr_crime_events_daily.csv
  FR_EVENTS_DAILY_OUT: crime_prediction_data/fr_crime_events_daily.csv

  # NEIGH (varsayƒ±lan; adƒ±m i√ßinde artifact √∂ncelikli PICK yapƒ±lacak)
  NEIGH_FILE: ${{ github.workspace }}/neighbors.csv

  # 911 varsayƒ±lanlarƒ±
  FR_911_DATE_COL: "incident_datetime"
  FR_911_GEOID_COL: "GEOID"
  FR_911_WINSOR_Q: "0"
  FR_CAT_TOPK: "8"
  FR_911_EMA_ALPHAS: "0.3,0.5"

  # 311 varsayƒ±lanlarƒ±
  FR_311_DATE_COL: "date"
  FR_311_GEOID_COL: "GEOID"
  FR_311_WINSOR_Q: "0"
  FR_311_EMA_ALPHAS: "0.3,0.6"

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest

    steps:
      - name: Debug trigger
        run: |
          set -euo pipefail
          echo "event=${{ github.event_name }}"
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            echo "from=${{ github.event.workflow_run.name }}"
            echo "conclusion=${{ github.event.workflow_run.conclusion }}"
            echo "head_branch=${{ github.event.workflow_run.head_branch }}"
          fi

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: System deps for geo stack (rtree/libspatialindex)
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y libspatialindex-dev unzip

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python dependencies
        run: |
          set -euo pipefail
          python -m pip install -U pip wheel setuptools pyarrow pandas
          pip install numpy scikit-learn pyproj shapely geopandas fiona rtree

      # ===== UPSTREAM ARTIFACT ƒ∞NDƒ∞RME =====
      - name: Download upstream artifact (from triggering run)
        if: ${{ github.event_name == 'workflow_run' }}
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact
          if_no_artifact_found: warn

      - name: Download upstream artifact (latest successful, when manual)
        if: ${{ github.event_name != 'workflow_run' }}
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: full_pipeline.yml
          branch: main
          name: sf-crime-pipeline-output
          path: artifact
          if_no_artifact_found: warn

      - name: Unzip artifact if present
        run: |
          set -euo pipefail
          if [ -f "${ARTIFACT_ZIP}" ]; then
            unzip -o "${ARTIFACT_ZIP}" -d "${ARTIFACT_DIR}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi

      - name: List artifact tree (sanity)
        run: |
          set -euo pipefail
          echo "== artifact contents =="
          find artifact -maxdepth 6 -type f | sed -n '1,200p' || true

      # ===== (0) FR daily GRID/EVENTS: sf_crime.csv KAYNAƒûI ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (0) Build FR daily (GRID & EVENTS) + Y_label
        run: |
          set -euo pipefail
          echo "üì¶ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          mkdir -p "${CRIME_DATA_DIR}/crime_prediction_data"

          # sf_crime.csv adaylarƒ± ‚Äî artifact √∂ncelikli
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/sf_crime.csv"
            "${CRIME_DATA_DIR}/artifact/sf_crime.csv"
            "${CRIME_DATA_DIR}/sf_crime.csv"
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_crime.csv"
            "sf_crime.csv"
          )
          FR_EVENTS_PATH=""
          for p in "${CANDIDATES[@]}"; do
            if [ -f "$p" ]; then FR_EVENTS_PATH="$p"; break; fi
          done
          if [ -z "$FR_EVENTS_PATH" ]; then
            echo "‚ùå sf_crime.csv bulunamadƒ±"; exit 1
          fi

          export FR_EVENTS_PATH
          export FR_OUT_EVENTS="${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_events_daily.csv"
          export FR_OUT_GRID="${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_grid_daily.csv"
          export FR_MIN_YEARS="5"
          export FR_DATE_COL="incident_datetime"
          export FR_GEOID_COL="GEOID"
          export FR_ID_COL="id"

          echo "üîß FR_EVENTS_PATH: ${FR_EVENTS_PATH}"
          python -u update_crime_daily.py

          echo "---- GRID head ----";   head -n 5 "${FR_OUT_GRID}"   || true
          echo "---- EVENTS head ----"; head -n 5 "${FR_OUT_EVENTS}" || true

      # ===== (1) 911 ENRICH ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ KAYNAK SE√áƒ∞Mƒ∞ =====
      - name: (1) 911 ‚Üí enrich GRID & EVENTS (artifact-first)
        env:
          CRIME_DATA_DIR:      ${{ env.CRIME_DATA_DIR }}
          FR_OUTPUT_DIR:       ${{ env.FR_OUTPUT_DIR }}
          FR_EVENTS_DAILY_OUT: ${{ env.FR_EVENTS_DAILY_OUT }}
          FR_GRID_DAILY_OUT:   ${{ env.FR_GRID_DAILY_OUT }}
        run: |
          set -euo pipefail
          echo "== 911 kaynaƒüƒ± se√ßimi (artifact-first) =="
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/sf_911_last_5_year_y.csv"
            "${GITHUB_WORKSPACE}/artifact/sf_911_last_5_year.csv"
            "${CRIME_DATA_DIR}/artifact/sf_911_last_5_year_y.csv"
            "${CRIME_DATA_DIR}/artifact/sf_911_last_5_year.csv"
            "${CRIME_DATA_DIR}/sf_911_last_5_year_y.csv"
            "${CRIME_DATA_DIR}/sf_911_last_5_year.csv"
            "sf_911_last_5_year_y.csv"
            "sf_911_last_5_year.csv"
          )
          PICK=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { PICK="$p"; break; }
          done
          [ -z "$PICK" ] && { echo "‚ùå 911 CSV bulunamadƒ±."; exit 1; }
          export FR_911="$PICK"
          echo "‚úÖ 911 source: $FR_911"

          python -u update_911_daily.py

      # ===== (2) 311 ENRICH ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (2) 311 ‚Üí enrich GRID & EVENTS (artifact-first)
        env:
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
          FR_311_DATE_COL:  "${{ env.FR_311_DATE_COL }}"
          FR_311_GEOID_COL: "${{ env.FR_311_GEOID_COL }}"
          FR_311_WINSOR_Q:  "${{ env.FR_311_WINSOR_Q }}"
          FR_311_EMA_ALPHAS: "${{ env.FR_311_EMA_ALPHAS }}"
        run: |
          set -euo pipefail
          GRID="${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"
          EVTS="${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}"
          if [ ! -f "$GRID" ] || [ ! -f "$EVTS" ]; then
            echo "‚ö†Ô∏è daily grid/events yok ‚Üí 311 enrich atlanƒ±yor."
            exit 0
          fi
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/sf_311_last_5_years.csv"
            "${CRIME_DATA_DIR}/artifact/sf_311_last_5_years.csv"
            "${CRIME_DATA_DIR}/sf_311_last_5_years.csv"
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_311_last_5_years.csv"
            "sf_311_last_5_years.csv"
          )
          PICK=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { PICK="$p"; break; }
          done
          if [ -z "$PICK" ]; then
            echo "‚ÑπÔ∏è 311 bulunamadƒ± ‚Üí adƒ±m atlanƒ±yor."
            exit 0
          fi
          echo "‚úÖ 311 kaynaƒüƒ±: $PICK"
          export FR_311_DAILY_IN="$PICK"

          PYFILE=""
          [ -f "./update_311_daily.py" ] && PYFILE="./update_311_daily.py"
          [ -z "$PYFILE" ] && [ -f "./scripts/update_311_daily.py" ] && PYFILE="./scripts/update_311_daily.py"
          [ -z "$PYFILE" ] && { echo "‚ùå 311 script'i yok"; exit 67; }
          python -u "$PYFILE"

      # ===== (3) BUS ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (3) Bus stops -> enrich GRID & EVENTS (artifact-first)
        run: |
          set -euo pipefail
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/sf_bus_stops_with_geoid.csv"
            "${CRIME_DATA_DIR}/artifact/sf_bus_stops_with_geoid.csv"
            "${CRIME_DATA_DIR}/sf_bus_stops_with_geoid.csv"
            "sf_bus_stops_with_geoid.csv"
          )
          BUS_SOURCE=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { BUS_SOURCE="$p"; break; }
          done
          [ -z "$BUS_SOURCE" ] && { echo "‚ÑπÔ∏è Bus stops yok ‚Üí atlanƒ±yor"; exit 0; }
          export BUS_CANON_RAW="$BUS_SOURCE"
          echo "‚úÖ BUS source: $BUS_CANON_RAW"
          python -u update_bus_daily.py

      # ===== (4) TRAIN ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (4) Train stops -> enrich GRID & EVENTS (artifact-first)
        run: |
          set -euo pipefail
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/sf_train_stops_with_geoid.csv"
            "${CRIME_DATA_DIR}/artifact/sf_train_stops_with_geoid.csv"
            "${CRIME_DATA_DIR}/sf_train_stops_with_geoid.csv"
            "sf_train_stops_with_geoid.csv"
          )
          TRAIN_SOURCE=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { TRAIN_SOURCE="$p"; break; }
          done
          [ -z "$TRAIN_SOURCE" ] && { echo "‚ÑπÔ∏è Train stops yok ‚Üí atlanƒ±yor"; exit 0; }
          export TRAIN_STOPS_NAME="$TRAIN_SOURCE"
          echo "‚úÖ TRAIN source: $TRAIN_STOPS_NAME"
          python -u update_train_daily.py

      # ===== (5) POI ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (5) POI -> enrich GRID & EVENTS (artifact-first)
        run: |
          set -euo pipefail
          # POI GeoJSON
          POI_GJ=""
          for p in \
            "${GITHUB_WORKSPACE}/artifact/sf_pois.geojson" \
            "${CRIME_DATA_DIR}/artifact/sf_pois.geojson" \
            "${CRIME_DATA_DIR}/sf_pois.geojson" \
            "sf_pois.geojson"; do
            [ -f "$p" ] && { POI_GJ="$p"; break; }
          done
          # Cleaned CSV
          POI_CLEAN=""
          for p in \
            "${GITHUB_WORKSPACE}/artifact/sf_pois_cleaned_with_geoid.csv" \
            "${CRIME_DATA_DIR}/artifact/sf_pois_cleaned_with_geoid.csv" \
            "${CRIME_DATA_DIR}/sf_pois_cleaned_with_geoid.csv" \
            "sf_pois_cleaned_with_geoid.csv"; do
            [ -f "$p" ] && { POI_CLEAN="$p"; break; }
          done
          # Blocks (n√ºfuslu)
          BLOCK_GJ=""
          for p in \
            "${GITHUB_WORKSPACE}/artifact/sf_census_blocks_with_population.geojson" \
            "${CRIME_DATA_DIR}/artifact/sf_census_blocks_with_population.geojson" \
            "${CRIME_DATA_DIR}/sf_census_blocks_with_population.geojson" \
            "sf_census_blocks_with_population.geojson"; do
            [ -f "$p" ] && { BLOCK_GJ="$p"; break; }
          done

          [ -z "$POI_GJ" ] && [ -z "$POI_CLEAN" ] && { echo "‚ÑπÔ∏è POI kaynaklarƒ± yok ‚Üí atlanƒ±yor"; exit 0; }

          export POI_GEOJSON_1="$POI_GJ"
          export POI_GEOJSON_2="$POI_GJ"
          export POI_CLEAN_CSV="$POI_CLEAN"
          export BLOCK_GEOJSON="$BLOCK_GJ"

          echo "‚úÖ POI_GEOJSON: ${POI_GEOJSON_1:-none}"
          echo "‚úÖ POI_CLEAN_CSV: ${POI_CLEAN_CSV:-none}"
          echo "‚úÖ BLOCK_GEOJSON: ${BLOCK_GEOJSON:-none}"
          python -u update_poi_daily.py

      # ===== (5.1) BLOCKS CENTROID ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (5.1) Build BLOCKS centroid CSV (artifact-first)
        run: |
          set -euo pipefail
          python - <<'PY'
          import os
          from pathlib import Path
          import pandas as pd, geopandas as gpd
          BASE = Path(os.environ["CRIME_DATA_DIR"])
          # artifact-first
          cand = [
            BASE/"artifact/sf_census_blocks_with_population.geojson",
            Path(os.getenv("GITHUB_WORKSPACE",""))/"artifact/sf_census_blocks_with_population.geojson",
            BASE/"sf_census_blocks_with_population.geojson",
            Path("sf_census_blocks_with_population.geojson"),
          ]
          INP = next((p for p in cand if p.exists()), None)
          if INP is None:
              print("‚ÑπÔ∏è BLOCKS geojson yok ‚Üí centroid √ºretimi atlandƒ±."); raise SystemExit(0)
          OUT = BASE/"sf_blocks_centroids.csv"
          gdf = gpd.read_file(INP).to_crs("EPSG:4326")
          if "GEOID" not in gdf.columns:
              raise ValueError("BLOCKS GeoJSON i√ßinde GEOID yok")
          gdf["GEOID"] = (
              gdf["GEOID"].astype(str).str.extract(r"(\d+)",expand=False)
              .fillna("").str.replace(" ","",regex=False).str.zfill(11).str[:11]
          )
          cent = gdf.dissolve(by="GEOID")["geometry"].centroid
          df=pd.DataFrame({"GEOID":cent.index,"centroid_lat":cent.y,"centroid_lon":cent.x})
          OUT.parent.mkdir(parents=True, exist_ok=True)
          df.to_csv(OUT,index=False)
          print(f"‚úÖ wrote {OUT} rows={len(df)}")
          PY

      # ===== (6) POLICE & GOV ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (6) Police & Government -> enrich GRID & EVENTS (artifact-first)
        run: |
          set -euo pipefail
          # Police
          POLICE=""
          for p in \
            "${GITHUB_WORKSPACE}/artifact/sf_police_stations.csv" \
            "${CRIME_DATA_DIR}/artifact/sf_police_stations.csv" \
            "${CRIME_DATA_DIR}/sf_police_stations.csv" \
            "sf_police_stations.csv"; do
            [ -f "$p" ] && { POLICE="$p"; break; }
          done
          # Gov
          GOV=""
          for p in \
            "${GITHUB_WORKSPACE}/artifact/sf_government_buildings.csv" \
            "${CRIME_DATA_DIR}/artifact/sf_government_buildings.csv" \
            "${CRIME_DATA_DIR}/sf_government_buildings.csv" \
            "sf_government_buildings.csv"; do
            [ -f "$p" ] && { GOV="$p"; break; }
          done
          # Blocks centroids
          BLOCKS="${CRIME_DATA_DIR}/sf_blocks_centroids.csv"
          [ ! -f "$BLOCKS" ] && { echo "‚ÑπÔ∏è blocks centroid yok ‚Üí atlanƒ±yor"; exit 0; }

          [ -z "$POLICE" ] && [ -z "$GOV" ] && { echo "‚ÑπÔ∏è police/gov yok ‚Üí atlanƒ±yor"; exit 0; }
          export POLICE_FILE="$POLICE"
          export GOV_FILE="$GOV"
          export BLOCKS_CSV="$BLOCKS"
          echo "‚úÖ POLICE: ${POLICE_FILE:-none}"
          echo "‚úÖ GOV: ${GOV_FILE:-none}"
          python -u update_police_gov_daily.py

      # ===== (7) WEATHER ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ (tarih-merge) =====
      - name: (7) Weather (date-merge) -> enrich GRID & EVENTS (artifact-first)
        run: |
          set -euo pipefail
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/sf_weather_5years.csv"
            "${CRIME_DATA_DIR}/artifact/sf_weather_5years.csv"
            "${CRIME_DATA_DIR}/sf_weather_5years.csv"
            "sf_weather_5years.csv"
          )
          WX=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { WX="$p"; break; }
          done
          [ -z "$WX" ] && { echo "‚ÑπÔ∏è weather yok ‚Üí atlanƒ±yor"; exit 0; }
          export WEATHER_FILE="$WX"
          echo "‚úÖ WEATHER source: $WEATHER_FILE"
          python -u update_weather_daily.py

      # ===== (8) NEIGHBORS ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (8) Neighbor windows (1/3/7d) -> enrich GRID & EVENTS (artifact-first)
        run: |
          set -euo pipefail
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/neighbors.csv"
            "${CRIME_DATA_DIR}/artifact/neighbors.csv"
            "${CRIME_DATA_DIR}/neighbors.csv"
            "neighbors.csv"
          )
          PICK=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { PICK="$p"; break; }
          done
          if [ -z "$PICK" ]; then
            echo "‚ÑπÔ∏è neighbors.csv yok ‚Üí kom≈üu enrich atlanƒ±yor."
            exit 0
          fi
          export NEIGH_FILE="$PICK"
          echo "‚úÖ NEIGH source: $NEIGH_FILE"
          python -u scripts/make_neighbors_daily.py

      # ===== (9) POPULATION ‚Äî ARTIFACT √ñNCELƒ∞KLƒ∞ =====
      - name: (9) Population -> enrich GRID & EVENTS (artifact-first)
        run: |
          set -euo pipefail
          CANDIDATES=(
            "${GITHUB_WORKSPACE}/artifact/sf_population.csv"
            "${CRIME_DATA_DIR}/artifact/sf_population.csv"
            "${CRIME_DATA_DIR}/sf_population.csv"
            "sf_population.csv"
          )
          POP=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { POP="$p"; break; }
          done
          if [ -z "$POP" ]; then
            echo "‚ÑπÔ∏è population yok ‚Üí atlanƒ±yor"
            exit 0
          fi
          export POP_FILE="$POP"
          echo "‚úÖ POP source: $POP_FILE"

          python - <<'PY'
          import os, pandas as pd
          base = os.environ["CRIME_DATA_DIR"]
          pop_path = os.environ["POP_FILE"]
          grid_path = os.path.join(base, os.environ["FR_GRID_DAILY_OUT"])
          evt_path  = os.path.join(base, os.environ["FR_EVENTS_DAILY_OUT"])

          pop = pd.read_csv(pop_path)
          pop["GEOID"] = (
              pop["GEOID"].astype(str).str.extract(r"(\d+)",expand=False)
              .str.zfill(11).str[:11]
          )

          def enrich(pth):
              if not os.path.exists(pth): return
              df = pd.read_csv(pth)
              if "GEOID" not in df.columns: return
              df["GEOID"] = (
                  df["GEOID"].astype(str).str.extract(r"(\d+)",expand=False)
                  .str.zfill(11).str[:11]
              )
              df = df.merge(pop[["GEOID","population"]], on="GEOID", how="left")
              df.to_csv(pth,index=False)
              print("‚úÖ enriched:",pth)

          enrich(grid_path)
          enrich(evt_path)
          PY

      - name: Final previews
        run: |
          set -euo pipefail
          echo "==== GRID (top 3 rows) ====";   head -n 3 "${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"   || true
          echo "==== EVENTS (top 3 rows) ===="; head -n 3 "${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}" || true
          echo "==== GRID columns ===="
          python - <<'PY'
          import pandas as pd, os
          p=os.path.join(os.getenv("CRIME_DATA_DIR"),os.getenv("FR_GRID_DAILY_OUT"))
          if os.path.exists(p):
              df=pd.read_csv(p, nrows=0); print("\n".join(df.columns))
          else:
              print("‚ö†Ô∏è GRID yok.")
          PY

      - name: Upload artifacts (GRID & EVENTS)
        uses: actions/upload-artifact@v4
        with:
          name: fr-daily-grid-events
          path: |
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_GRID_DAILY_OUT }}
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_EVENTS_DAILY_OUT }}
          if-no-files-found: warn

  patrol-fr:
    needs: run_fr
    if: ${{ needs.run_fr.result == 'success' }}
    runs-on: ubuntu-latest

    env:
      CRIME_DATA_DIR: ${{ github.workspace }}
      GRID_FILE: crime_prediction_data/fr_crime_grid_daily.csv
      EVENTS_FILE: crime_prediction_data/fr_crime_events_daily.csv
      PATROL_TOP_K: "25"
      PATROL_MIN_SPACING_M: "300"
      PATROL_OUT_CSV: "fr_patrol_plan.csv"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Download daily grid/events from previous job
        uses: actions/download-artifact@v4
        with:
          name: fr-daily-grid-events
          path: ${{ env.CRIME_DATA_DIR }}

      - name: Verify transferred files
        run: |
          set -euo pipefail
          echo "üì¶ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          ls -la "${CRIME_DATA_DIR}" || true
          ls -la "${CRIME_DATA_DIR}/crime_prediction_data" || true
          head -n 3 "${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_grid_daily.csv" || true
          head -n 3 "${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_events_daily.csv" || true

      - name: Install runtime Python deps
        run: |
          set -euo pipefail
          python -m pip install -U pip
          pip install pandas numpy

      - name: Run patrol planner (auto-locate grid; events fallback)
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          GRID_FILE:      ${{ env.GRID_FILE }}
          EVENTS_FILE:    ${{ env.EVENTS_FILE }}
          PATROL_TOP_K:   ${{ env.PATROL_TOP_K }}
          PATROL_OUT_CSV: ${{ env.PATROL_OUT_CSV }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys
          from pathlib import Path
          import pandas as pd

          base        = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data"))
          grid_hint   = os.environ.get("GRID_FILE","fr_crime_grid_daily.csv")
          events_hint = os.environ.get("EVENTS_FILE","fr_crime_events_daily.csv")
          k           = int(os.environ.get("PATROL_TOP_K","25"))
          out_csv     = base / os.environ.get("PATROL_OUT_CSV","fr_patrol_plan.csv")

          def locate(hint, fname):
              p = base / hint
              if p.exists(): return p
              m = list(base.rglob(fname))
              if m:
                  m.sort(key=lambda x: len(str(x)))
                  return m[-1]
              return None

          grid_fp   = locate(grid_hint,   "fr_crime_grid_daily.csv")
          events_fp = locate(events_hint, "fr_crime_events_daily.csv")

          if grid_fp and grid_fp.exists():
              df = pd.read_csv(grid_fp)
          elif events_fp and events_fp.exists():
              ev = pd.read_csv(events_fp)
              if ev.empty:
                  Path(out_csv).parent.mkdir(parents=True, exist_ok=True)
                  pd.DataFrame(columns=["GEOID","date","risk_score","Y_label","events_count"]).to_csv(out_csv, index=False)
                  sys.exit(0)
              for c in ["GEOID","date"]:
                  if c not in ev.columns:
                      print(f"‚ùå EVENTS zorunlu kolon yok: {c}", file=sys.stderr); sys.exit(3)
              ev["date"] = pd.to_datetime(ev["date"], errors="coerce").dt.date
              ev = ev.dropna(subset=["GEOID","date"])
              agg = ev.groupby(["GEOID","date"], as_index=False).size().rename(columns={"size":"events_count"})
              for c in ["n_911_day","n_911_last1d","n_911_last3d","n_911_last7d"]:
                  if c in ev.columns:
                      tmp = ev.groupby(["GEOID","date"], as_index=False)[c].max()
                      agg = agg.merge(tmp, on=["GEOID","date"], how="left")
              agg["Y_label"] = (agg["events_count"] > 0).astype("int8")
              df = agg
          else:
              print(f"‚ùå GRID & EVENTS bulunamadƒ±.\n- GRID: {base / grid_hint}\n- EVENTS: {base / events_hint}", file=sys.stderr)
              sys.exit(2)

          if df.empty:
              Path(out_csv).parent.mkdir(parents=True, exist_ok=True)
              pd.DataFrame(columns=["GEOID","date","risk_score","Y_label","events_count"]).to_csv(out_csv, index=False)
              sys.exit(0)

          df["date"] = pd.to_datetime(df["date"], errors="coerce")
          last_day = df["date"].dropna().max()
          if pd.isna(last_day):
              print("‚ùå Tarih alanƒ± hatalƒ±.", file=sys.stderr); sys.exit(4)
          today = df[df["date"]==last_day].copy()

          def safe_num(d, cols, default=0.0):
              for name in cols:
                  if name in d.columns:
                      return pd.to_numeric(d[name], errors="coerce").fillna(0)
              return pd.Series(default, index=d.index)

          events_series = safe_num(today, ["events_count","crime_count_day"], 0.0)
          nbor_24  = safe_num(today, ["neighbor_crime_24h","neighbor_crime_1d"], 0.0)
          nbor_72  = safe_num(today, ["neighbor_crime_72h","neighbor_crime_3d"], 0.0)
          nbor_7d  = safe_num(today, ["neighbor_crime_7d"], 0.0)
          n911_1d  = safe_num(today, ["n911_prev_1d","n_911_last1d"], 0.0)

          today["risk_score"] = events_series*1.0 + nbor_24*0.20 + nbor_72*0.10 + nbor_7d*0.05 + n911_1d*0.10

          agg_cols = {"risk_score":"max"}
          if "events_count" in today.columns: agg_cols["events_count"] = "max"
          elif "crime_count_day" in today.columns: agg_cols["crime_count_day"] = "max"
          if "Y_label" in today.columns: agg_cols["Y_label"] = "max"

          topk = (today.sort_values("risk_score", ascending=False)
                       .groupby("GEOID", as_index=False)
                       .agg(agg_cols)
                       .sort_values("risk_score", ascending=False)
                       .head(k))
          topk.insert(1, "date", last_day.date())
          Path(out_csv).parent.mkdir(parents=True, exist_ok=True)
          topk.to_csv(out_csv, index=False)
          print(f"‚úÖ wrote patrol CSV -> {out_csv} (rows={len(topk)})")
          PY

      - name: Preview patrol CSV
        run: |
          set -euo pipefail
          echo "üìÑ $(basename "${PATROL_OUT_CSV}") @ ${CRIME_DATA_DIR}"
          head -n 5 "${CRIME_DATA_DIR}/${PATROL_OUT_CSV}" || true

      - name: Upload patrol artifacts
        uses: actions/upload-artifact@v4
        with:
          name: fr-patrol-plan
          path: ${{ env.CRIME_DATA_DIR }}/${{ env.PATROL_OUT_CSV }}
          if-no-files-found: warn
