name: Daily Crime

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
    branches: [main]

permissions:
  contents: read
  actions: read

concurrency:
  group: daily-crime-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    env:
      CRIME_DATA_DIR: crime_prediction_data
      WX_LOCATION: "paris"
      WX_UNIT: "metric"
      GEOID_LEN: "11"

      # artifact indirilecek yerler
      ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
      ARTIFACT_DIR: artifact
      FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
      FALLBACK_DIRS: ${{ github.workspace }}/crime_prediction_data,${{ github.workspace }}

      # GÜNLÜK I/O dosya adları (ADIMLAR BUNLARA BAKIYOR)
      FR_GRID_DAILY_IN:  fr_crime_grid_daily.csv
      FR_GRID_DAILY_OUT: fr_crime_grid_daily.csv
      FR_EVENTS_DAILY_IN:  fr_crime_events_daily.csv
      FR_EVENTS_DAILY_OUT: fr_crime_events_daily.csv

      # komşuluk dosyası
      NEIGH_FILE: neighbors.csv

    steps:
      - name: Debug trigger
        run: |
          echo "event_name=${{ github.event_name }}"
          echo "from workflow=${{ github.event.workflow_run.name }}"
          echo "conclusion=${{ github.event.workflow_run.conclusion }}"

      - uses: actions/checkout@v4

      - name: Ensure data dir (FR)
        run: mkdir -p "${CRIME_DATA_DIR}"

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps (quick)
        run: |
          python -m pip install -U pip wheel setuptools
          [ -f requirements.txt ] && pip install -r requirements.txt || true
          python -m pip install -U pyarrow pandas
          # günlük zenginleştirme adımları için
          python -m pip install numpy scikit-learn pyproj shapely geopandas fiona rtree

      - name: Download upstream artifact (triggering run)
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact

      - name: Unzip artifact if present (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${{ env.ARTIFACT_ZIP }}" ]; then
            command -v unzip >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null && sudo apt-get install -y unzip >/dev/null; }
            unzip -o "${{ env.ARTIFACT_ZIP }}" -d "${{ env.ARTIFACT_DIR }}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi

      # (0) Daily + Y_label (GRID & EVENTS üret)
      - name: (0) Build FR daily (GRID & EVENTS) + Y_label
        env:
          CRIME_DATA_DIR:  ${{ env.CRIME_DATA_DIR }}
          FR_EVENTS_PATH:  ${{ env.CRIME_DATA_DIR }}/fr_crime.csv
          FR_OUT_EVENTS:   ${{ env.CRIME_DATA_DIR }}/fr_crime_events_daily.csv
          FR_OUT_GRID:     ${{ env.CRIME_DATA_DIR }}/fr_crime_grid_daily.csv
          FR_MIN_YEARS:    "5"
          FR_DATE_COL:     "incident_datetime"
          FR_GEOID_COL:    "GEOID"
          FR_ID_COL:       "id"
        run: |
          set -e
          python -u update_crime_fr_daily.py
          echo "---- GRID head ----"
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_grid_daily.csv" || true
          echo "---- EVENTS head ----"
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_events_daily.csv" || true

      # (1) 911 -> GRID/EVENTS
      - name: (1) 911 -> enrich GRID & EVENTS
        env:
          FR_911_PATH: "${{ env.CRIME_DATA_DIR }}/sf_911_last_5_year.csv"
          FR_911_DATE_COL: "incident_datetime"
          FR_911_GEOID_COL: "GEOID"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u enrich_with_911.py
          echo "---- After 911 (GRID head) ----"
          head -n 5 "${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}" || true

      # (2) 311 -> GRID/EVENTS
      - name: (2) 311 -> enrich GRID & EVENTS
        env:
          CRIME_DATA_DIR: "${{ env.CRIME_DATA_DIR }}"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
          FR_311_DAILY_IN: ""                        # varsa dogrudan gunluk 311 dosyasi
          AGG_311_NAME: "sf_311_last_5_years.csv"   # yoksa buradan gunluk uretilir
        run: |
          set -e
          python -u update_311_daily.py
          echo "---- After 311 (GRID cols) ----"
          python - <<'PY'
import pandas as pd, os
p=os.path.join(os.getenv("CRIME_DATA_DIR"),os.getenv("FR_GRID_DAILY_OUT"))
df=pd.read_csv(p, nrows=0); print(list(df.columns))
PY

      # (3) Bus stops -> GRID/EVENTS
      - name: (3) Bus stops -> enrich GRID & EVENTS
        env:
          CRIME_DATA_DIR: "${{ env.CRIME_DATA_DIR }}"
          BUS_CANON_RAW: "sf_bus_stops_with_geoid.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_bus_fr_daily.py

      # (4) Train stops -> GRID/EVENTS
      - name: (4) Train stops -> enrich GRID & EVENTS
        env:
          CRIME_DATA_DIR: "${{ env.CRIME_DATA_DIR }}"
          TRAIN_STOPS_NAME: "sf_train_stops_with_geoid.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_train_fr_daily.py

      # (5) POI -> GRID/EVENTS
      - name: (5) POI -> enrich GRID & EVENTS
        env:
          CRIME_DATA_DIR: "${{ env.CRIME_DATA_DIR }}"
          POI_GEOJSON_1: "${{ env.CRIME_DATA_DIR }}/sf_pois.geojson"
          POI_GEOJSON_2: "sf_pois.geojson"
          POI_CLEAN_CSV: "${{ env.CRIME_DATA_DIR }}/sf_pois_cleaned_with_geoid.csv"
          BLOCK_GEOJSON: "${{ env.CRIME_DATA_DIR }}/sf_census_blocks_with_population.geojson"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_poi_fr_daily.py

      # (6) Police & Government -> GRID/EVENTS
      - name: (6) Police & Government -> enrich GRID & EVENTS
        env:
          CRIME_DATA_DIR: "${{ env.CRIME_DATA_DIR }}"
          POLICE_FILE: "sf_police_stations.csv"
          GOV_FILE: "sf_government_buildings.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_police_gov_daily.py

      # (7) Weather (date-merge) -> GRID/EVENTS
      - name: (7) Weather (date-merge) -> enrich GRID & EVENTS
        env:
          CRIME_DATA_DIR: "${{ env.CRIME_DATA_DIR }}"
          WEATHER_FILE: "sf_weather_5years.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_weather_fr_daily.py

      # (8) Neighbor windows (1/3/7d)
      - name: (8) Neighbor windows (1/3/7d) -> enrich GRID & EVENTS
        env:
          CRIME_DATA_DIR: "${{ env.CRIME_DATA_DIR }}"
          NEIGH_FILE: "${{ env.NEIGH_FILE }}"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u make_neighbors_fr.py

      - name: Final previews
        run: |
          echo "==== GRID (top 3 rows) ===="
          head -n 3 "${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}" || true
          echo "==== EVENTS (top 3 rows) ===="
          head -n 3 "${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}" || true
          echo "==== GRID column list ===="
          python - <<'PY'
import pandas as pd, os
p=os.path.join(os.getenv("CRIME_DATA_DIR"),os.getenv("FR_GRID_DAILY_OUT"))
df=pd.read_csv(p, nrows=0); print("\n".join(df.columns))
PY

      - name: Upload artifacts (GRID & EVENTS)
        uses: actions/upload-artifact@v4
        with:
          name: fr-daily-grid-events
          path: |
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_GRID_DAILY_OUT }}
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_EVENTS_DAILY_OUT }}
          if-no-files-found: warn

  # İKİNCİ JOB — doğru needs: run_fr
  patrol-fr:
    needs: [run_fr]
    runs-on: ubuntu-latest
    env:
      CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
      GRID_FILE:      ${{ env.FR_GRID_DAILY_OUT }}
      EVENTS_FILE:    ${{ env.FR_EVENTS_DAILY_OUT }}
      PATROL_TOP_K:   "25"
      PATROL_MIN_SPACING_M: "300"
      PATROL_OUT_CSV: "fr_patrol_plan.csv"
      PATROL_OUT_GEOJSON: "fr_patrol_plan.geojson"

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps (runtime only)
        run: |
          python -m pip install -U pip
          pip install pandas numpy shapely geopandas

      - name: Run patrol planner
        run: |
          set -e
          python - <<'PY'
import os, pandas as pd
from pathlib import Path

base = Path(os.environ["CRIME_DATA_DIR"])
grid = pd.read_csv(base / os.environ["GRID_FILE"])
k    = int(os.environ.get("PATROL_TOP_K","25"))
out_csv = base / os.environ.get("PATROL_OUT_CSV","fr_patrol_plan.csv")

grid["date"] = pd.to_datetime(grid["date"], errors="coerce")
last_day = grid["date"].max()
today = grid[grid["date"]==last_day].copy()

def safe_num(col):
    return pd.to_numeric(today.get(col, 0), errors="coerce").fillna(0)

today["risk_score"] = (
    safe_num("events_count")*1.0 +
    safe_num("neighbor_crime_24h")*0.20 +
    safe_num("neighbor_crime_72h")*0.10 +
    safe_num("neighbor_crime_7d")*0.05 +
    safe_num("n911_prev_1d")*0.10
)

topk = (today
        .sort_values("risk_score", ascending=False)
        .groupby("GEOID", as_index=False)
        .agg({"risk_score":"max","Y_label":"max","events_count":"max"})
        .sort_values("risk_score", ascending=False)
        .head(k))

topk.insert(1, "date", last_day.date())
topk.to_csv(out_csv, index=False)
print(f"Wrote patrol CSV -> {out_csv} (rows={len(topk)})")
PY

      - name: Upload patrol artifacts
        uses: actions/upload-artifact@v4
        with:
          name: fr-patrol-plan
          path: |
            ${{ env.CRIME_DATA_DIR }}/${{ env.PATROL_OUT_CSV }}
          if-no-files-found: warn
