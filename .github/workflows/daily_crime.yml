name: Daily Crime

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
  workflow_dispatch:

permissions:
  contents: read
  actions: read

concurrency:
  group: daily-crime-${{ github.ref }}
  cancel-in-progress: true

env:
  CRIME_DATA_DIR: ${{ github.workspace }}
  WX_LOCATION: "paris"
  WX_UNIT: "metric"
  GEOID_LEN: "11"

  # Artifact ve ZIP yollarƒ±
  ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
  ARTIFACT_DIR: artifact

  # √áƒ±ktƒ±/okuma i√ßin ana veri klas√∂r√º
  FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
  FALLBACK_DIRS: ${{ github.workspace }}/crime_prediction_data,${{ github.workspace }}

  # G√ºnl√ºk dosyalar ‚Äî ALT KLAS√ñRLE Bƒ∞RLƒ∞KTE!
  FR_GRID_DAILY_IN:  crime_prediction_data/fr_crime_grid_daily.csv
  FR_GRID_DAILY_OUT: crime_prediction_data/fr_crime_grid_daily.csv
  FR_EVENTS_DAILY_IN:  crime_prediction_data/fr_crime_events_daily.csv
  FR_EVENTS_DAILY_OUT: crime_prediction_data/fr_crime_events_daily.csv

  NEIGH_FILE: neighbors.csv

  # 911 varsayƒ±lanlarƒ± (bo≈ü kalmasƒ±n)
  FR_911_DATE_COL: "incident_datetime"
  FR_911_GEOID_COL: "GEOID"
  FR_911_WINSOR_Q: "0"
  FR_CAT_TOPK: "8"

  # 311 varsayƒ±lanlarƒ± (bo≈ü kalmasƒ±n)
  FR_311_DATE_COL: "date"
  FR_311_GEOID_COL: "GEOID"
  FR_311_WINSOR_Q: "0"      # bo≈ü gelirse 0 (kapalƒ±) ‚Üí kod i√ßinde 0.999'a √ßekmek isterseniz ENV'de deƒüi≈ütirin
  FR_311_EMA_ALPHAS: "0.3,0.6"

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest

    steps:
      - name: Debug trigger (workflow_run)
        if: ${{ github.event_name == 'workflow_run' }}
        run: |
          set -euo pipefail
          echo "event=${{ github.event_name }}"
          echo "from=${{ github.event.workflow_run.name }}"
          echo "conclusion=${{ github.event.workflow_run.conclusion }}"
          echo "head_branch=${{ github.event.workflow_run.head_branch }}"

      - name: Debug trigger (dispatch)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: |
          set -euo pipefail
          echo "event=${{ github.event_name }}"
          echo "from="
          echo "conclusion="
          echo "head_branch="

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: System deps for geo stack (rtree/libspatialindex)
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y libspatialindex-dev

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python dependencies
        run: |
          set -euo pipefail
          python -m pip install -U pip wheel setuptools pyarrow pandas
          pip install numpy scikit-learn pyproj shapely geopandas fiona rtree

      - name: Download upstream artifact (triggering run)
        if: ${{ github.event_name == 'workflow_run' }}
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact

      - name: Unzip artifact if present (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${{ env.ARTIFACT_ZIP }}" ]; then
            command -v unzip >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null && sudo apt-get install -y unzip >/dev/null; }
            unzip -o "${{ env.ARTIFACT_ZIP }}" -d "${{ env.ARTIFACT_DIR }}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi

      - name: List artifact tree (sanity)
        run: |
          set -euo pipefail
          echo "== artifact contents =="
          find artifact -maxdepth 6 -type f | sed -n '1,200p' || true

      # --- (0) Build FR daily: sf_crime.csv konumunu otomatik bul ---
      - name: (0) Build FR daily (GRID & EVENTS) + Y_label
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail

          echo "üìÇ CWD: $(pwd)"
          echo "üì¶ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          mkdir -p "${CRIME_DATA_DIR}/crime_prediction_data"
          ls -la "${CRIME_DATA_DIR}" || true

          # sf_crime.csv aday yollar
          C1="${CRIME_DATA_DIR}/sf_crime.csv"
          C2="${CRIME_DATA_DIR}/crime_prediction_data/sf_crime.csv"
          C3="${CRIME_DATA_DIR}/artifact/sf_crime.csv"
          if   [ -f "$C1" ]; then export FR_EVENTS_PATH="$C1"
          elif [ -f "$C2" ]; then export FR_EVENTS_PATH="$C2"
          elif [ -f "$C3" ]; then export FR_EVENTS_PATH="$C3"
          else
            echo "‚ùå sf_crime.csv yok (aradƒ±m: $C1 $C2 $C3)"; exit 1
          fi

          export FR_OUT_EVENTS="${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_events_daily.csv"
          export FR_OUT_GRID="${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_grid_daily.csv"
          export FR_MIN_YEARS="5"
          export FR_DATE_COL="incident_datetime"
          export FR_GEOID_COL="GEOID"
          export FR_ID_COL="id"

          echo "üîß FR_EVENTS_PATH: ${FR_EVENTS_PATH}"
          echo "üîß FR_OUT_EVENTS : ${FR_OUT_EVENTS}"
          echo "üîß FR_OUT_GRID   : ${FR_OUT_GRID}"

          python -u update_crime_daily.py

          echo "---- GRID head ----";   head -n 5 "${FR_OUT_GRID}"   || true
          echo "---- EVENTS head ----"; head -n 5 "${FR_OUT_EVENTS}" || true

      # ---------------------- 911 ENRICH (revize arama desenleri) ----------------------
      - name: Fallback: Download 911 from latest Release if missing
        env:
          WANT1: sf_911_last_5_year.csv          # sizin release‚Äôteki dosya adƒ± (ekranda g√∂rd√ºƒü√ºn√ºz)
          WANT2: sf_911_last_5_years.csv         # olasƒ± √ßoƒüul varyant
        run: |
          set -euo pipefail
          # 1) Workspace/Artifact aramasƒ± (zaten biraz sonra da aranacak),
          #    burada sadece hƒ±zlƒ± bir kontrol ve gerekirse Release indir.
          found=""

          # aday yollar
          for p in \
            "${CRIME_DATA_DIR}/${WANT1}" \
            "${CRIME_DATA_DIR}/${WANT2}" \
            "${CRIME_DATA_DIR}/crime_prediction_data/${WANT1}" \
            "${CRIME_DATA_DIR}/crime_prediction_data/${WANT2}" \
            "${CRIME_DATA_DIR}/artifact/${WANT1}" \
            "${CRIME_DATA_DIR}/artifact/${WANT2}"
          do
            if [ -f "$p" ]; then found="$p"; break; fi
          done

          if [ -z "$found" ]; then
            echo "‚ÑπÔ∏è 911 yerelde yok ‚Üí latest release'tan indiriyorum..."
            mkdir -p "${CRIME_DATA_DIR}"
            # current repo‚Äôdan son release‚Äôteki dosyayƒ± desenle indir
            gh release download --repo "$GITHUB_REPOSITORY" --latest \
              --pattern "${WANT1}" --dir "${CRIME_DATA_DIR}" || true
            gh release download --repo "$GITHUB_REPOSITORY" --latest \
              --pattern "${WANT2}" --dir "${CRIME_DATA_DIR}" || true

            # tekrar bak
            for p in \
              "${CRIME_DATA_DIR}/${WANT1}" \
              "${CRIME_DATA_DIR}/${WANT2}" \
              "${CRIME_DATA_DIR}/crime_prediction_data/${WANT1}" \
              "${CRIME_DATA_DIR}/crime_prediction_data/${WANT2}"
            do
              if [ -f "$p" ]; then found="$p"; break; fi
            done
          fi

          if [ -n "$found" ]; then
            echo "‚úÖ 911 release dosyasƒ± hazƒ±r: $found"
            echo "FR_911_PATH=$found" >> "$GITHUB_ENV"
          else
            echo "‚ÑπÔ∏è Release'ta da 911 bulunamadƒ± (devamƒ±nda arama adƒ±mƒ± yine deneyecek)."
          fi

      - name: (1) 911 ‚Üí enrich GRID & EVENTS (robust recursive find)
        env:
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
          FR_911_DATE_COL:  "${{ env.FR_911_DATE_COL }}"
          FR_911_GEOID_COL: "${{ env.FR_911_GEOID_COL }}"
          FR_911_WINSOR_Q:  "${{ env.FR_911_WINSOR_Q }}"
          FR_CAT_TOPK:      "${{ env.FR_CAT_TOPK }}"
        run: |
          set -euo pipefail

          GRID="${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"
          EVTS="${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}"
          if [ ! -f "$GRID" ] || [ ! -f "$EVTS" ]; then
            echo "‚ö†Ô∏è daily grid/events yok ‚Üí 911 enrich atlanƒ±yor."
            exit 0
          fi

          echo "üîé 911 dosyasƒ± aranƒ±yor..."

          # Manuel override destekle
          if [ -n "${FR_911_PATH:-}" ] && [ -f "${FR_911_PATH}" ]; then
            PICK="${FR_911_PATH}"
          else
            # Aranacak desenler: year/years, csv/csv.gz/parquet (+ _y varyantƒ±)
            mapfile -t FOUND_A < <(find "${CRIME_DATA_DIR}" -maxdepth 8 -type f \
              \( -iname "sf_911_last_5_year.csv"      -o -iname "sf_911_last_5_year_y.csv" \
               -o -iname "sf_911_last_5_years.csv"    -o -iname "sf_911_last_5_years_y.csv" \
               -o -iname "sf_911_last_5_year.csv.gz"  -o -iname "sf_911_last_5_years.csv.gz" \
               -o -iname "sf_911_last_5_year.parquet" -o -iname "sf_911_last_5_years.parquet" \) 2>/dev/null | sort)

            if [ -n "${FR_OUTPUT_DIR:-}" ] && [ -d "${FR_OUTPUT_DIR}" ]; then
              mapfile -t FOUND_B < <(find "${FR_OUTPUT_DIR}" -maxdepth 8 -type f \
                \( -iname "sf_911_last_5_year.csv"      -o -iname "sf_911_last_5_year_y.csv" \
                 -o -iname "sf_911_last_5_years.csv"    -o -iname "sf_911_last_5_years_y.csv" \
                 -o -iname "sf_911_last_5_year.csv.gz"  -o -iname "sf_911_last_5_years.csv.gz" \
                 -o -iname "sf_911_last_5_year.parquet" -o -iname "sf_911_last_5_years.parquet" \) 2>/dev/null | sort)
            else
              FOUND_B=()
            fi

            mapfile -t FOUND_C < <(find "${CRIME_DATA_DIR}/artifact" -maxdepth 10 -type f \
              \( -iname "sf_911_last_5_year.csv"      -o -iname "sf_911_last_5_year_y.csv" \
               -o -iname "sf_911_last_5_years.csv"    -o -iname "sf_911_last_5_years_y.csv" \
               -o -iname "sf_911_last_5_year.csv.gz"  -o -iname "sf_911_last_5_years.csv.gz" \
               -o -iname "sf_911_last_5_year.parquet" -o -iname "sf_911_last_5_years.parquet" \) 2>/dev/null | sort || true)

            ALL=("${FOUND_A[@]}" "${FOUND_B[@]}" "${FOUND_C[@]}")
            PICK=""
            declare -A seen
            for p in "${ALL[@]}"; do
              [ -z "${p}" ] && continue
              if [ -f "$p" ] && [ -z "${seen[$p]+x}" ]; then
                seen[$p]=1
                base="$(basename "$p")"
                # √ñncelik: *_y.* (etiketli √∂zet), yoksa ilk bulunan
                if [[ "$base" =~ ^sf_911_last_5_years?_y\.csv(\.gz)?$ ]]; then PICK="$p"; break; fi
                if [ -z "$PICK" ]; then PICK="$p"; fi
              fi
            done
          fi

          if [ -z "${PICK:-}" ]; then
            echo "‚ÑπÔ∏è 911 verisi bulunamadƒ± ‚Üí adƒ±m atlanƒ±yor."
            exit 0
          fi
          echo "‚úÖ 911 kaynaƒüƒ±: $PICK"

          export FR_911_PATH="$PICK"

          if [ -f "./update_911_daily.py" ]; then
            PYFILE="./update_911_daily.py"
          elif [ -f "./scripts/update_911_daily.py" ]; then
            PYFILE="./scripts/update_911_daily.py"
          else
            echo "‚ùå update_911_daily.py yok."; exit 66
          fi

          python -u "$PYFILE"

          # hƒ±zlƒ± kontrol
          head -n 5 "$GRID" || true

      # ---------------------- 311 ENRICH (winsor+EMA saƒülam) ----------------------
      - name: (2) 311 ‚Üí enrich GRID & EVENTS (robust path + robust script)
        env:
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
          FR_311_DATE_COL:  "${{ env.FR_311_DATE_COL }}"
          FR_311_GEOID_COL: "${{ env.FR_311_GEOID_COL }}"
          FR_311_WINSOR_Q:  "${{ env.FR_311_WINSOR_Q }}"
          FR_311_EMA_ALPHAS: "${{ env.FR_311_EMA_ALPHAS }}"
        run: |
          set -euo pipefail

          GRID="${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"
          EVTS="${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}"
          if [ ! -f "$GRID" ] || [ ! -f "$EVTS" ]; then
            echo "‚ö†Ô∏è daily grid/events yok ‚Üí 311 enrich atlanƒ±yor."
            exit 0
          fi

          CANDIDATES=(
            "${CRIME_DATA_DIR}/sf_311_last_5_years.csv"
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_311_last_5_years.csv"
            "${CRIME_DATA_DIR}/crime_prediction_data/crime_prediction_data/sf_311_last_5_years.csv"
            "${FR_OUTPUT_DIR}/sf_311_last_5_years.csv"
            "${FR_OUTPUT_DIR}/crime_prediction_data/sf_311_last_5_years.csv"
            "${CRIME_DATA_DIR}/artifact/sf_311_last_5_years.csv"
          )

          PICK=""
          TRIED=()
          for p in "${CANDIDATES[@]}"; do
            TRIED+=("$p")
            if [ -f "$p" ]; then PICK="$p"; break; fi
          done

          if [ -z "$PICK" ]; then
            echo "‚ÑπÔ∏è 311 g√ºnl√ºk bulunamadƒ± (aradƒ±m: ${TRIED[*]}) ‚Üí adƒ±m atlanƒ±yor."
            exit 0
          fi

          echo "‚úÖ 311 kaynaƒüƒ±: $PICK"
          export FR_311_DAILY_IN="$PICK"

          if [ -f "./update_311_daily.py" ]; then
            PYFILE="./update_311_daily.py"
          elif [ -f "./enrich_with_311.py" ]; then
            PYFILE="./enrich_with_311.py"
          elif [ -f "./scripts/update_311_daily.py" ]; then
            PYFILE="./scripts/update_311_daily.py"
          elif [ -f "./scripts/enrich_with_311.py" ]; then
            PYFILE="./scripts/enrich_with_311.py"
          else
            echo "‚ùå 311 script'i bulunamadƒ±."; exit 67
          fi

          python -u "$PYFILE"

          python - <<'PY'
          import os, pandas as pd
          p=os.path.join(os.getenv("CRIME_DATA_DIR"), os.getenv("FR_GRID_DAILY_OUT","crime_prediction_data/fr_crime_grid_daily.csv"))
          if os.path.exists(p):
              df=pd.read_csv(p, nrows=0)
              print("GRID columns:", list(df.columns))
          else:
              print("‚ö†Ô∏è GRID yok, kolon listesi alƒ±namadƒ±.")
          PY

      - name: (3) Bus stops -> enrich GRID & EVENTS
        working-directory: ${{ github.workspace }}
        env:
          BUS_CANON_RAW: "sf_bus_stops_with_geoid.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -euo pipefail
          python -u update_bus_daily.py

      - name: (4) Train stops -> enrich GRID & EVENTS
        working-directory: ${{ github.workspace }}
        env:
          TRAIN_STOPS_NAME: "sf_train_stops_with_geoid.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -euo pipefail
          python -u update_train_daily.py

      - name: (5) POI -> enrich GRID & EVENTS
        working-directory: ${{ github.workspace }}
        env:
          POI_GEOJSON_1: "${{ env.CRIME_DATA_DIR }}/sf_pois.geojson"
          POI_GEOJSON_2: "sf_pois.geojson"
          POI_CLEAN_CSV: "${{ env.CRIME_DATA_DIR }}/sf_pois_cleaned_with_geoid.csv"
          BLOCK_GEOJSON: "${{ env.CRIME_DATA_DIR }}/sf_census_blocks_with_population.geojson"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -euo pipefail
          python -u update_poi_daily.py

      - name: (6) Police & Government -> enrich GRID & EVENTS
        working-directory: ${{ github.workspace }}
        env:
          POLICE_FILE: "sf_police_stations.csv"
          GOV_FILE: "sf_government_buildings.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -euo pipefail
          python -u update_police_gov_daily.py

      - name: (7) Weather (date-merge) -> enrich GRID & EVENTS
        working-directory: ${{ github.workspace }}
        env:
          WEATHER_FILE: "sf_weather_5years.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -euo pipefail
          python -u update_weather_daily.py

      - name: (8) Neighbor windows (1/3/7d) -> enrich GRID & EVENTS
        working-directory: ${{ github.workspace }}
        env:
          NEIGH_FILE: "${{ env.NEIGH_FILE }}"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -euo pipefail
          if [ ! -f "${NEIGH_FILE}" ]; then
            echo "‚ÑπÔ∏è neighbors.csv yok ‚Üí kom≈üu enrich atlanƒ±yor."
            exit 0
          fi
          python -u make_neighbors_fr.py

      - name: Final previews
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail
          echo "==== GRID (top 3 rows) ====";   head -n 3 "${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"   || true
          echo "==== EVENTS (top 3 rows) ===="; head -n 3 "${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}" || true
          echo "==== GRID column list ===="
          python - <<'PY'
          import pandas as pd, os
          p=os.path.join(os.getenv("CRIME_DATA_DIR"),os.getenv("FR_GRID_DAILY_OUT"))
          if os.path.exists(p):
              df=pd.read_csv(p, nrows=0); print("\n".join(df.columns))
          else:
              print("‚ö†Ô∏è GRID yok.")
          PY

      - name: Upload artifacts (GRID & EVENTS)
        uses: actions/upload-artifact@v4
        with:
          name: fr-daily-grid-events
          path: |
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_GRID_DAILY_OUT }}
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_EVENTS_DAILY_OUT }}
          if-no-files-found: warn

  patrol-fr:
    needs: [run_fr]
    if: ${{ needs.run_fr.result == 'success' }}
    runs-on: ubuntu-latest
    env:
      CRIME_DATA_DIR: ${{ github.workspace }}
      GRID_FILE:      crime_prediction_data/fr_crime_grid_daily.csv
      PATROL_TOP_K:   "25"
      PATROL_MIN_SPACING_M: "300"
      PATROL_OUT_CSV: "fr_patrol_plan.csv"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Download daily grid/events from previous job
        uses: actions/download-artifact@v4
        with:
          name: fr-daily-grid-events
          path: ${{ env.CRIME_DATA_DIR }}

      - name: Verify transferred files
        run: |
          set -euo pipefail
          echo "üì¶ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          ls -la "${CRIME_DATA_DIR}" || true
          ls -la "${CRIME_DATA_DIR}/crime_prediction_data" || true
          head -n 3 "${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_grid_daily.csv" || true
          head -n 3 "${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_events_daily.csv" || true

      - name: Install runtime Python deps
        run: |
          set -euo pipefail
          python -m pip install -U pip
          pip install pandas numpy

      - name: Run patrol planner
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys, pandas as pd
          from pathlib import Path
          base = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data"))
          grid_path = base / os.environ.get("GRID_FILE","fr_crime_grid_daily.csv")
          k    = int(os.environ.get("PATROL_TOP_K","25"))
          out_csv = base / os.environ.get("PATROL_OUT_CSV","fr_patrol_plan.csv")
          if not grid_path.exists():
              print(f"‚ùå GRID bulunamadƒ±: {grid_path}", file=sys.stderr); sys.exit(2)
          df = pd.read_csv(grid_path)
          if df.empty:
              print("‚ö†Ô∏è GRID bo≈ü, plan √ºretilemedi.")
              import pandas as pd
              pd.DataFrame(columns=["GEOID","date","risk_score","Y_label","events_count"]).to_csv(out_csv, index=False)
              sys.exit(0)
          need = ["GEOID","date"]
          for c in need:
              if c not in df.columns:
                  print(f"‚ùå Zorunlu kolon yok: {c}", file=sys.stderr); sys.exit(3)
          df["date"] = pd.to_datetime(df["date"], errors="coerce")
          last_day = df["date"].dropna().max()
          if pd.isna(last_day):
              print("‚ùå Tarih alanƒ± hatalƒ±.", file=sys.stderr); sys.exit(4)
          today = df[df["date"]==last_day].copy()
          def safe_num(name, default=0.0):
              s = pd.to_numeric(today[name], errors="coerce").fillna(0) if name in today.columns else default
              import pandas as pd
              return s if hasattr(s, "values") else pd.Series(default, index=today.index)
          today["risk_score"] = (
              safe_num("events_count")*1.0 +
              safe_num("neighbor_crime_24h")*0.20 +
              safe_num("neighbor_crime_72h")*0.10 +
              safe_num("neighbor_crime_7d")*0.05 +
              safe_num("n911_prev_1d")*0.10
          )
          agg_cols = {c:"max" for c in ["risk_score","events_count"] if c in today.columns}
          if "Y_label" in today.columns: agg_cols["Y_label"] = "max"
          topk = (today.sort_values("risk_score", ascending=False)
                       .groupby("GEOID", as_index=False)
                       .agg(agg_cols)
                       .sort_values("risk_score", ascending=False)
                       .head(k))
          topk.insert(1, "date", last_day.date())
          out_csv.parent.mkdir(parents=True, exist_ok=True)
          topk.to_csv(out_csv, index=False)
          print(f"‚úÖ Wrote patrol CSV -> {out_csv} (rows={len(topk)})")
          PY

      - name: Upload patrol artifacts
        uses: actions/upload-artifact@v4
        with:
          name: fr-patrol-plan
          path: ${{ env.CRIME_DATA_DIR }}/${{ env.PATROL_OUT_CSV }}
          if-no-files-found: warn
