name: Daily Crime

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
  workflow_dispatch:

permissions:
  contents: read
  actions: read

concurrency:
  group: daily-crime-${{ github.ref }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash

env:
  # K√∂k: repo √ßalƒ±≈üma alanƒ±
  CRIME_DATA_DIR: ${{ github.workspace }}

  WX_LOCATION: "paris"
  WX_UNIT: "metric"
  GEOID_LEN: "11"

  # Artifact klas√∂r√º (varsa)
  ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
  ARTIFACT_DIR: artifact

  # Ana √ßƒ±ktƒ±/okuma dizini
  FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
  FALLBACK_DIRS: ${{ github.workspace }}/crime_prediction_data,${{ github.workspace }}

  # G√ºnl√ºk dosyalar ‚Äî alt klas√∂rle birlikte
  FR_GRID_DAILY_IN:  crime_prediction_data/fr_crime_grid_daily.csv
  FR_GRID_DAILY_OUT: crime_prediction_data/fr_crime_grid_daily.csv
  FR_EVENTS_DAILY_IN:  crime_prediction_data/fr_crime_events_daily.csv
  FR_EVENTS_DAILY_OUT: crime_prediction_data/fr_crime_events_daily.csv

  # (Fix) Top-level env i√ßinde ba≈üka env'e referans verilemez ‚áí github.workspace kullan
  NEIGH_FILE: ${{ github.workspace }}/neighbors.csv

  # 911 varsayƒ±lanlarƒ±
  FR_911_DATE_COL: "incident_datetime"
  FR_911_GEOID_COL: "GEOID"
  FR_911_WINSOR_Q: "0"
  FR_CAT_TOPK: "8"
  FR_911_EMA_ALPHAS: "0.3,0.5"

  # 311 varsayƒ±lanlarƒ±
  FR_311_DATE_COL: "date"
  FR_311_GEOID_COL: "GEOID"
  FR_311_WINSOR_Q: "0"
  FR_311_EMA_ALPHAS: "0.3,0.6"

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest

    steps:
      - name: Debug trigger
        run: |
          set -euo pipefail
          echo "event=${{ github.event_name }}"
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            echo "from=${{ github.event.workflow_run.name }}"
            echo "conclusion=${{ github.event.workflow_run.conclusion }}"
            echo "head_branch=${{ github.event.workflow_run.head_branch }}"
          fi

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: System deps for geo stack (rtree/libspatialindex)
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y libspatialindex-dev unzip

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python dependencies
        run: |
          set -euo pipefail
          python -m pip install -U pip wheel setuptools pyarrow pandas
          pip install numpy scikit-learn pyproj shapely geopandas fiona rtree

      - name: Download upstream artifact (only when triggered by run)
        if: ${{ github.event_name == 'workflow_run' }}
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact

      - name: Unzip artifact if present (optional)
        run: |
          set -euo pipefail
          if [ -f "${ARTIFACT_ZIP}" ]; then
            unzip -o "${ARTIFACT_ZIP}" -d "${ARTIFACT_DIR}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi

      - name: List artifact tree (sanity)
        run: |
          set -euo pipefail
          echo "== artifact contents =="
          find artifact -maxdepth 6 -type f | sed -n '1,200p' || true

      # --- (0) Build FR daily: sf_crime.csv konumunu otomatik bul ---
      - name: (0) Build FR daily (GRID & EVENTS) + Y_label
        run: |
          set -euo pipefail
          echo "üìÇ CWD: $(pwd)"
          echo "üì¶ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          mkdir -p "${CRIME_DATA_DIR}/crime_prediction_data"
          ls -la "${CRIME_DATA_DIR}" || true

          # sf_crime.csv aday yollar
          C1="${CRIME_DATA_DIR}/sf_crime.csv"
          C2="${CRIME_DATA_DIR}/crime_prediction_data/sf_crime.csv"
          C3="${CRIME_DATA_DIR}/artifact/sf_crime.csv"
          if   [ -f "$C1" ]; then export FR_EVENTS_PATH="$C1"
          elif [ -f "$C2" ]; then export FR_EVENTS_PATH="$C2"
          elif [ -f "$C3" ]; then export FR_EVENTS_PATH="$C3"
          else
            echo "‚ùå sf_crime.csv yok (aradƒ±m: $C1 $C2 $C3)"; exit 1
          fi

          export FR_OUT_EVENTS="${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_events_daily.csv"
          export FR_OUT_GRID="${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_grid_daily.csv"
          export FR_MIN_YEARS="5"
          export FR_DATE_COL="incident_datetime"
          export FR_GEOID_COL="GEOID"
          export FR_ID_COL="id"

          echo "üîß FR_EVENTS_PATH: ${FR_EVENTS_PATH}"
          echo "üîß FR_OUT_EVENTS : ${FR_OUT_EVENTS}"
          echo "üîß FR_OUT_GRID   : ${FR_OUT_GRID}"

          python -u update_crime_daily.py

          echo "---- GRID head ----";   head -n 5 "${FR_OUT_GRID}"   || true
          echo "---- EVENTS head ----"; head -n 5 "${FR_OUT_EVENTS}" || true

      # ---------------------- 911 ENRICH ‚Äî SADE: sadece yerel/artefact arama ----------------------
      - name: (1) 911 ‚Üí enrich GRID & EVENTS
        env:
          ARTIFACT_ZIP:  ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:  ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
          FR_EVENTS_DAILY_OUT: ${{ env.FR_EVENTS_DAILY_OUT }}
          FR_GRID_DAILY_OUT:   ${{ env.FR_GRID_DAILY_OUT }}
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}   # -u i√ßin garanti
        run: |
          set -euo pipefail

          echo "== check & set FR_911 =="
          CANDIDATES=(
            "${ARTIFACT_DIR}/sf_911_last_5_year_y.csv"
            "${ARTIFACT_DIR}/sf_911_last_5_year.csv"
            "${ARTIFACT_DIR}/sf_911_last_5_year_y"          # uzantƒ±sƒ±z
            "${ARTIFACT_DIR}/sf_911_last_5_year"            # uzantƒ±sƒ±z
            "${ARTIFACT_DIR}/sf-crime-pipeline-output/sf_911_last_5_year_y.csv"
            "${ARTIFACT_DIR}/sf-crime-pipeline-output/sf_911_last_5_year.csv"
            "${ARTIFACT_DIR}/sf-crime-pipeline-output/sf_911_last_5_year_y"
            "${ARTIFACT_DIR}/sf-crime-pipeline-output/sf_911_last_5_year"

            "${CRIME_DATA_DIR}/sf_911_last_5_year_y.csv"
            "${CRIME_DATA_DIR}/sf_911_last_5_year.csv"
            "${CRIME_DATA_DIR}/sf_911_last_5_year_y"
            "${CRIME_DATA_DIR}/sf_911_last_5_year"
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_911_last_5_year_y.csv"
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_911_last_5_year.csv"
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_911_last_5_year_y"
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_911_last_5_year"

            # ihtiyaten "years" varyantƒ±
            "${ARTIFACT_DIR}/sf_911_last_5_years.csv"
            "${ARTIFACT_DIR}/sf_911_last_5_years"
            "${CRIME_DATA_DIR}/sf_911_last_5_years.csv"
            "${CRIME_DATA_DIR}/sf_911_last_5_years"
            "sf_911_last_5_year.csv"
            "sf_911_last_5_year"
            "sf_911_last_5_years.csv"
            "sf_911_last_5_years"
          )
          PICK=""
          for p in "${CANDIDATES[@]}"; do
            if [ -f "$p" ]; then PICK="$p"; break; fi
          done
          if [ -n "$PICK" ]; then
            echo "‚úÖ 911 source: $PICK"
            export FR_911="$PICK"      # <<< √ñNEMLƒ∞: FR_911_PATH deƒüil, FR_911
          else
            echo "‚ÑπÔ∏è 911 kaynaƒüƒ± bulunamadƒ±; bu adƒ±m nazik√ße atlanacak (Python guard var)."
            # exit 0  # sert atlamak istersen a√ß
          fi

          echo "== find 911 CSVs (if artifact exists) =="
          if [ -d "artifact" ]; then
            # csv uzantƒ±lƒ±
            find artifact -maxdepth 6 -type f -name 'sf_911_last_5_year*.csv' -ls || true
            # uzantƒ±sƒ±z (name pattern)
            find artifact -maxdepth 6 -type f -name 'sf_911_last_5_year*' ! -name '*.csv' -ls || true
          else
            echo "‚ÑπÔ∏è artifact/ yok (muhtemelen workflow_dispatch ile √ßalƒ±≈ütƒ±)."
          fi

          python -u update_911_daily.py

          EVENTS_FILE="${FR_OUTPUT_DIR}/${FR_EVENTS_DAILY_OUT:-fr_crime_events_daily.csv}"
          GRID_FILE="${FR_OUTPUT_DIR}/${FR_GRID_DAILY_OUT:-fr_crime_grid_daily.csv}"

          for f in "$EVENTS_FILE" "$GRID_FILE"; do
            if [ -f "$f" ]; then
              echo ""; echo "üìÑ $(basename "$f") ‚Äî $(wc -l < "$f") satƒ±r"
              head -n 5 "$f" || true
              echo "üß≠ columns:"
              F="$f" python - <<'PY'
              import os, pandas as pd
              f = os.environ['F']
              try:
                  df = pd.read_csv(f, nrows=0)
                  print(",".join(df.columns))
              except Exception as e:
                  print(f"kolon okuma hatasƒ±: {e}")
              PY
            else
              echo "‚ö†Ô∏è Dosya yok: $f"
            fi
          done
          
      # ---------------------- 311 ENRICH (yerel arama) ----------------------
      - name: (2) 311 ‚Üí enrich GRID & EVENTS (local search)
        env:
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
          FR_311_DATE_COL:  "${{ env.FR_311_DATE_COL }}"
          FR_311_GEOID_COL: "${{ env.FR_311_GEOID_COL }}"
          FR_311_WINSOR_Q:  "${{ env.FR_311_WINSOR_Q }}"
          FR_311_EMA_ALPHAS: "${{ env.FR_311_EMA_ALPHAS }}"
        run: |
          set -euo pipefail

          GRID="${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"
          EVTS="${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}"
          if [ ! -f "$GRID" ] || [ ! -f "$EVTS" ]; then
            echo "‚ö†Ô∏è daily grid/events yok ‚Üí 311 enrich atlanƒ±yor."
            exit 0
          fi

          CANDIDATES=( \
            "${CRIME_DATA_DIR}/sf_311_last_5_years.csv" \
            "${CRIME_DATA_DIR}/crime_prediction_data/sf_311_last_5_years.csv" \
            "${CRIME_DATA_DIR}/artifact/sf_311_last_5_years.csv" \
          )
          PICK=""
          for p in "${CANDIDATES[@]}"; do
            [ -f "$p" ] && { PICK="$p"; break; }
          done
          if [ -z "$PICK" ]; then
            echo "‚ÑπÔ∏è 311 g√ºnl√ºk bulunamadƒ± ‚Üí adƒ±m atlanƒ±yor."
            exit 0
          fi
          echo "‚úÖ 311 kaynaƒüƒ±: $PICK"
          export FR_311_DAILY_IN="$PICK"

          if [ -f "./update_311_daily.py" ]; then
            PYFILE="./update_311_daily.py"
          elif [ -f "./scripts/update_311_daily.py" ]; then
            PYFILE="./scripts/update_311_daily.py"
          else
            echo "‚ùå 311 script'i bulunamadƒ±."; exit 67
          fi

          python -u "$PYFILE"

          python - <<'PY'
          import os, pandas as pd
          p=os.path.join(os.getenv("CRIME_DATA_DIR"), os.getenv("FR_GRID_DAILY_OUT","crime_prediction_data/fr_crime_grid_daily.csv"))
          if os.path.exists(p):
              df=pd.read_csv(p, nrows=0)
              print("GRID columns:", list(df.columns))
          else:
              print("‚ö†Ô∏è GRID yok, kolon listesi alƒ±namadƒ±.")
          PY

      - name: (3) Bus stops -> enrich GRID & EVENTS
        env:
          BUS_CANON_RAW: "sf_bus_stops_with_geoid.csv"
        run: |
          set -euo pipefail
          python -u update_bus_daily.py

      - name: (4) Train stops -> enrich GRID & EVENTS
        env:
          TRAIN_STOPS_NAME: "sf_train_stops_with_geoid.csv"
        run: |
          set -euo pipefail
          python -u update_train_daily.py

      - name: (5) POI -> enrich GRID & EVENTS
        env:
          POI_GEOJSON_1: "${{ env.CRIME_DATA_DIR }}/sf_pois.geojson"
          POI_GEOJSON_2: "sf_pois.geojson"
          POI_CLEAN_CSV: "${{ env.CRIME_DATA_DIR }}/sf_pois_cleaned_with_geoid.csv"
          BLOCK_GEOJSON: "${{ env.CRIME_DATA_DIR }}/sf_census_blocks_with_population.geojson"
        run: |
          set -euo pipefail
          python -u update_poi_daily.py

      - name: (5.1) Build BLOCKS centroid CSV (one-time)
        run: |
          set -euo pipefail
          python - <<'PY'
          import pandas as pd, geopandas as gpd, os
          from pathlib import Path

          BASE = Path(os.environ["CRIME_DATA_DIR"])
          INP  = BASE/"sf_census_blocks_with_population.geojson"
          OUT  = BASE/"sf_blocks_centroids.csv"

          print(f"INPUT={INP}")
          gdf = gpd.read_file(INP).to_crs("EPSG:4326")
          if "GEOID" not in gdf.columns:
              raise ValueError("BLOCKS GeoJSON i√ßinde GEOID yok")

          def g11(s: pd.Series)->pd.Series:
              return (
                s.astype(str).str.extract(r"(\d+)",expand=False)
                .fillna("").str.replace(" ","",regex=False).str.zfill(11).str[:11]
              )

          gdf["GEOID"]=g11(gdf["GEOID"])
          cent = gdf.dissolve(by="GEOID")["geometry"].centroid
          df=pd.DataFrame({"GEOID":cent.index,"centroid_lat":cent.y,"centroid_lon":cent.x})
          df.to_csv(OUT,index=False)
          print(f"‚úÖ wrote {OUT} rows={len(df)}")
          PY

      - name: (6) Police & Government -> enrich GRID & EVENTS
        env:
          POLICE_FILE: "sf_police_stations.csv"
          GOV_FILE: "sf_government_buildings.csv"
          BLOCKS_CSV: "sf_blocks_centroids.csv"
        run: |
          set -euo pipefail
          python -u update_police_gov_daily.py

      - name: (7) Weather (date-merge) -> enrich GRID & EVENTS
        env:
          WEATHER_FILE: "sf_weather_5years.csv"
        run: |
          set -euo pipefail
          python -u update_weather_daily.py

      - name: (8) Neighbor windows (1/3/7d) -> enrich GRID & EVENTS
        env:
          NEIGH_FILE: "${{ env.NEIGH_FILE }}"
        run: |
          set -euo pipefail
          if [ ! -f "${NEIGH_FILE}" ]; then
            echo "‚ÑπÔ∏è neighbors.csv yok ‚Üí kom≈üu enrich atlanƒ±yor."
            exit 0
          fi
          python -u scripts/make_neighbors_daily.py

      - name: (9) Population -> enrich GRID & EVENTS
        env:
          POP_FILE: "sf_population.csv"
        run: |
          set -euo pipefail

          POP="${CRIME_DATA_DIR}/${POP_FILE}"
          GRID="${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"
          EVTS="${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}"

          if [ ! -f "$POP" ]; then
            echo "‚ÑπÔ∏è population yok ‚Üí atlanƒ±yor ($POP)"
            exit 0
          fi

          python - <<'PY'
          import os, pandas as pd
          base = os.environ["CRIME_DATA_DIR"]
          pop_path = os.path.join(base, os.environ["POP_FILE"])
          grid_path = os.path.join(base, os.environ["FR_GRID_DAILY_OUT"])
          evt_path  = os.path.join(base, os.environ["FR_EVENTS_DAILY_OUT"])

          pop = pd.read_csv(pop_path)
          # normalize
          pop["GEOID"] = (
              pop["GEOID"].astype(str).str.extract(r"(\d+)",expand=False)
              .str.zfill(11).str[:11]
          )

          def enrich(pth):
              if not os.path.exists(pth): return
              df = pd.read_csv(pth)
              if "GEOID" not in df.columns: return
              df["GEOID"] = (
                  df["GEOID"].astype(str).str.extract(r"(\d+)",expand=False)
                  .str.zfill(11).str[:11]
              )
              df = df.merge(pop[["GEOID","population"]], on="GEOID", how="left")
              df.to_csv(pth,index=False)
              print("‚úÖ enriched:",pth)

          enrich(grid_path)
          enrich(evt_path)
          PY

      - name: Final previews
        run: |
          set -euo pipefail
          echo "==== GRID (top 3 rows) ====";   head -n 3 "${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}"   || true
          echo "==== EVENTS (top 3 rows) ===="; head -n 3 "${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}" || true
          echo "==== GRID column list ===="
          python - <<'PY'
          import pandas as pd, os
          p=os.path.join(os.getenv("CRIME_DATA_DIR"),os.getenv("FR_GRID_DAILY_OUT"))
          if os.path.exists(p):
              df=pd.read_csv(p, nrows=0); print("\n".join(df.columns))
          else:
              print("‚ö†Ô∏è GRID yok.")
          PY

      - name: Upload artifacts (GRID & EVENTS)
        uses: actions/upload-artifact@v4
        with:
          name: fr-daily-grid-events
          path: |
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_GRID_DAILY_OUT }}
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_EVENTS_DAILY_OUT }}
          if-no-files-found: warn

  patrol-fr:
    needs: [run_fr]
    if: ${{ needs.run_fr.result == 'success' }}
    runs-on: ubuntu-latest
    env:
      CRIME_DATA_DIR: ${{ github.workspace }}
      GRID_FILE: crime_prediction_data/fr_crime_grid_daily.csv
      PATROL_TOP_K:   "25"
      PATROL_MIN_SPACING_M: "300"
      PATROL_OUT_CSV: "fr_patrol_plan.csv"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Download daily grid/events from previous job
        uses: actions/download-artifact@v4
        with:
          name: fr-daily-grid-events
          path: ${{ env.CRIME_DATA_DIR }}

      - name: Verify transferred files
        run: |
          set -euo pipefail
          echo "üì¶ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          ls -la "${CRIME_DATA_DIR}" || true
          ls -la "${CRIME_DATA_DIR}/crime_prediction_data" || true
          head -n 3 "${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_grid_daily.csv" || true
          head -n 3 "${CRIME_DATA_DIR}/crime_prediction_data/fr_crime_events_daily.csv" || true

      - name: Install runtime Python deps
        run: |
          set -euo pipefail
          python -m pip install -U pip
          pip install pandas numpy

      - name: Run patrol planner
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys, pandas as pd
          from pathlib import Path
          base = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data"))
          grid_path = base / os.environ.get("GRID_FILE","fr_crime_grid_daily.csv")
          k    = int(os.environ.get("PATROL_TOP_K","25"))
          out_csv = base / os.environ.get("PATROL_OUT_CSV","fr_patrol_plan.csv")
          if not grid_path.exists():
              print(f"‚ùå GRID bulunamadƒ±: {grid_path}", file=sys.stderr); sys.exit(2)
          df = pd.read_csv(grid_path)
          if df.empty:
              print("‚ö†Ô∏è GRID bo≈ü, plan √ºretilemedi.")
              pd.DataFrame(columns=["GEOID","date","risk_score","Y_label","events_count"]).to_csv(out_csv, index=False)
              sys.exit(0)
          need = ["GEOID","date"]
          for c in need:
              if c not in df.columns:
                  print(f"‚ùå Zorunlu kolon yok: {c}", file=sys.stderr); sys.exit(3)
          df["date"] = pd.to_datetime(df["date"], errors="coerce")
          last_day = df["date"].dropna().max()
          if pd.isna(last_day):
              print("‚ùå Tarih alanƒ± hatalƒ±.", file=sys.stderr); sys.exit(4)
          today = df[df["date"]==last_day].copy()
          def safe_num(name, default=0.0):
              s = pd.to_numeric(today[name], errors="coerce").fillna(0) if name in today.columns else default
              import pandas as pd
              return s if hasattr(s, "values") else pd.Series(default, index=today.index)
          today["risk_score"] = (
              safe_num("events_count")*1.0 +
              safe_num("neighbor_crime_24h")*0.20 +
              safe_num("neighbor_crime_72h")*0.10 +
              safe_num("neighbor_crime_7d")*0.05 +
              safe_num("n911_prev_1d")*0.10
          )
          agg_cols = {c:"max" for c in ["risk_score","events_count"] if c in today.columns}
          if "Y_label" in today.columns: agg_cols["Y_label"] = "max"
          topk = (today.sort_values("risk_score", ascending=False)
                       .groupby("GEOID", as_index=False)
                       .agg(agg_cols)
                       .sort_values("risk_score", ascending=False)
                       .head(k))
          topk.insert(1, "date", last_day.date())
          out_csv.parent.mkdir(parents=True, exist_ok=True)
          topk.to_csv(out_csv, index=False)
          print(f"‚úÖ Wrote patrol CSV -> {out_csv} (rows={len(topk)})")
          PY

      - name: Upload patrol artifacts
        uses: actions/upload-artifact@v4
        with:
          name: fr-patrol-plan
          path: ${{ env.CRIME_DATA_DIR }}/${{ env.PATROL_OUT_CSV }}
          if-no-files-found: warn
