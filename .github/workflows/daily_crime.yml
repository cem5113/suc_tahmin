name: Daily Crime

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
  workflow_dispatch:

permissions:
  contents: read
  actions: read

concurrency:
  group: daily-crime-${{ github.ref }}
  cancel-in-progress: true

# ðŸ”§ ORTAK ENV
env:
  CRIME_DATA_DIR: ${{ github.workspace }}/crime_prediction_data
  WX_LOCATION: "paris"
  WX_UNIT: "metric"
  GEOID_LEN: "11"
  ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
  ARTIFACT_DIR: artifact
  FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
  FALLBACK_DIRS: ${{ github.workspace }}/crime_prediction_data,${{ github.workspace }}
  FR_GRID_DAILY_IN:  fr_crime_grid_daily.csv
  FR_GRID_DAILY_OUT: fr_crime_grid_daily.csv
  FR_EVENTS_DAILY_IN:  fr_crime_events_daily.csv
  FR_EVENTS_DAILY_OUT: fr_crime_events_daily.csv
  NEIGH_FILE: neighbors.csv

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest

    steps:
      - name: Debug trigger (workflow_run)
        if: ${{ github.event_name == 'workflow_run' }}
        run: |
          echo "event=${{ github.event_name }}"
          echo "from=${{ github.event.workflow_run.name }}"
          echo "conclusion=${{ github.event.workflow_run.conclusion }}"
          echo "head_branch=${{ github.event.workflow_run.head_branch }}"

      - name: Debug trigger (dispatch)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: |
          echo "event=${{ github.event_name }}"
          echo "from="
          echo "conclusion="
          echo "head_branch="

      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        run: |
          python -m pip install -U pip wheel setuptools pyarrow pandas
          pip install numpy scikit-learn pyproj shapely geopandas fiona rtree

      - name: Download upstream artifact (triggering run)
        if: ${{ github.event_name == 'workflow_run' }}
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact

      - name: Unzip artifact if present (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${{ env.ARTIFACT_ZIP }}" ]; then
            command -v unzip >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null && sudo apt-get install -y unzip >/dev/null; }
            unzip -o "${{ env.ARTIFACT_ZIP }}" -d "${{ env.ARTIFACT_DIR }}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi

      # (0) GRID & EVENTS Ã¼retimi + Y_label â€” mutlak path kullan
      - name: (0) Build FR daily (GRID & EVENTS) + Y_label
        env:
          FR_EVENTS_PATH:  ${{ env.CRIME_DATA_DIR }}/sf_crime.csv
          FR_OUT_EVENTS:   ${{ env.CRIME_DATA_DIR }}/fr_crime_events_daily.csv
          FR_OUT_GRID:     ${{ env.CRIME_DATA_DIR }}/fr_crime_grid_daily.csv
          FR_MIN_YEARS:    "5"
          FR_DATE_COL:     "incident_datetime"
          FR_GEOID_COL:    "GEOID"
          FR_ID_COL:       "id"
        run: |
          set -e
          echo "ðŸ“‚ CWD: $(pwd)"
          echo "ðŸ”§ FR_EVENTS_PATH: ${FR_EVENTS_PATH}"
          echo "ðŸ”§ FR_OUT_EVENTS : ${FR_OUT_EVENTS}"
          echo "ðŸ”§ FR_OUT_GRID   : ${FR_OUT_GRID}"
          ls -la "${CRIME_DATA_DIR}" || true
          python -u update_crime_daily.py
          echo "---- GRID head ----"
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_grid_daily.csv" || true
          echo "---- EVENTS head ----"
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_events_daily.csv" || true

      - name: (1) 911 -> enrich GRID & EVENTS
        env:
          FR_911_PATH: "${{ env.CRIME_DATA_DIR }}/sf_911_last_5_year.csv"
          FR_911_DATE_COL: "incident_datetime"
          FR_911_GEOID_COL: "GEOID"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u enrich_with_911.py
          head -n 5 "${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}" || true

      - name: (2) 311 -> enrich GRID & EVENTS
        env:
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
          FR_311_DAILY_IN: ""
          AGG_311_NAME: "sf_311_last_5_years.csv"
        run: |
          set -e
          python -u update_311_daily.py
          python - <<'PY'
          import pandas as pd, os
          p=os.path.join(os.getenv("CRIME_DATA_DIR"),os.getenv("FR_GRID_DAILY_OUT"))
          df=pd.read_csv(p, nrows=0); print(list(df.columns))
          PY

      - name: (3) Bus stops -> enrich GRID & EVENTS
        env:
          BUS_CANON_RAW: "sf_bus_stops_with_geoid.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_bus_daily.py

      - name: (4) Train stops -> enrich GRID & EVENTS
        env:
          TRAIN_STOPS_NAME: "sf_train_stops_with_geoid.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_train_daily.py

      - name: (5) POI -> enrich GRID & EVENTS
        env:
          POI_GEOJSON_1: "${{ env.CRIME_DATA_DIR }}/sf_pois.geojson"
          POI_GEOJSON_2: "sf_pois.geojson"
          POI_CLEAN_CSV: "${{ env.CRIME_DATA_DIR }}/sf_pois_cleaned_with_geoid.csv"
          BLOCK_GEOJSON: "${{ env.CRIME_DATA_DIR }}/sf_census_blocks_with_population.geojson"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_poi_daily.py

      - name: (6) Police & Government -> enrich GRID & EVENTS
        env:
          POLICE_FILE: "sf_police_stations.csv"
          GOV_FILE: "sf_government_buildings.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_police_gov_daily.py

      - name: (7) Weather (date-merge) -> enrich GRID & EVENTS
        env:
          WEATHER_FILE: "sf_weather_5years.csv"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u update_weather_daily.py

      - name: (8) Neighbor windows (1/3/7d) -> enrich GRID & EVENTS
        env:
          NEIGH_FILE: "${{ env.NEIGH_FILE }}"
          FR_GRID_DAILY_IN:  "${{ env.FR_GRID_DAILY_IN }}"
          FR_GRID_DAILY_OUT: "${{ env.FR_GRID_DAILY_OUT }}"
          FR_EVENTS_DAILY_IN:  "${{ env.FR_EVENTS_DAILY_IN }}"
          FR_EVENTS_DAILY_OUT: "${{ env.FR_EVENTS_DAILY_OUT }}"
        run: |
          set -e
          python -u make_neighbors_fr.py

      - name: Final previews
        run: |
          echo "==== GRID (top 3 rows) ===="
          head -n 3 "${CRIME_DATA_DIR}/${FR_GRID_DAILY_OUT}" || true
          echo "==== EVENTS (top 3 rows) ===="
          head -n 3 "${CRIME_DATA_DIR}/${FR_EVENTS_DAILY_OUT}" || true
          echo "==== GRID column list ===="
          python - <<'PY'
          import pandas as pd, os
          p=os.path.join(os.getenv("CRIME_DATA_DIR"),os.getenv("FR_GRID_DAILY_OUT"))
          df=pd.read_csv(p, nrows=0); print("\n".join(df.columns))
          PY

      - name: Upload artifacts (GRID & EVENTS)
        uses: actions/upload-artifact@v4
        with:
          name: fr-daily-grid-events
          path: |
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_GRID_DAILY_OUT }}
            ${{ env.CRIME_DATA_DIR }}/${{ env.FR_EVENTS_DAILY_OUT }}
          if-no-files-found: warn

  patrol-fr:
    needs: [run_fr]
    if: ${{ needs.run_fr.result == 'success' }}
    runs-on: ubuntu-latest
    env:
      GRID_FILE:      fr_crime_grid_daily.csv
      PATROL_TOP_K:   "25"
      PATROL_MIN_SPACING_M: "300"
      PATROL_OUT_CSV: "fr_patrol_plan.csv"

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      # ðŸ”‘ Daily dosyalarÄ±nÄ± Ã¶nceki job'dan indir
      - name: Download daily grid/events from previous job
        uses: actions/download-artifact@v4
        with:
          name: fr-daily-grid-events
          path: ${{ env.CRIME_DATA_DIR }}

      - name: Verify transferred files
        run: |
          echo "ðŸ“¦ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          ls -la "${CRIME_DATA_DIR}" || true
          head -n 3 "${CRIME_DATA_DIR}/fr_crime_grid_daily.csv" || true
          head -n 3 "${CRIME_DATA_DIR}/fr_crime_events_daily.csv" || true

      - name: Install deps (runtime only)
        run: |
          python -m pip install -U pip
          pip install pandas numpy

      - name: Run patrol planner
        run: |
          set -e
          python - <<'PY'
          import os, sys, pandas as pd
          from pathlib import Path
          base = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data"))
          grid_path = base / os.environ.get("GRID_FILE","fr_crime_grid_daily.csv")
          k    = int(os.environ.get("PATROL_TOP_K","25"))
          out_csv = base / os.environ.get("PATROL_OUT_CSV","fr_patrol_plan.csv")
          if not grid_path.exists():
              print(f"âŒ GRID bulunamadÄ±: {grid_path}", file=sys.stderr); sys.exit(2)
          df = pd.read_csv(grid_path)
          if df.empty:
              print("âš ï¸ GRID boÅŸ, plan Ã¼retilemedi.")
              pd.DataFrame(columns=["GEOID","date","risk_score","Y_label","events_count"]).to_csv(out_csv, index=False)
              sys.exit(0)
          need = ["GEOID","date"]
          for c in need:
              if c not in df.columns:
                  print(f"âŒ Zorunlu kolon yok: {c}", file=sys.stderr); sys.exit(3)
          df["date"] = pd.to_datetime(df["date"], errors="coerce")
          last_day = df["date"].dropna().max()
          if pd.isna(last_day):
              print("âŒ Tarih alanÄ± hatalÄ±.", file=sys.stderr); sys.exit(4)
          today = df[df["date"]==last_day].copy()
          def safe_num(name, default=0.0):
              s = pd.to_numeric(today[name], errors="coerce").fillna(0) if name in today.columns else default
              return s if hasattr(s, "values") else pd.Series(default, index=today.index)
          today["risk_score"] = (
              safe_num("events_count")*1.0 +
              safe_num("neighbor_crime_24h")*0.20 +
              safe_num("neighbor_crime_72h")*0.10 +
              safe_num("neighbor_crime_7d")*0.05 +
              safe_num("n911_prev_1d")*0.10
          )
          agg_cols = {c:"max" for c in ["risk_score","events_count"] if c in today.columns}
          if "Y_label" in today.columns: agg_cols["Y_label"] = "max"
          topk = (today.sort_values("risk_score", ascending=False)
                       .groupby("GEOID", as_index=False)
                       .agg(agg_cols)
                       .sort_values("risk_score", ascending=False)
                       .head(k))
          topk.insert(1, "date", last_day.date())
          out_csv.parent.mkdir(parents=True, exist_ok=True)
          topk.to_csv(out_csv, index=False)
          print(f"âœ… Wrote patrol CSV -> {out_csv} (rows={len(topk)})")
          PY

      - name: Upload patrol artifacts
        uses: actions/upload-artifact@v4
        with:
          name: fr-patrol-plan
          path: ${{ env.CRIME_DATA_DIR }}/${{ env.PATROL_OUT_CSV }}
          if-no-files-found: warn
