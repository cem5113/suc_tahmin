name: Post Processing (FR)

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
    branches: [main]

permissions:
  contents: read
  actions: read

concurrency:
  group: post-processing-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    env:
      CRIME_DATA_DIR: crime_prediction_data
      WX_LOCATION: "paris"
      WX_UNIT: "metric"
      GEOID_LEN: "11"

      ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
      ARTIFACT_DIR: artifact
      FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
      FALLBACK_DIRS: ${{ github.workspace }}/crime_prediction_data,${{ github.workspace }}

    steps:
      - uses: actions/checkout@v4

      - name: Ensure data dir (FR)
        run: mkdir -p "${CRIME_DATA_DIR}"

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps (quick)
        run: |
          python -m pip install -U pip wheel setuptools
          [ -f requirements.txt ] && pip install -r requirements.txt || true

      - name: Install parquet engine
        run: |
          python -m pip install -U pyarrow pandas

      - name: Download upstream artifact (triggering run)
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact

      - name: Unzip artifact if present (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${{ env.ARTIFACT_ZIP }}" ]; then
            command -v unzip >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null && sudo apt-get install -y unzip >/dev/null; }
            unzip -o "${{ env.ARTIFACT_ZIP }}" -d "${{ env.ARTIFACT_DIR }}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi

      # --- FR 00..09: Mevcut Ã¼retim adÄ±mlarÄ±n (fr_crime_09'a kadar) ---
      - name: FR 00) Base grid / event label merge
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_crime_fr.py
          head -n 5 "${CRIME_DATA_DIR}/sf_crime_grid_full_labeled.csv" || true

      - name: FR 01) 911
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_911_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_01.csv" || true

      - name: FR 02) 311
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_311_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_02.csv" || true

      - name: FR 03) Population
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_population_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_03.csv" || true

      - name: FR 04) Bus
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_bus_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_04.csv" || true

      - name: FR 05) Train
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_train_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_05.csv" || true

      - name: FR 06) POI
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_poi_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_06.csv" || true

      - name: FR 07) Police & Gov
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_police_gov_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_07.csv" || true

      - name: FR 08) Weather
        env:
          ARTIFACT_ZIP: ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR: ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS: ${{ env.FALLBACK_DIRS }}
        run: |
          set -euo pipefail
          python -u update_weather_fr.py || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_08.csv" || true

      - name: FR 09) Neighbors
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
        run: |
          set -euo pipefail
          if [ -f scripts/make_neighbors_fr.py ]; then
            PY=scripts/make_neighbors_fr.py
          elif [ -f make_neighbors_fr.py ]; then
            PY=make_neighbors_fr.py
          else
            echo "âš ï¸ make_neighbors_fr.py bulunamadÄ±, adÄ±m atlanÄ±yor."
            exit 0
          fi
          test -f "${CRIME_DATA_DIR}/fr_crime_08.csv" || echo "âš ï¸ fr_crime_08.csv yok (devam edilebilir)."
          python -u "$PY" || true
          head -n 5 "${CRIME_DATA_DIR}/fr_crime_09.csv" || true

      - name: 10.8) Feature analysis (XGB + SHAP)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        run: |
          set -euo pipefail
          python -u run_feature_analysis_fr.py

      - name: 10.9) Prepare SHAP CSV for quartiles (discover & normalize)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
        run: |
          set -euo pipefail
          mkdir -p scripts "${CRIME_DATA_DIR}"
          # Basit bir Ã¶rnek script oluÅŸtur (yoksa)
          if [ ! -f scripts/prepare_shap_csv.py ]; then
            cat > scripts/prepare_shap_csv.py <<'PY'
            import os, pandas as pd
            from pathlib import Path
            BASE = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data")).resolve()
            p = BASE/"shap_feature_importance.csv"
            if not p.exists():
                print("[WARN] shap_feature_importance.csv yok, adÄ±m atlandÄ±.")
                raise SystemExit(0)
            df = pd.read_csv(p)
            df = df.rename(columns={"mean_abs_shap":"shap"})
            df["rank"] = df["shap"].rank(ascending=False, method="dense").astype(int)
            df.to_csv(BASE/"shap_feature_importance_ranked.csv", index=False)
            print("âœ… shap_feature_importance_ranked.csv hazÄ±r.")
            PY
          fi
          python -u scripts/prepare_shap_csv.py


      - name: FR 11) Risk exports (single CSV with top1..top3 columns)
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
        shell: bash
        run: |
          set -euo pipefail

          echo "ðŸ”Ž DF/PROBA kaynaklarÄ±nÄ± arÄ±yorumâ€¦"
          DF_CANDS=(
            "${CRIME_DATA_DIR}/fr_crime_09.csv"
            "${CRIME_DATA_DIR}/fr_crime_08.csv"
            "${CRIME_DATA_DIR}/fr_crime.csv"
          )
          RISK_CANDS=(
            "${CRIME_DATA_DIR}/risk_hourly_grid_full_labeled.csv"
            "${ARTIFACT_DIR}/risk_hourly_grid_full_labeled.csv"
            "${ARTIFACT_DIR}/crime_prediction_data/risk_hourly_grid_full_labeled.csv"
          )
          pick_first() { for p in "$@"; do [ -f "$p" ] && { echo "$p"; return 0; }; done; return 1; }
          DF_PATH="$(pick_first "${DF_CANDS[@]}" || true)"
          RISK_PATH="$(pick_first "${RISK_CANDS[@]}" || true)"

          if [ -z "${DF_PATH:-}" ]; then
            echo "âŒ DF bulunamadÄ± (fr_crime_09.csv bekleniyor)."; exit 1
          fi

          # risk_source'Ä± CRIME_DATA_DIR altÄ±na sabitle (join iÃ§in)
          if [ -n "${RISK_PATH:-}" ] && [ ! -f "${CRIME_DATA_DIR}/risk_hourly_grid_full_labeled.csv" ]; then
            cp -f "${RISK_PATH}" "${CRIME_DATA_DIR}/risk_hourly_grid_full_labeled.csv" || true
          fi

          # script yolu
          if [ -f risk_exports_fr.py ]; then PY=risk_exports_fr.py;
          elif [ -f scripts/risk_exports_fr.py ]; then PY=scripts/risk_exports_fr.py;
          else echo "âŒ risk_exports_fr.py yok"; exit 1; fi

          python -u "$PY" --df "${DF_PATH}" --proba-from-risk "${CRIME_DATA_DIR}/risk_hourly_grid_full_labeled.csv" --threshold 0.5 --out-prefix ""

          echo "---- head(risk_hourly_grid_full_labeled.csv) ----"
          head -n 3 "${CRIME_DATA_DIR}/risk_hourly_grid_full_labeled.csv" || true

      - name: 11) Install ML deps for stacking
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        run: |
          python -m pip install -U pip wheel setuptools
          pip install pandas numpy scikit-learn joblib
          pip install xgboost lightgbm || true

      - name: 11.5) Run stacking risk pipeline
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          STACKING_DATASET: ${{ env.CRIME_DATA_DIR }}/sf_crime_grid_full_labeled.csv
          ENABLE_SPATIAL_TE: "1"
          TE_ALPHA: "50"
          NEIGH_FILE: ${{ env.CRIME_DATA_DIR }}/neighbors.csv
          ENABLE_TE_ABLATION: "1"
          ABLASYON_BASIS: "ohe"
          PATROL_HORIZON_DAYS: ${{ env.PATROL_HORIZON_DAYS }}
          PATROL_TOP_K: ${{ env.PATROL_TOP_K }}
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
        run: |
          set -e
          echo "HORIZON=${PATROL_HORIZON_DAYS}, TOP_K=${PATROL_TOP_K}"
          if [ ! -f "${STACKING_DATASET}" ]; then
            echo "âŒ STACKING_DATASET bulunamadÄ±: ${STACKING_DATASET}"
            exit 2
          fi
          python -u stacking_risk_pipeline_fr.py


      - name: FR 12) Build 2 ZIPs with EXACT files (incl. feature-analysis; no fr_crime_10)
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_DIR: ${{ env.ARTIFACT_DIR }}
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys, zipfile
          from pathlib import Path
          import pandas as pd

          base = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data")).resolve()
          extra = Path(os.environ.get("ARTIFACT_DIR","artifact")).resolve()
          base.mkdir(parents=True, exist_ok=True); extra.mkdir(parents=True, exist_ok=True)

          # CSV paketine girecekler
          WANT_CSV = [
            "fr_crime_09.csv",
            "risk_hourly.csv",
            "risk_daily.csv",
            "patrol_recs.csv",
            "risk_types_top3.csv",
            "metrics_stacking_ohe.csv",
            # feature-analysis Ã§Ä±ktÄ±larÄ±
            "feature_type_decision.csv",
            "feature_dropped_for_strict_numeric.csv",
            "feature_importance_xgb.csv",
            "feature_top20_xgb.csv",
            "shap_feature_importance.csv",
            "shap_top20.csv",
            "shap_feature_importance_ranked.csv",
          ]
          # Parquet paketine girecekler
          WANT_PQ  = [
            "fr_crime_09.parquet",
            "risk_hourly.parquet",
            "risk_daily.parquet",
            "patrol_recs.parquet",
            "metrics_stacking_ohe.parquet",
          ]

          def find_one(name: str):
            cands = list(base.rglob(name)) + list(extra.rglob(name))
            return cands[0] if cands else None

          # EÄŸer fr_crime_09 sadece CSV ise parquet Ã¼ret; tersi de
          def ensure_parquet(csv_path: Path) -> Path|None:
            try:
              df = pd.read_csv(csv_path, low_memory=False)
              pq = csv_path.with_suffix(".parquet"); df.to_parquet(pq, index=False)
              print(f"[MAKE] {pq.name} from {csv_path.name}")
              return pq
            except Exception as e:
              print(f"[WARN] {csv_path.name} â†’ parquet Ã¼retilemedi: {e}", file=sys.stderr)
              return None

          def ensure_csv(pq_path: Path) -> Path|None:
            try:
              df = pd.read_parquet(pq_path)
              csv = pq_path.with_suffix(".csv"); df.to_csv(csv, index=False)
              print(f"[MAKE] {csv.name} from {pq_path.name}")
              return csv
            except Exception as e:
              print(f"[WARN] {pq_path.name} â†’ csv Ã¼retilemedi: {e}", file=sys.stderr)
              return None

          csv_09 = find_one("fr_crime_09.csv")
          pq_09  = find_one("fr_crime_09.parquet")
          if csv_09 is None and pq_09 is None:
            print("âŒ fr_crime_09.(csv|parquet) yok; Ã¶nceki adÄ±mlarÄ± kontrol edin.", file=sys.stderr)
            sys.exit(1)
          if pq_09 is None and csv_09 is not None: pq_09 = ensure_parquet(csv_09)
          if csv_09 is None and pq_09 is not None: csv_09 = ensure_csv(pq_09)

          sel_csv, sel_pq = [], []

          def add_if_exists(bucket, name):
            p = find_one(name)
            if p is not None and "fr_crime_10" not in p.name:
              bucket.append(p)

          for n in WANT_CSV: add_if_exists(sel_csv, n)
          for n in WANT_PQ:  add_if_exists(sel_pq,  n)

          # Minimum gÃ¼vence
          if not any(p.name == "fr_crime_09.csv" for p in sel_csv) and csv_09 is not None:
            sel_csv.append(csv_09)
          if not any(p.name == "fr_crime_09.parquet" for p in sel_pq) and pq_09 is not None:
            sel_pq.append(pq_09)

          out_csv_zip = base / "fr_csv_outputs.zip"
          out_pq_zip  = base / "fr_parquet_outputs.zip"

          def arcname_for(p: Path) -> Path:
            try:
              pr = p.resolve()
              if str(pr).startswith(str(base.resolve())):
                return pr.relative_to(base)
              if str(pr).startswith(str(extra.resolve())):
                return Path("artifact") / pr.relative_to(extra)
            except Exception:
              pass
            return Path(p.name)

          with zipfile.ZipFile(out_csv_zip, "w", compression=zipfile.ZIP_DEFLATED) as z:
            for p in sel_csv: z.write(p, arcname=str(arcname_for(p))); print(f"+ CSV: {p.name}")
          print(f"âœ… CSV ZIP hazÄ±r: {out_csv_zip}")

          with zipfile.ZipFile(out_pq_zip, "w", compression=zipfile.ZIP_DEFLATED) as z:
            for p in sel_pq: z.write(p, arcname=str(arcname_for(p))); print(f"+ PQ: {p.name}")
          print(f"âœ… Parquet ZIP hazÄ±r: {out_pq_zip}")
          PY

      - name: Upload FR outputs (CSV ZIP)
        uses: actions/upload-artifact@v4
        with:
          name: fr-crime-outputs-csv
          path: ${{ env.CRIME_DATA_DIR }}/fr_csv_outputs.zip
          if-no-files-found: error
          retention-days: 14
          overwrite: true

      - name: Upload FR outputs (Parquet ZIP)
        uses: actions/upload-artifact@v4
        with:
          name: fr-crime-outputs-parquet
          path: ${{ env.CRIME_DATA_DIR }}/fr_parquet_outputs.zip
          if-no-files-found: error
          retention-days: 14
          overwrite: true
