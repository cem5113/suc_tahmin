name: Post Processing (FR)

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
    branches: [main]

permissions:
  contents: read
  actions: write

concurrency:
  group: post-processing-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    env:
      CRIME_DATA_DIR: ${{ github.workspace }}/crime_prediction_data
      ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
      ARTIFACT_DIR: artifact
      FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
      FALLBACK_DIRS: ${{ github.workspace }},${{ github.workspace }}/crime_prediction_data
      FR_LABEL_PATH: ${{ github.workspace }}/crime_prediction_data/sf_crime_grid_full_labeled.csv
      WX_LOCATION: "paris"
      WX_UNIT: "metric"
      GEOID_LEN: "11"
      PATROL_HORIZON_DAYS: "1"
      PATROL_TOP_K: "50"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Ensure base dirs
        shell: bash
        run: |
          set -euo pipefail
          echo "GITHUB_WORKSPACE=${GITHUB_WORKSPACE}"
          echo "CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          mkdir -p "${CRIME_DATA_DIR}"
          mkdir -p "${ARTIFACT_DIR}"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python dependencies (project)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip wheel setuptools
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: Install parquet engine and data libs
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pandas pyarrow

      - name: Download upstream artifact (from triggering run)
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact

      - name: Show artifact tree (debug)
        shell: bash
        run: |
          set -euo pipefail
          echo "=== artifact/ (after download) ==="
          ls -lahR artifact || true

      - name: Unzip artifact if present (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${{ env.ARTIFACT_ZIP }}" ]; then
            command -v unzip >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null && sudo apt-get install -y unzip >/dev/null; }
            echo "Unzipping: ${ARTIFACT_ZIP} -> ${ARTIFACT_DIR}"
            unzip -o "${ARTIFACT_ZIP}" -d "${ARTIFACT_DIR}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi
          echo "=== artifact/ (after optional unzip) ==="
          ls -lahR artifact || true

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # FR 00..09 â€” Mevcut Ã¼retim adÄ±mlarÄ±nÄ±z (dosyalar varsa Ã§alÄ±ÅŸÄ±r)
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: FR 00) Base grid / event label merge
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_crime_fr.py ]; then PY=update_crime_fr.py; elif [ -f scripts/update_crime_fr.py ]; then PY=scripts/update_crime_fr.py; else echo "âš ï¸ update_crime_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY"
          echo "HEAD sf_crime_grid_full_labeled.csv:"; head -n 5 "./sf_crime_grid_full_labeled.csv" || true
          echo "HEAD fr_crime.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime.csv" || true

      - name: FR 01) 911
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_911_fr.py ]; then PY=update_911_fr.py; elif [ -f scripts/update_911_fr.py ]; then PY=scripts/update_911_fr.py; else echo "âš ï¸ update_911_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_01.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_01.csv" || true

      - name: FR 02) 311
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
          FR_311_IN:      ${{ env.ARTIFACT_DIR }}/sf_311_last_5_years.csv
          FR_311_IN_PQ:   ${{ env.ARTIFACT_DIR }}/sf_311_last_5_years.parquet
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${FR_311_IN_PQ}" ]; then export FR_311_IN="${FR_311_IN_PQ}"; fi
          python -u update_311_fr.py || true
          echo "HEAD fr_crime_02.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_02.csv" || true

      - name: FR 03) Population
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_population_fr.py ]; then PY=update_population_fr.py; elif [ -f scripts/update_population_fr.py ]; then PY=scripts/update_population_fr.py; else echo "âš ï¸ update_population_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_03.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_03.csv" || true

      - name: FR 04) Bus
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_bus_fr.py ]; then PY=update_bus_fr.py; elif [ -f scripts/update_bus_fr.py ]; then PY=scripts/update_bus_fr.py; else echo "âš ï¸ update_bus_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_04.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_04.csv" || true

      - name: FR 05) Train
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_train_fr.py ]; then PY=update_train_fr.py; elif [ -f scripts/update_train_fr.py ]; then PY=scripts/update_train_fr.py; else echo "âš ï¸ update_train_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_05.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_05.csv" || true

      - name: FR 06) POI
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_poi_fr.py ]; then PY=update_poi_fr.py; elif [ -f scripts/update_poi_fr.py ]; then PY=scripts/update_poi_fr.py; else echo "âš ï¸ update_poi_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_06.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_06.csv" || true

      - name: FR 07) Police & Gov
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_police_gov_fr.py ]; then PY=update_police_gov_fr.py; elif [ -f scripts/update_police_gov_fr.py ]; then PY=scripts/update_police_gov_fr.py; else echo "âš ï¸ update_police_gov_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_07.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_07.csv" || true

      - name: FR 08) Weather
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_weather_fr.py ]; then PY=update_weather_fr.py; elif [ -f scripts/update_weather_fr.py ]; then PY=scripts/update_weather_fr.py; else echo "âš ï¸ update_weather_fr.py yok, adÄ±m atlanÄ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_08.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_08.csv" || true

      - name: FR 09) Neighbors
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/make_neighbors_fr.py ]; then PY=scripts/make_neighbors_fr.py
          elif [ -f make_neighbors_fr.py ]; then PY=make_neighbors_fr.py
          else echo "âš ï¸ make_neighbors_fr.py bulunamadÄ±, adÄ±m atlanÄ±yor."; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_09.csv:"; head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_09.csv" || true

      - name: Gate (always proceed)
        id: gate
        run: echo "proceed=true" >> "$GITHUB_OUTPUT"
        
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # FR 10 â€” SADECE STACKING (risk export YOK)
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: FR 10) Run stacking only (no risk exports)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          GEOID_LEN: ${{ env.GEOID_LEN || '11' }}
          # Ã‡oklu dataset
          STACKING_DATASETS: |
            ${{ env.CRIME_DATA_DIR }}/fr_crime_09.csv,
            ${{ env.CRIME_DATA_DIR }}/fr_crime_Q1.csv,
            ${{ env.CRIME_DATA_DIR }}/fr_crime_Q1Q2.csv
          STACKING_DATASET:  ${{ env.CRIME_DATA_DIR }}/fr_crime.csv
          # Spatial Target Encoding
          ENABLE_SPATIAL_TE: "1"
          TE_ALPHA: "50"
          NEIGHBOR_FILE: ${{ env.CRIME_DATA_DIR }}/neighbors.csv
          # EÄŸitim & CV
          CV_JOBS: "4"
          SUBSET_STRATEGY: "last12m"
          SUBSET_MIN_POS: "10000"
        shell: bash
        run: |
          set -euo pipefail
          echo "â–¶ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          echo "â–¶ GEOID_LEN=${GEOID_LEN}"
          echo "â–¶ STACKING_DATASETS=${STACKING_DATASETS}"

          # KomÅŸuluk dosyasÄ± zorunlu deÄŸil â†’ yoksa Spatial-TE kapat
          if [ -z "${NEIGHBOR_FILE:-}" ] || [ ! -f "${NEIGHBOR_FILE}" ]; then
            echo "â„¹ï¸ NEIGHBOR_FILE yok â†’ ENABLE_SPATIAL_TE=0"
            export ENABLE_SPATIAL_TE=0
            unset NEIGHBOR_FILE
          fi

          echo "ğŸš€ TRAIN_PHASE=select"
          export TRAIN_PHASE=select
          export STACKING_DATASETS="${STACKING_DATASETS}"
          python -u stacking_risk_pipeline_fr.py

          echo "ğŸš€ TRAIN_PHASE=final"
          export TRAIN_PHASE=final
          python -u stacking_risk_pipeline_fr.py

          echo "âœ… Stacking tamamlandÄ± â€” risk export bu adÄ±mda yapÄ±lmadÄ±."

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # FR 11 â€” RÄ°SK CSV'LERÄ° (hourly + daily) AYRI ADIM
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: FR 11) Generate risk CSVs (hourly + daily)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          WX_LOCATION: "paris"
          WX_UNIT: "metric"
        shell: bash
        run: |
          set -euo pipefail
          echo "â–¶ risk_exports_fr.py Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor..."
          if [ -f risk_exports_fr.py ]; then
            python -u risk_exports_fr.py
          elif [ -f scripts/risk_exports_fr.py ]; then
            python -u scripts/risk_exports_fr.py
          else
            echo "âŒ risk_exports_fr.py bulunamadÄ±"; exit 1
          fi

          echo "ğŸ“‚ Ãœretilen risk dosyalarÄ±:"
          ls -lah "${CRIME_DATA_DIR}" | grep -E 'risk_(hourly|daily)_grid_full_labeled' || true

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # FR 12 â€” RÄ°SK Ã‡IKTILARINI DOÄRULA
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: FR 12) Assert risk outputs exist
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        shell: bash
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
        run: |
          set -euo pipefail
          echo "ğŸ“‚ risk CSV kontrolÃ¼"
          test -f "${CRIME_DATA_DIR}/risk_hourly_grid_full_labeled.csv"
          test -f "${CRIME_DATA_DIR}/risk_daily_grid_full_labeled.csv"
          echo "âœ… risk CSVâ€™leri mevcut."

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # FR 13 â€” ZIP Ä°NÅA (joker destekli, fr_crime_10 hariÃ§)
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: FR 13) Build 2 ZIPs with EXACT files
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys, zipfile
          from pathlib import Path
          import pandas as pd

          base  = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data")).expanduser().resolve()
          extra = Path(os.environ.get("ARTIFACT_DIR","artifact")).expanduser().resolve()
          base.mkdir(parents=True, exist_ok=True)
          extra.mkdir(parents=True, exist_ok=True)

          WANT_CSV_PATTERNS = [
              "fr_crime_09.csv",
              "risk_hourly_grid_full_labeled*.csv",
              "risk_daily_grid_full_labeled*.csv",
              "metrics_stacking*.csv",
              "metrics_all*.csv",
              "stacking_manifest.csv",
          ]
          WANT_PQ_PATTERNS = [
              "fr_crime_09.parquet",
              "risk_hourly_grid_full_labeled*.parquet",
              "risk_daily_grid_full_labeled*.parquet",
              "metrics_stacking*.parquet",
              "metrics_all*.parquet",
          ]

          def rglob_many(root: Path, pattern: str):
              return [p for p in root.rglob(pattern) if p.is_file()]

          def find_first(pattern: str):
              for root in (base, extra):
                  hits = rglob_many(root, pattern)
                  if hits:
                      return hits[0]
              return None

          def ensure_pair(pattern_csv: str, pattern_pq: str):
              csv_p = find_first(pattern_csv)
              pq_p  = find_first(pattern_pq)

              def bad(p):
                  return p is not None and "fr_crime_10" in p.name

              if bad(csv_p): csv_p = None
              if bad(pq_p):  pq_p  = None

              if csv_p is None and pq_p is None:
                  return (None, None)

              if csv_p is None and pq_p is not None:
                  try:
                      df = pd.read_parquet(pq_p)
                      csv_p = pq_p.with_suffix(".csv")
                      df.to_csv(csv_p, index=False)
                      print(f"[MAKE] {csv_p.name} from {pq_p.name}")
                  except Exception as e:
                      print(f"[WARN] {pattern_csv} Ã¼retilemedi: {e}", file=sys.stderr)

              if pq_p is None and csv_p is not None:
                  try:
                      df = pd.read_csv(csv_p, low_memory=False)
                      pq_p = csv_p.with_suffix(".parquet")
                      df.to_parquet(pq_p, index=False)
                      print(f"[MAKE] {pq_p.name} from {csv_p.name}")
                  except Exception as e:
                      print(f"[WARN] {pattern_pq} Ã¼retilemedi: {e}", file=sys.stderr)

              return (csv_p, pq_p)

          fr09_csv, fr09_pq = ensure_pair("fr_crime_09.csv", "fr_crime_09.parquet")
          if fr09_csv is None and fr09_pq is None:
              print("âŒ fr_crime_09.(csv|parquet) bulunamadÄ±, Ã¼retim adÄ±mlarÄ±nÄ± kontrol edin.", file=sys.stderr)
              sys.exit(1)

          OPTIONAL = [
              ("risk_hourly_grid_full_labeled*.csv", "risk_hourly_grid_full_labeled*.parquet"),
              ("risk_daily_grid_full_labeled*.csv",  "risk_daily_grid_full_labeled*.parquet"),
              ("metrics_stacking*.csv",              "metrics_stacking*.parquet"),
              ("metrics_all*.csv",                   "metrics_all*.parquet"),
              ("stacking_manifest.csv",              "stacking_manifest.parquet"),
          ]

          selected_csv, selected_pq = [fr09_csv], [fr09_pq]
          for cpat, ppat in OPTIONAL:
              c, p = ensure_pair(cpat, ppat)
              if c is not None: selected_csv.append(c)
              if p is not None: selected_pq.append(p)

          def unique_paths(paths):
              seen = set(); out = []
              for p in paths:
                  if p is None:
                      continue
                  key = str(p.resolve())
                  if key in seen:
                      continue
                  seen.add(key); out.append(p)
              return out

          sel_csv = unique_paths(selected_csv)
          sel_pq  = unique_paths(selected_pq)

          out_csv_zip = base / "fr_csv_outputs.zip"
          out_pq_zip  = base / "fr_parquet_outputs.zip"

          def arcname_for(p: Path):
              try:
                  pr = p.resolve()
                  br = base.resolve()
                  er = extra.resolve()
                  if str(pr).startswith(str(br)):
                      return p.relative_to(base)
                  if str(pr).startswith(str(er)):
                      return Path("artifact") / p.relative_to(extra)
              except Exception:
                  pass
              return Path(p.name)

          with zipfile.ZipFile(out_csv_zip, "w", compression=zipfile.ZIP_DEFLATED) as z:
              for p in sel_csv:
                  if "fr_crime_10" in p.name:
                      continue
                  z.write(p, arcname=str(arcname_for(p)))
                  print(f"+ CSV: {p}")
          print(f"âœ… CSV ZIP hazÄ±r: {out_csv_zip}")

          with zipfile.ZipFile(out_pq_zip, "w", compression=zipfile.ZIP_DEFLATED) as z:
              for p in sel_pq:
                  if "fr_crime_10" in p.name:
                      continue
                  z.write(p, arcname=str(arcname_for(p)))
                  print(f"+ PQ: {p}")
          print(f"âœ… Parquet ZIP hazÄ±r: {out_pq_zip}"
          )
          PY

      - name: Upload FR outputs (CSV ZIP)
        uses: actions/upload-artifact@v4
        with:
          name: fr-crime-outputs-csv
          path: ${{ env.CRIME_DATA_DIR }}/fr_csv_outputs.zip
          overwrite: true
          if-no-files-found: error
          retention-days: 14

      - name: Upload FR outputs (Parquet ZIP)
        uses: actions/upload-artifact@v4
        with:
          name: fr-crime-outputs-parquet
          path: ${{ env.CRIME_DATA_DIR }}/fr_parquet_outputs.zip
          overwrite: true
          if-no-files-found: error
          retention-days: 14
