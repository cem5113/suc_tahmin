name: Post Processing (FR)

on:
  workflow_run:
    workflows: ["Full SF Crime Pipeline"]
    types: [completed]
    branches: [main]

permissions:
  contents: read
  actions: write

concurrency:
  group: post-processing-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run_fr:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    env:
      CRIME_DATA_DIR: ${{ github.workspace }}/crime_prediction_data
      WX_LOCATION: "paris"
      WX_UNIT: "metric"
      GEOID_LEN: "11"
      ARTIFACT_ZIP: artifact/sf-crime-pipeline-output.zip
      ARTIFACT_DIR: artifact
      FR_OUTPUT_DIR: ${{ github.workspace }}/crime_prediction_data
      FALLBACK_DIRS: ${{ github.workspace }},${{ github.workspace }}/crime_prediction_data
      FR_LABEL_PATH: ${{ github.workspace }}/crime_prediction_data/sf_crime_grid_full_labeled.csv
  
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Ensure base dirs
        shell: bash
        run: |
          set -euo pipefail
          echo "GITHUB_WORKSPACE=${GITHUB_WORKSPACE}"
          echo "CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          mkdir -p "${CRIME_DATA_DIR}"
          mkdir -p "${ARTIFACT_DIR}"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Python dependencies (project)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip wheel setuptools
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: Install parquet engine and data libs
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pandas pyarrow

      - name: Download upstream artifact (from triggering run)
        uses: dawidd6/action-download-artifact@v6
        with:
          run_id: ${{ github.event.workflow_run.id }}
          name: sf-crime-pipeline-output
          path: artifact

      - name: Show artifact tree (debug)
        shell: bash
        run: |
          set -euo pipefail
          echo "=== artifact/ (after download) ==="
          ls -lahR artifact || true

      - name: Unzip artifact if present (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "${{ env.ARTIFACT_ZIP }}" ]; then
            command -v unzip >/dev/null 2>&1 || { sudo apt-get update -y >/dev/null && sudo apt-get install -y unzip >/dev/null; }
            echo "Unzipping: ${ARTIFACT_ZIP} -> ${ARTIFACT_DIR}"
            unzip -o "${ARTIFACT_ZIP}" -d "${ARTIFACT_DIR}"
          else
            echo "No artifact ZIP file found (this is fine)."
          fi
          echo "=== artifact/ (after optional unzip) ==="
          ls -lahR artifact || true

      # ------------------------------------------------------------------
      # FR 00..09: Mevcut √ºretim adƒ±mlarƒ±n (fr_crime_09'a kadar)
      # Her step scriptlerinin ARTIFACT_ZIP/ARTIFACT_DIR/FR_OUTPUT_DIR/FALLBACK_DIRS
      # ortam deƒüi≈ükenlerini okuduƒüu varsayƒ±mƒ±yla √ßalƒ±≈üƒ±r.
      # ------------------------------------------------------------------

      - name: FR 00) Base grid / event label merge
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_crime_fr.py ]; then PY=update_crime_fr.py; elif [ -f scripts/update_crime_fr.py ]; then PY=scripts/update_crime_fr.py; else echo "‚ö†Ô∏è update_crime_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY"
          echo "HEAD sf_crime_grid_full_labeled.csv:"
          head -n 5 "./sf_crime_grid_full_labeled.csv" || true
          echo "HEAD fr_crime.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime.csv" || true


      - name: FR 01) 911
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_911_fr.py ]; then PY=update_911_fr.py; elif [ -f scripts/update_911_fr.py ]; then PY=scripts/update_911_fr.py; else echo "‚ö†Ô∏è update_911_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_01.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_01.csv" || true

      - name: FR 02) 311
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
          FR_311_IN:      ${{ env.ARTIFACT_DIR }}/sf_311_last_5_years.csv
          FR_311_IN_PQ:   ${{ env.ARTIFACT_DIR }}/sf_311_last_5_years.parquet
        shell: bash
        run: |
          set -euo pipefail
          # Parquet varsa onu, yoksa CSV‚Äôyi g√∂ster
          if [ -f "${FR_311_IN_PQ}" ]; then
            export FR_311_IN="${FR_311_IN_PQ}"
          fi
          python -u update_311_fr.py || true
          echo "HEAD fr_crime_02.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_02.csv" || true

      - name: FR 03) Population
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_population_fr.py ]; then PY=update_population_fr.py; elif [ -f scripts/update_population_fr.py ]; then PY=scripts/update_population_fr.py; else echo "‚ö†Ô∏è update_population_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_03.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_03.csv" || true

      - name: FR 04) Bus
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_bus_fr.py ]; then PY=update_bus_fr.py; elif [ -f scripts/update_bus_fr.py ]; then PY=scripts/update_bus_fr.py; else echo "‚ö†Ô∏è update_bus_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_04.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_04.csv" || true

      - name: FR 05) Train
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_train_fr.py ]; then PY=update_train_fr.py; elif [ -f scripts/update_train_fr.py ]; then PY=scripts/update_train_fr.py; else echo "‚ö†Ô∏è update_train_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_05.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_05.csv" || true

      - name: FR 06) POI
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_poi_fr.py ]; then PY=update_poi_fr.py; elif [ -f scripts/update_poi_fr.py ]; then PY=scripts/update_poi_fr.py; else echo "‚ö†Ô∏è update_poi_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_06.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_06.csv" || true

      - name: FR 07) Police & Gov
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_police_gov_fr.py ]; then PY=update_police_gov_fr.py; elif [ -f scripts/update_police_gov_fr.py ]; then PY=scripts/update_police_gov_fr.py; else echo "‚ö†Ô∏è update_police_gov_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_07.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_07.csv" || true

      - name: FR 08) Weather
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_ZIP:   ${{ env.ARTIFACT_ZIP }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f update_weather_fr.py ]; then PY=update_weather_fr.py; elif [ -f scripts/update_weather_fr.py ]; then PY=scripts/update_weather_fr.py; else echo "‚ö†Ô∏è update_weather_fr.py yok, adƒ±m atlanƒ±yor"; exit 0; fi
          python -u "$PY" || true
          echo "HEAD fr_crime_08.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_08.csv" || true

      - name: FR 09) Neighbors
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
          FR_OUTPUT_DIR:  ${{ env.FR_OUTPUT_DIR }}
          FALLBACK_DIRS:  ${{ env.FALLBACK_DIRS }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/make_neighbors_fr.py ]; then
            PY=scripts/make_neighbors_fr.py
          elif [ -f make_neighbors_fr.py ]; then
            PY=make_neighbors_fr.py
          else
            echo "‚ö†Ô∏è make_neighbors_fr.py bulunamadƒ±, adƒ±m atlanƒ±yor."
            exit 0
          fi
          if [ ! -f "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_08.csv" ]; then
            echo "‚ö†Ô∏è fr_crime_08.csv bulunamadƒ± (devam edilebilir)."
          fi
          python -u "$PY" || true
          echo "HEAD fr_crime_09.csv:"
          head -n 5 "$GITHUB_WORKSPACE/crime_prediction_data/fr_crime_09.csv" || true

      - name: 12) Run stacking risk pipeline (select + final, robust)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          # Zorunlu/temel
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          GEOID_LEN: ${{ env.GEOID_LEN || '11' }}
      
          # Veri seti se√ßimi:
          # 1) STACKING_DATASETS (virg√ºll√º liste) dolu ise o kullanƒ±lƒ±r
          # 2) deƒüilse STACKING_DATASET kullanƒ±lƒ±r
          STACKING_DATASETS: ${{ env.STACKING_DATASETS || '' }}
          STACKING_DATASET:  ${{ env.CRIME_DATA_DIR }}/fr_crime.csv
      
          # Spatial Target Encoding
          ENABLE_SPATIAL_TE: "1"
          TE_ALPHA: "50"
          NEIGHBOR_FILE: ${{ env.CRIME_DATA_DIR }}/neighbors.csv 
      
          # Ablasyon/kar≈üƒ±la≈ütƒ±rma
          ENABLE_TE_ABLATION: "1"
          ABLASYON_BASIS: "ohe"
      
          # Devriye √∂nerileri
          PATROL_HORIZON_DAYS: ${{ env.PATROL_HORIZON_DAYS }}
          PATROL_TOP_K:        ${{ env.PATROL_TOP_K }}
      
          # Eƒüitim & CV
          CV_JOBS: "4"
          SUBSET_STRATEGY: "last12m"      # select fazƒ± i√ßin
          SUBSET_MIN_POS: "10000"         # yetersiz pozitifte 18/24 ay geni≈ületme e≈üiƒüi
      
        run: |
          set -euo pipefail
      
          echo "‚ñ∂ CRIME_DATA_DIR=${CRIME_DATA_DIR}"
          echo "‚ñ∂ HORIZON=${PATROL_HORIZON_DAYS}, TOP_K=${PATROL_TOP_K}"
          echo "‚ñ∂ GEOID_LEN=${GEOID_LEN}"
          echo "‚ñ∂ CV_JOBS=${CV_JOBS}, SUBSET_STRATEGY=${SUBSET_STRATEGY}, SUBSET_MIN_POS=${SUBSET_MIN_POS}"
      
          # Veri seti belirle (√ßoklu liste √∂ncelikli)
          if [ -n "${STACKING_DATASETS}" ]; then
            DATASETS="${STACKING_DATASETS}"
            echo "üì¶ STACKING_DATASETS kullanƒ±lƒ±yor: ${DATASETS}"
          else
            DATASETS="${STACKING_DATASET}"
            echo "üìÑ STACKING_DATASET kullanƒ±lƒ±yor: ${DATASETS}"
          fi
      
          # Girdi mevcut mu?
          # Virg√ºll√ºyse ilkini kontrol edip uyarƒ± veriyoruz (tam kontrol yerine hƒ±zlƒ± sigorta)
          IFS=',' read -r FIRST_DATASET _ <<< "${DATASETS}"
          if [ -n "${FIRST_DATASET}" ] && [ ! -f "${FIRST_DATASET}" ]; then
            ALT="${CRIME_DATA_DIR}/$(basename "${FIRST_DATASET}")"
            if [ -f "${ALT}" ]; then
              echo "‚ÑπÔ∏è ${FIRST_DATASET} bulunamadƒ±; ${ALT} kullanƒ±labilir."
            else
              echo "‚ùå Veri seti bulunamadƒ±: ${FIRST_DATASET}"
              ls -lah "${CRIME_DATA_DIR}" || true
              exit 2
            fi
          fi
      
          # Kom≈üuluk dosyasƒ± yoksa Spatial-TE'yi otomatik kapat
          if [ -z "${NEIGHBOR_FILE:-}" ] || [ ! -f "${NEIGHBOR_FILE}" ]; then
            echo "‚ÑπÔ∏è NEIGHBOR_FILE bulunamadƒ± ‚Üí ENABLE_SPATIAL_TE=0"
            export ENABLE_SPATIAL_TE=0
            unset NEIGHBOR_FILE
          else
            echo "‚úÖ NEIGHBOR_FILE: ${NEIGHBOR_FILE}"
          fi
      
          # Faz 1: select (son 12 ay + hƒ±zlƒ± aƒüa√ß sayƒ±larƒ±)
          echo "üöÄ TRAIN_PHASE=select"
          export TRAIN_PHASE=select
          export STACKING_DATASETS="${DATASETS}"
          python -u stacking_risk_pipeline.py
      
          # Faz 2: final (5 yƒ±l + daha y√ºksek aƒüa√ß sayƒ±larƒ±)
          echo "üöÄ TRAIN_PHASE=final"
          export TRAIN_PHASE=final
          python -u stacking_risk_pipeline_fr.py
      
          echo "üìú √úretilen ba≈ülƒ±ca √ßƒ±ktƒ±lar:"
          ls -lah "${CRIME_DATA_DIR}" | sed -n '1,200p' || true
          test -f "${CRIME_DATA_DIR}/stacking_manifest.csv" && \
            (echo "‚îÄ stacking_manifest.csv:"; head -n 5 "${CRIME_DATA_DIR}/stacking_manifest.csv" || true)

      - name: FR 12) Build 2 ZIPs with EXACT files
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          ARTIFACT_DIR:   ${{ env.ARTIFACT_DIR }}
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, sys, zipfile
          from pathlib import Path
          import pandas as pd

          base  = Path(os.environ.get("CRIME_DATA_DIR","crime_prediction_data")).expanduser().resolve()
          extra = Path(os.environ.get("ARTIFACT_DIR","artifact")).expanduser().resolve()
          base.mkdir(parents=True, exist_ok=True)
          extra.mkdir(parents=True, exist_ok=True)

          # Mantƒ±ksal hedefler (birden fazla isim varyantƒ± desteklenir)
          CANDIDATES_CSV = [
            "fr_crime_09.csv",
            "risk_hourly_grid_full_labeled.csv",
            "risk_hourly.csv",
            "metrics_stacking_ohe.csv",
            "metrics_all.csv",
          ]
          CANDIDATES_PQ  = [
            "fr_crime_09.parquet",
            "risk_hourly_grid_full_labeled.parquet",
            "risk_hourly.parquet",
            "metrics_stacking_ohe.parquet",
            "metrics_all.parquet",
          ]

          def find_all(name: str):
            """√ñnce base, sonra artifact i√ßinde tam ada g√∂re ara (rglob)."""
            found = []
            for root in (base, extra):
              for p in root.rglob(name):
                if "fr_crime_10" in p.name:
                  continue
                found.append(p)
            return found

          def ensure_pair(csv_name: str, pq_name: str):
            """Bir √ßƒ±ktƒ±nƒ±n hem CSV hem Parquet versiyonunu √ºret/garanti et."""
            csv_paths = find_all(csv_name)
            pq_paths  = find_all(pq_name)

            csv_p, pq_p = (csv_paths[0] if csv_paths else None), (pq_paths[0] if pq_paths else None)

            # YOKSA, mevcut olandan t√ºret
            if csv_p is None and pq_p is None:
              return (None, None)

            if csv_p is None and pq_p is not None:
              try:
                df = pd.read_parquet(pq_p)
                csv_p = pq_p.with_suffix(".csv")
                df.to_csv(csv_p, index=False)
                print(f"[MAKE] {csv_p.name} from {pq_p.name}")
              except Exception as e:
                print(f"[WARN] {csv_name} √ºretilemedi: {e}", file=sys.stderr)

            if pq_p is None and csv_p is not None:
              try:
                df = pd.read_csv(csv_p, low_memory=False)
                pq_p = csv_p.with_suffix(".parquet")
                df.to_parquet(pq_p, index=False)
                print(f"[MAKE] {pq_p.name} from {csv_p.name}")
              except Exception as e:
                print(f"[WARN] {pq_name} √ºretilemedi: {e}", file=sys.stderr)

            return (csv_p, pq_p)

          # Zorunlu: fr_crime_09 (her iki formatta)
          fr09_csv, fr09_pq = ensure_pair("fr_crime_09.csv", "fr_crime_09.parquet")
          if fr09_csv is None and fr09_pq is None:
            print("‚ùå fr_crime_09.(csv|parquet) bulunamadƒ±, √ºretim adƒ±mlarƒ±nƒ± kontrol edin.", file=sys.stderr)
            sys.exit(1)

          # ƒ∞steƒüe baƒülƒ±: risk_hourly ve metrics (varsa dahil edilir)
          rh_csv, rh_pq = ensure_pair("risk_hourly_grid_full_labeled.csv", "risk_hourly_grid_full_labeled.parquet")
          if rh_csv is None and rh_pq is None:
            # eski adla deneyelim
            rh_csv, rh_pq = ensure_pair("risk_hourly.csv", "risk_hourly.parquet")

          mx_csv, mx_pq = ensure_pair("metrics_stacking_ohe.csv", "metrics_stacking_ohe.parquet")
          if mx_csv is None and mx_pq is None:
              mx_csv, mx_pq = ensure_pair("metrics_all.csv", "metrics_all.parquet")

          # Se√ßilecek dosyalarƒ± topla (fr_crime_10 asla eklenmez)
          sel_csv = [p for p in [fr09_csv, rh_csv, mx_csv] if p is not None]
          sel_pq  = [p for p in [fr09_pq,  rh_pq,  mx_pq]  if p is not None]

          out_csv_zip = base / "fr_csv_outputs.zip"
          out_pq_zip  = base / "fr_parquet_outputs.zip"

          def arcname_for(p: Path):
            try:
              pr = p.resolve()
              br = base.resolve()
              er = extra.resolve()
              if pr.as_posix().startswith(br.as_posix()):
                return p.relative_to(base)
              if pr.as_posix().startswith(er.as_posix()):
                return Path("artifact") / p.relative_to(extra)
            except Exception:
              pass
            return Path(p.name)

          # CSV ZIP
          with zipfile.ZipFile(out_csv_zip, "w", compression=zipfile.ZIP_DEFLATED) as z:
            for p in sel_csv:
              if "fr_crime_10" in p.name:
                continue
              z.write(p, arcname=str(arcname_for(p)))
              print(f"+ CSV: {p}")
          print(f"‚úÖ CSV ZIP hazƒ±r: {out_csv_zip}")

          # PARQUET ZIP
          with zipfile.ZipFile(out_pq_zip, "w", compression=zipfile.ZIP_DEFLATED) as z:
            for p in sel_pq:
              if "fr_crime_10" in p.name:
                continue
              z.write(p, arcname=str(arcname_for(p)))
              print(f"+ PQ: {p}")
          print(f"‚úÖ Parquet ZIP hazƒ±r: {out_pq_zip}")
          PY

      - name: Upload FR outputs (CSV ZIP)
        uses: actions/upload-artifact@v4
        with:
          name: fr-crime-outputs-csv
          path: ${{ env.CRIME_DATA_DIR }}/fr_csv_outputs.zip
          if-no-files-found: error
          retention-days: 14

      - name: Upload FR outputs (Parquet ZIP)
        uses: actions/upload-artifact@v4
        with:
          name: fr-crime-outputs-parquet
          path: ${{ env.CRIME_DATA_DIR }}/fr_parquet_outputs.zip
          if-no-files-found: error
          retention-days: 14
